#!/usr/bin/env python3
"""
å…¨é¢æµ‹è¯•å¥—ä»¶ - è¾¹ç•Œæ¡ä»¶ã€é”™è¯¯åœºæ™¯å’Œæ€§èƒ½æµ‹è¯•

ç¡®ä¿ç³»ç»Ÿåœ¨å„ç§æ¡ä»¶ä¸‹çš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚
"""

import sys
import tempfile
import threading
import time
from pathlib import Path
from unittest.mock import MagicMock, patch

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src"))

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæ¡ä»¶"""
    print("ğŸ§ª æµ‹è¯•é”™è¯¯å¤„ç†...")

    try:
        from database.connection import DatabaseConnection, DatabaseConnectionError
        from database.models import DocumentModel
        from repositories.document_repository import DocumentRepository

        # æµ‹è¯•æ— æ•ˆæ•°æ®åº“è·¯å¾„
        try:
            DatabaseConnection("/invalid/path/database.db")
            assert False, "åº”è¯¥æŠ›å‡ºè¿æ¥é”™è¯¯"
        except DatabaseConnectionError:
            print("  âœ… æ— æ•ˆæ•°æ®åº“è·¯å¾„é”™è¯¯å¤„ç†æ­£ç¡®")

        # æµ‹è¯•æ¨¡å‹éªŒè¯
        try:
            DocumentModel("", "", "", -1)  # ç©ºæ ‡é¢˜å’Œè´Ÿæ•°å¤§å°
            assert False, "åº”è¯¥æŠ›å‡ºéªŒè¯é”™è¯¯"
        except ValueError:
            print("  âœ… æ¨¡å‹æ•°æ®éªŒè¯æ­£ç¡®")

        # æµ‹è¯•æ•°æ®åº“æ“ä½œé”™è¯¯
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as temp_db:
            db_path = temp_db.name

        db = DatabaseConnection(db_path)
        repo = DocumentRepository(db)

        # æµ‹è¯•æŸ¥æ‰¾ä¸å­˜åœ¨çš„è®°å½•
        result = repo.find_by_id(99999)
        assert result is None
        print("  âœ… ä¸å­˜åœ¨è®°å½•æŸ¥æ‰¾å¤„ç†æ­£ç¡®")

        # æµ‹è¯•æ— æ•ˆSQL
        try:
            db.execute("INVALID SQL QUERY")
            assert False, "åº”è¯¥æŠ›å‡ºSQLé”™è¯¯"
        except Exception:
            print("  âœ… æ— æ•ˆSQLé”™è¯¯å¤„ç†æ­£ç¡®")

        # æ¸…ç†
        db.close_connection()
        Path(db_path).unlink(missing_ok=True)

        print("âœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_concurrent_operations():
    """æµ‹è¯•å¹¶å‘æ“ä½œå®‰å…¨æ€§"""
    print("ğŸ§ª æµ‹è¯•å¹¶å‘æ“ä½œ...")

    try:
        from database.connection import DatabaseConnection
        from database.migrations import DatabaseMigrator
        from database.models import DocumentModel
        from repositories.document_repository import DocumentRepository

        # åˆå§‹åŒ–æ•°æ®åº“
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as temp_db:
            db_path = temp_db.name

        db = DatabaseConnection(db_path)
        migrator = DatabaseMigrator(db)
        migrator.migrate()

        repo = DocumentRepository(db)
        results = []
        errors = []

        def worker_thread(thread_id):
            """å¹¶å‘å·¥ä½œçº¿ç¨‹"""
            try:
                for i in range(5):
                    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
                    with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_pdf:
                        temp_pdf.write(f"Thread {thread_id} document {i}".encode())
                        pdf_path = temp_pdf.name

                    doc = DocumentModel.from_file(
                        pdf_path,
                        f"hash_{thread_id}_{i}",
                        f"Document {thread_id}-{i}"
                    )

                    created_doc = repo.create(doc)
                    results.append(f"thread_{thread_id}_doc_{i}")

                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    Path(pdf_path).unlink(missing_ok=True)

                    time.sleep(0.001)  # çŸ­æš‚å»¶è¿Ÿå¢åŠ ç«äº‰æ¡ä»¶

            except Exception as e:
                errors.append(f"Thread {thread_id} error: {e}")

        # å¯åŠ¨å¤šä¸ªå¹¶å‘çº¿ç¨‹
        threads = []
        for thread_id in range(3):
            thread = threading.Thread(target=worker_thread, args=(thread_id,))
            threads.append(thread)
            thread.start()

        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()

        # éªŒè¯ç»“æœ
        assert len(errors) == 0, f"å¹¶å‘é”™è¯¯: {errors}"
        assert len(results) == 15, f"æœŸæœ›15ä¸ªç»“æœï¼Œå®é™…{len(results)}ä¸ª"

        # éªŒè¯æ•°æ®åº“ä¸€è‡´æ€§
        total_docs = repo.count()
        assert total_docs == 15, f"æ•°æ®åº“ä¸­æœŸæœ›15ä¸ªæ–‡æ¡£ï¼Œå®é™…{total_docs}ä¸ª"

        print(f"  âœ… æˆåŠŸå¤„ç† {len(results)} ä¸ªå¹¶å‘æ“ä½œ")
        print("  ğŸ“Š æ•°æ®åº“ä¸€è‡´æ€§éªŒè¯é€šè¿‡")

        # æ¸…ç†
        db.close_connection()
        Path(db_path).unlink(missing_ok=True)

        print("âœ… å¹¶å‘æ“ä½œæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ å¹¶å‘æ“ä½œæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_large_data_handling():
    """æµ‹è¯•å¤§æ•°æ®é‡å¤„ç†æ€§èƒ½"""
    print("ğŸ§ª æµ‹è¯•å¤§æ•°æ®é‡å¤„ç†...")

    try:
        from database.connection import DatabaseConnection
        from database.migrations import DatabaseMigrator
        from database.models import DocumentModel
        from repositories.document_repository import DocumentRepository

        # åˆå§‹åŒ–æ•°æ®åº“
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as temp_db:
            db_path = temp_db.name

        db = DatabaseConnection(db_path)
        migrator = DatabaseMigrator(db)
        migrator.migrate()

        repo = DocumentRepository(db)

        # æµ‹è¯•æ‰¹é‡æ’å…¥æ€§èƒ½
        start_time = time.time()
        batch_size = 100

        documents = []
        for i in range(batch_size):
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_pdf:
                temp_pdf.write(f"Large test document {i}".encode())
                pdf_path = temp_pdf.name

            doc = DocumentModel.from_file(pdf_path, f"large_hash_{i}", f"Large Document {i}")
            documents.append((doc, pdf_path))

        # æ‰¹é‡åˆ›å»º
        for doc, pdf_path in documents:
            repo.create(doc)
            Path(pdf_path).unlink(missing_ok=True)

        insert_time = time.time() - start_time
        print(f"  ğŸ“Š æ’å…¥ {batch_size} ä¸ªæ–‡æ¡£è€—æ—¶: {insert_time:.2f}ç§’")

        # æµ‹è¯•å¤§é‡æŸ¥è¯¢æ€§èƒ½
        start_time = time.time()

        # æ‰§è¡Œå„ç§æŸ¥è¯¢
        all_docs = repo.find_all()
        search_results = repo.search_by_title("Large")
        stats = repo.get_statistics()

        query_time = time.time() - start_time
        print(f"  ğŸ“Š å¤æ‚æŸ¥è¯¢è€—æ—¶: {query_time:.2f}ç§’")

        # éªŒè¯ç»“æœ
        assert len(all_docs) == batch_size
        assert len(search_results) == batch_size
        assert stats["total_documents"] == batch_size

        # æ€§èƒ½åŸºå‡†
        avg_insert_time = insert_time / batch_size * 1000  # æ¯«ç§’
        print(f"  âš¡ å¹³å‡æ’å…¥æ—¶é—´: {avg_insert_time:.2f}ms/æ–‡æ¡£")

        if avg_insert_time > 100:  # å¦‚æœè¶…è¿‡100ms/æ–‡æ¡£åˆ™è­¦å‘Š
            print("  âš ï¸ æ’å…¥æ€§èƒ½å¯èƒ½éœ€è¦ä¼˜åŒ–")
        else:
            print("  âœ… æ’å…¥æ€§èƒ½è‰¯å¥½")

        # æ¸…ç†
        db.close_connection()
        Path(db_path).unlink(missing_ok=True)

        print("âœ… å¤§æ•°æ®é‡å¤„ç†æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ å¤§æ•°æ®é‡å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_content_hash_edge_cases():
    """æµ‹è¯•å†…å®¹å“ˆå¸ŒæœåŠ¡çš„è¾¹ç•Œæƒ…å†µ"""
    print("ğŸ§ª æµ‹è¯•å†…å®¹å“ˆå¸Œè¾¹ç•Œæƒ…å†µ...")

    try:
        # ç›´æ¥å¯¼å…¥é¿å…ä¾èµ–é—®é¢˜
        sys.path.insert(0, str(Path(__file__).parent / "src" / "services"))
        from content_hash_service import ContentHashError, ContentHashService

        # æµ‹è¯•ç©ºæ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False) as empty_file:
            empty_path = empty_file.name

        try:
            hash_result = ContentHashService.calculate_file_hash(empty_path)
            assert isinstance(hash_result, str)
            assert len(hash_result) == 16
            print("  âœ… ç©ºæ–‡ä»¶å“ˆå¸Œè®¡ç®—æ­£ç¡®")
        except Exception as e:
            print(f"  âš ï¸ ç©ºæ–‡ä»¶å¤„ç†: {e}")

        # æµ‹è¯•å¤§æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰
        with patch('builtins.open') as mock_open:
            mock_file = MagicMock()
            # æ¨¡æ‹Ÿåˆ†å—è¯»å–
            mock_file.read.side_effect = [
                b'chunk1' * 1000,  # ç¬¬ä¸€å—
                b'chunk2' * 1000,  # ç¬¬äºŒå—
                b''  # ç»“æŸ
            ]
            mock_open.return_value.__enter__.return_value = mock_file

            with patch('pathlib.Path.exists', return_value=True):
                with patch('pathlib.Path.is_file', return_value=True):
                    hash_result = ContentHashService.calculate_file_hash("/fake/large/file.pdf")
                    assert len(hash_result) == 16
                    print("  âœ… å¤§æ–‡ä»¶åˆ†å—å¤„ç†æ­£ç¡®")

        # æµ‹è¯•ä¸å­˜åœ¨çš„æ–‡ä»¶
        try:
            ContentHashService.calculate_file_hash("/nonexistent/file.pdf")
            assert False, "åº”è¯¥æŠ›å‡ºæ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯"
        except ContentHashError:
            print("  âœ… ä¸å­˜åœ¨æ–‡ä»¶é”™è¯¯å¤„ç†æ­£ç¡®")

        # æµ‹è¯•æ— æ•ˆPDFï¼ˆéœ€è¦PyMuPDFï¼‰
        try:
            import fitz
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as invalid_pdf:
                invalid_pdf.write(b"This is not a valid PDF content")
                invalid_path = invalid_pdf.name

            try:
                ContentHashService.calculate_content_hash(invalid_path)
                assert False, "åº”è¯¥æŠ›å‡ºPDFå¤„ç†é”™è¯¯"
            except ContentHashError:
                print("  âœ… æ— æ•ˆPDFé”™è¯¯å¤„ç†æ­£ç¡®")

            Path(invalid_path).unlink(missing_ok=True)

        except ImportError:
            print("  âš ï¸ PyMuPDFä¸å¯ç”¨ï¼Œè·³è¿‡PDFæµ‹è¯•")

        # æµ‹è¯•æ–‡æœ¬è§„èŒƒåŒ–è¾¹ç•Œæƒ…å†µ
        test_cases = [
            ("", ""),  # ç©ºå­—ç¬¦ä¸²
            ("   ", ""),  # åªæœ‰ç©ºæ ¼
            ("UPPER\tLOWER", "upper lower"),  # å¤§å°å†™å’Œåˆ¶è¡¨ç¬¦
            ("Multiple   Spaces", "multiple spaces"),  # å¤šä¸ªç©ºæ ¼
            ("Line1\nLine2\r\nLine3", "line1 line2 line3"),  # æ¢è¡Œç¬¦
        ]

        for input_text, expected in test_cases:
            result = ContentHashService._normalize_text(input_text)
            assert result == expected, f"æ–‡æœ¬è§„èŒƒåŒ–å¤±è´¥: '{input_text}' -> '{result}' (æœŸæœ›: '{expected}')"

        print("  âœ… æ–‡æœ¬è§„èŒƒåŒ–è¾¹ç•Œæƒ…å†µæ­£ç¡®")

        # æ¸…ç†
        Path(empty_path).unlink(missing_ok=True)

        print("âœ… å†…å®¹å“ˆå¸Œè¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ å†…å®¹å“ˆå¸Œè¾¹ç•Œæƒ…å†µæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_transaction_rollback():
    """æµ‹è¯•äº‹åŠ¡å›æ»šåŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•äº‹åŠ¡å›æ»š...")

    try:
        from database.connection import DatabaseConnection
        from database.migrations import DatabaseMigrator
        from database.models import DocumentModel
        from repositories.document_repository import DocumentRepository

        # åˆå§‹åŒ–æ•°æ®åº“
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as temp_db:
            db_path = temp_db.name

        db = DatabaseConnection(db_path)
        migrator = DatabaseMigrator(db)
        migrator.migrate()

        repo = DocumentRepository(db)

        # åˆ›å»ºæµ‹è¯•æ•°æ®
        with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_pdf:
            temp_pdf.write(b"test content")
            pdf_path = temp_pdf.name

        doc = DocumentModel.from_file(pdf_path, "test_hash", "Test Document")
        created_doc = repo.create(doc)

        # éªŒè¯åˆå§‹çŠ¶æ€
        initial_count = repo.count()
        assert initial_count == 1

        # æµ‹è¯•äº‹åŠ¡å›æ»š
        try:
            with db.transaction():
                # åˆ›å»ºå¦ä¸€ä¸ªæ–‡æ¡£
                doc2 = DocumentModel.from_file(pdf_path, "test_hash_2", "Test Document 2")
                repo.create(doc2)

                # æ•…æ„è§¦å‘é”™è¯¯ï¼ˆé‡å¤å“ˆå¸Œï¼‰
                doc3 = DocumentModel.from_file(pdf_path, "test_hash", "Duplicate Hash")
                repo.create(doc3)  # è¿™åº”è¯¥å¤±è´¥å› ä¸ºå“ˆå¸Œé‡å¤

        except Exception:
            print("  âœ… äº‹åŠ¡å› é‡å¤å“ˆå¸Œå›æ»šï¼ˆç¬¦åˆé¢„æœŸï¼‰")

        # éªŒè¯å›æ»šåçŠ¶æ€
        final_count = repo.count()
        assert final_count == initial_count, f"æœŸæœ›{initial_count}ä¸ªæ–‡æ¡£ï¼Œå®é™…{final_count}ä¸ª"
        print("  âœ… äº‹åŠ¡å›æ»šéªŒè¯æˆåŠŸ")

        # æ¸…ç†
        Path(pdf_path).unlink(missing_ok=True)
        db.close_connection()
        Path(db_path).unlink(missing_ok=True)

        print("âœ… äº‹åŠ¡å›æ»šæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ äº‹åŠ¡å›æ»šæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_migration_compatibility():
    """æµ‹è¯•æ•°æ®åº“è¿ç§»å…¼å®¹æ€§"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®åº“è¿ç§»å…¼å®¹æ€§...")

    try:
        from database.connection import DatabaseConnection
        from database.migrations import DatabaseMigrator

        # åˆ›å»ºç©ºæ•°æ®åº“
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as temp_db:
            db_path = temp_db.name

        db = DatabaseConnection(db_path)
        migrator = DatabaseMigrator(db)

        # æµ‹è¯•ä»ç‰ˆæœ¬0å¼€å§‹
        assert migrator.get_current_version() == 0
        assert migrator.needs_migration() is True
        print("  âœ… åˆå§‹çŠ¶æ€æ£€æµ‹æ­£ç¡®")

        # æ‰§è¡Œè¿ç§»
        success = migrator.migrate()
        assert success is True
        print("  âœ… è¿ç§»æ‰§è¡ŒæˆåŠŸ")

        # éªŒè¯è¿ç§»åçŠ¶æ€
        assert migrator.get_current_version() == 1
        assert migrator.needs_migration() is False
        print("  âœ… è¿ç§»åçŠ¶æ€æ­£ç¡®")

        # æµ‹è¯•é‡å¤è¿ç§»
        success2 = migrator.migrate()
        assert success2 is True  # åº”è¯¥æˆåŠŸä½†æ— æ“ä½œ
        assert migrator.get_current_version() == 1
        print("  âœ… é‡å¤è¿ç§»å¤„ç†æ­£ç¡®")

        # éªŒè¯schemaå®Œæ•´æ€§
        assert migrator.validate_schema() is True
        print("  âœ… SchemaéªŒè¯é€šè¿‡")

        # æµ‹è¯•schemaä¿¡æ¯
        schema_info = migrator.get_schema_info()
        expected_tables = ["documents", "vector_indexes", "tags", "document_tags"]
        actual_tables = [table["name"] for table in schema_info["tables"]]

        for table in expected_tables:
            assert table in actual_tables, f"ç¼ºå°‘è¡¨: {table}"
        print("  âœ… æ‰€æœ‰å¿…è¦è¡¨å­˜åœ¨")

        # æ¸…ç†
        db.close_connection()
        Path(db_path).unlink(missing_ok=True)

        print("âœ… æ•°æ®åº“è¿ç§»å…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ æ•°æ®åº“è¿ç§»å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_memory_usage():
    """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
    print("ğŸ§ª æµ‹è¯•å†…å­˜ä½¿ç”¨...")

    try:
        import os

        import psutil

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        from database.connection import DatabaseConnection
        from database.migrations import DatabaseMigrator
        from database.models import DocumentModel
        from repositories.document_repository import DocumentRepository

        # åˆå§‹åŒ–æ•°æ®åº“
        with tempfile.NamedTemporaryFile(suffix='.db', delete=False) as temp_db:
            db_path = temp_db.name

        db = DatabaseConnection(db_path)
        migrator = DatabaseMigrator(db)
        migrator.migrate()
        repo = DocumentRepository(db)

        # åˆ›å»ºå¤§é‡æ–‡æ¡£æµ‹è¯•å†…å­˜ä½¿ç”¨
        for i in range(50):
            with tempfile.NamedTemporaryFile(suffix='.pdf', delete=False) as temp_pdf:
                temp_pdf.write(f"Memory test document {i}".encode())
                pdf_path = temp_pdf.name

            doc = DocumentModel.from_file(pdf_path, f"memory_hash_{i}", f"Memory Test {i}")
            repo.create(doc)
            Path(pdf_path).unlink(missing_ok=True)

        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory

        print(f"  ğŸ“Š åˆå§‹å†…å­˜: {initial_memory:.1f}MB")
        print(f"  ğŸ“Š æœ€ç»ˆå†…å­˜: {final_memory:.1f}MB")
        print(f"  ğŸ“Š å†…å­˜å¢é•¿: {memory_increase:.1f}MB")

        # å†…å­˜ä½¿ç”¨åº”è¯¥åˆç†ï¼ˆå°äº50MBå¢é•¿ï¼‰
        if memory_increase > 50:
            print("  âš ï¸ å†…å­˜ä½¿ç”¨å¯èƒ½è¿‡é«˜")
        else:
            print("  âœ… å†…å­˜ä½¿ç”¨åˆç†")

        # æ¸…ç†
        db.close_connection()
        Path(db_path).unlink(missing_ok=True)

        print("âœ… å†…å­˜ä½¿ç”¨æµ‹è¯•é€šè¿‡")
        return True

    except ImportError:
        print("  âš ï¸ psutilä¸å¯ç”¨ï¼Œè·³è¿‡å†…å­˜æµ‹è¯•")
        return True
    except Exception as e:
        print(f"âŒ å†…å­˜ä½¿ç”¨æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œå…¨é¢æµ‹è¯•å¥—ä»¶"""
    print("ğŸš€ å¼€å§‹å…¨é¢æµ‹è¯•...\n")

    tests = [
        test_error_handling,
        test_concurrent_operations,
        test_large_data_handling,
        test_content_hash_edge_cases,
        test_transaction_rollback,
        test_migration_compatibility,
        test_memory_usage
    ]

    passed = 0
    total = len(tests)

    for test_func in tests:
        if test_func():
            passed += 1
        print()  # ç©ºè¡Œåˆ†éš”

    print(f"ğŸ“Š å…¨é¢æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰å…¨é¢æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿç¨³å®šå¯é ï¼")
        return True
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
