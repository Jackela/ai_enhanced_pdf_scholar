name: Performance Monitoring

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      full_suite:
        description: 'Run full performance suite'
        required: false
        default: 'false'
        type: boolean

jobs:
  performance-validation:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install httpx  # For API benchmarks
    
    - name: Create performance directories
      run: |
        mkdir -p performance_results
        mkdir -p performance_artifacts
    
    - name: Run CI Performance Validation
      id: ci_validation
      run: |
        python scripts/ci_performance_check.py --save-results --quiet
        echo "validation_result=$?" >> $GITHUB_OUTPUT
      continue-on-error: true
    
    - name: Run Full Performance Suite (on schedule or manual trigger)
      if: github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && inputs.full_suite == 'true')
      run: |
        python scripts/comprehensive_performance_suite.py --save --html --output-dir performance_results
      continue-on-error: true
    
    - name: Upload CI Performance Results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: ci-performance-results-${{ github.run_number }}
        path: |
          ci_performance_results.json
          performance_baselines.json
        retention-days: 30
    
    - name: Upload Full Performance Results
      uses: actions/upload-artifact@v4
      if: github.event_name == 'schedule' || (github.event_name == 'workflow_dispatch' && inputs.full_suite == 'true')
      with:
        name: full-performance-results-${{ github.run_number }}
        path: |
          performance_results/
        retention-days: 90
    
    - name: Check Performance Results
      run: |
        if [ -f ci_performance_results.json ]; then
          echo "## üìä Performance Validation Results" >> $GITHUB_STEP_SUMMARY
          
          # Extract key metrics from results
          if python -c "
          import json
          with open('ci_performance_results.json') as f:
              results = json.load(f)
          
          passed = results.get('thresholds_passed', False) and results.get('regressions_passed', False)
          violations = len(results.get('violations', []))
          warnings = len(results.get('warnings', []))
          duration = results.get('duration_seconds', 0)
          
          print(f'Performance validation: {\"‚úÖ PASSED\" if passed else \"‚ùå FAILED\"}')
          print(f'Duration: {duration:.2f} seconds')
          print(f'Violations: {violations}')
          print(f'Warnings: {warnings}')
          
          if violations > 0:
              print(f'Exit code: 1')
              exit(1)
          "; then
            echo "Performance validation completed successfully"
          else
            echo "Performance validation failed with violations"
            exit 1
          fi
        else
          echo "No performance results found"
          exit 1
        fi
    
    - name: Comment PR with Performance Results
      if: github.event_name == 'pull_request' && always()
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          
          if (!fs.existsSync('ci_performance_results.json')) {
            return;
          }
          
          const results = JSON.parse(fs.readFileSync('ci_performance_results.json', 'utf8'));
          
          const passed = results.thresholds_passed && results.regressions_passed;
          const violations = results.violations || [];
          const warnings = results.warnings || [];
          
          let comment = `## üìä Performance Validation Results\n\n`;
          comment += `**Status:** ${passed ? '‚úÖ PASSED' : '‚ùå FAILED'}\n`;
          comment += `**Duration:** ${results.duration_seconds?.toFixed(2) || 'N/A'} seconds\n\n`;
          
          if (violations.length > 0) {
            comment += `### üö® Performance Violations (${violations.length})\n\n`;
            violations.slice(0, 5).forEach((violation, i) => {
              comment += `${i + 1}. ${violation}\n`;
            });
            if (violations.length > 5) {
              comment += `... and ${violations.length - 5} more violations\n`;
            }
            comment += '\n';
          }
          
          if (warnings.length > 0) {
            comment += `### ‚ö†Ô∏è Performance Warnings (${warnings.length})\n\n`;
            warnings.slice(0, 3).forEach((warning, i) => {
              comment += `${i + 1}. ${warning}\n`;
            });
            if (warnings.length > 3) {
              comment += `... and ${warnings.length - 3} more warnings\n`;
            }
            comment += '\n';
          }
          
          if (passed) {
            comment += `‚úÖ **All performance requirements met!**\n\n`;
          } else {
            comment += `‚ùå **Performance requirements not met.** Please investigate violations before merging.\n\n`;
          }
          
          comment += `<details>\n<summary>Performance Thresholds</summary>\n\n`;
          comment += `- Database queries: < 10ms\n`;
          comment += `- File I/O: > 1 MB/s\n`;
          comment += `- Text processing: > 1M chars/s\n`;
          comment += `- Overall operations: < 100ms\n`;
          comment += `- Regression threshold: 50%\n\n`;
          comment += `</details>\n`;
          
          // Find existing performance comment
          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number,
          });
          
          const existingComment = comments.find(comment => 
            comment.body.includes('üìä Performance Validation Results')
          );
          
          if (existingComment) {
            // Update existing comment
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: existingComment.id,
              body: comment
            });
          } else {
            // Create new comment
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: comment
            });
          }

  performance-regression-alert:
    runs-on: ubuntu-latest
    needs: performance-validation
    if: failure() && (github.event_name == 'push' && github.ref == 'refs/heads/main')
    
    steps:
    - name: Create Issue for Performance Regression
      uses: actions/github-script@v6
      with:
        script: |
          const title = `üö® Performance Regression Detected - ${new Date().toISOString().split('T')[0]}`;
          const body = `
          ## Performance Regression Alert
          
          A performance regression has been detected in the main branch.
          
          **Details:**
          - Branch: \`${context.ref}\`
          - Commit: \`${context.sha.substring(0, 7)}\`
          - Workflow Run: [#${context.runNumber}](${context.server_url}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
          
          **Action Required:**
          1. Review the performance validation results in the workflow artifacts
          2. Investigate recent changes that may have caused the regression
          3. Fix the performance issues or revert problematic changes
          4. Re-run the performance validation to confirm fixes
          
          This issue will be automatically closed when performance validation passes again.
          
          /label performance regression urgent
          `;
          
          // Check if there's already an open performance regression issue
          const { data: issues } = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: 'performance,regression',
            state: 'open'
          });
          
          if (issues.length === 0) {
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['performance', 'regression', 'urgent']
            });
          }