UP035 `typing.Dict` is deprecated, use `dict` instead
  --> auto_repair_system.py:22:1
   |
20 | from datetime import datetime
21 | from pathlib import Path
22 | from typing import Any, Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> auto_repair_system.py:22:1
   |
20 | from datetime import datetime
21 | from pathlib import Path
22 | from typing import Any, Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> auto_repair_system.py:22:1
   |
20 | from datetime import datetime
21 | from pathlib import Path
22 | from typing import Any, Dict, List, Optional, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

F841 Local variable `result` is assigned to but never used
  --> auto_repair_system.py:48:13
   |
46 |         # Run the complete UAT
47 |         try:
48 |             result = subprocess.run(
   |             ^^^^^^
49 |                 [sys.executable, "run_complete_uat.py"],
50 |                 cwd=self.project_root,
   |
help: Remove assignment to unused variable `result`

S603 `subprocess` call: check for execution of untrusted input
  --> auto_repair_system.py:48:22
   |
46 |         # Run the complete UAT
47 |         try:
48 |             result = subprocess.run(
   |                      ^^^^^^^^^^^^^^
49 |                 [sys.executable, "run_complete_uat.py"],
50 |                 cwd=self.project_root,
   |

B007 Loop control variable `test_name` not used within loop body
   --> auto_repair_system.py:109:13
    |
107 |         # Check for service method issues
108 |         integration_tests = report.get('integration_tests', {})
109 |         for test_name, test_result in integration_tests.items():
    |             ^^^^^^^^^
110 |             if not test_result.get('passed', True):
111 |                 error_msg = test_result.get('error', '')
    |
help: Rename unused `test_name` to `_test_name`

PERF102 When using only the values of a dict use the `values()` method
   --> auto_repair_system.py:109:39
    |
107 |         # Check for service method issues
108 |         integration_tests = report.get('integration_tests', {})
109 |         for test_name, test_result in integration_tests.items():
    |                                       ^^^^^^^^^^^^^^^^^^^^^^^
110 |             if not test_result.get('passed', True):
111 |                 error_msg = test_result.get('error', '')
    |
help: Replace `.items()` with `.values()`

C901 `fix_api_health` is too complex (12 > 10)
   --> auto_repair_system.py:152:9
    |
150 |             return False
151 |
152 |     def fix_api_health(self) -> bool:
    |         ^^^^^^^^^^^^^^
153 |         """Fix API health check issues."""
154 |         self.log("Fixing API health check issues...")
    |

C901 `fix_missing_method` is too complex (13 > 10)
   --> auto_repair_system.py:277:9
    |
275 |         return False
276 |
277 |     def fix_missing_method(self, class_name: str, method_name: str) -> bool:
    |         ^^^^^^^^^^^^^^^^^^
278 |         """Fix missing methods in service classes."""
279 |         self.log(f"Fixing missing method: {class_name}.{method_name}")
    |

F841 Local variable `indent` is assigned to but never used
   --> auto_repair_system.py:294:25
    |
292 |                     if class_pos > 0:
293 |                         # Find the end of the class
294 |                         indent = "    "
    |                         ^^^^^^
295 |
296 |                         # Add the method before the last method or at the end
    |
help: Remove assignment to unused variable `indent`

W293 Blank line contains whitespace
   --> auto_repair_system.py:300:1
    |
298 |     def create_document(self, title: str, content: str = "", metadata: Optional[Dict] = None) -> Document:
299 |         """Create a new document.
300 |
    | ^^^^^^^^
301 |         AUTONOMOUS REPAIR: Added missing method for UAT compatibility.
302 |         """
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> auto_repair_system.py:305:1
    |
303 |         from datetime import datetime
304 |         import uuid
305 |
    | ^^^^^^^^
306 |         document = Document(
307 |             id=str(uuid.uuid4()),
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> auto_repair_system.py:314:1
    |
312 |             updated_at=datetime.now()
313 |         )
314 |
    | ^^^^^^^^
315 |         # Store in repository if available
316 |         if hasattr(self, 'repository'):
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> auto_repair_system.py:318:1
    |
316 |         if hasattr(self, 'repository'):
317 |             self.repository.create(document)
318 |
    | ^^^^^^^^^^^^
319 |         return document
320 | '''
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> auto_repair_system.py:382:1
    |
380 |     """Start the API server with maximum stability."""
381 |     print("[AUTO-REPAIR] Starting API server with autonomous repair configuration...")
382 |
    | ^^^^
383 |     # Force uvicorn on Windows
384 |     if sys.platform == "win32":
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> auto_repair_system.py:386:1
    |
384 |     if sys.platform == "win32":
385 |         print("[AUTO-REPAIR] Windows detected - using uvicorn for stability")
386 |
    | ^^^^^^^^
387 |     # Configure uvicorn
388 |     config = uvicorn.Config(
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> auto_repair_system.py:397:1
    |
395 |         access_log=True
396 |     )
397 |
    | ^^^^
398 |     server = uvicorn.Server(config)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> auto_repair_system.py:399:1
    |
398 |     server = uvicorn.Server(config)
399 |
    | ^^^^
400 |     try:
401 |         print(f"[AUTO-REPAIR] Server starting on http://0.0.0.0:8000")
    |
help: Remove whitespace from blank line

S103 `os.chmod` setting a permissive mask `0o755` on file or directory
   --> auto_repair_system.py:416:38
    |
414 |         # Make it executable on Unix-like systems
415 |         if sys.platform != 'win32':
416 |             os.chmod(startup_script, 0o755)
    |                                      ^^^^^
417 |
418 |         # Update the main start script to use the repaired version
    |

S105 Possible hardcoded password assigned to: "PASSWORD_RESET"
  --> backend/api/auth/constants.py:14:22
   |
12 |     REFRESH = "refresh"
13 |     # False positive: static token descriptors, not secrets.
14 |     PASSWORD_RESET = "password_reset"  # nosec
   |                      ^^^^^^^^^^^^^^^^
15 |     EMAIL_VERIFICATION = "email_verification"  # nosec
   |

S105 Possible hardcoded password assigned to: "BEARER_TOKEN_SCHEME"
  --> backend/api/auth/constants.py:19:23
   |
18 | # Standard HTTP auth scheme descriptor, not a secret.
19 | BEARER_TOKEN_SCHEME = "Bearer"  # nosec
   |                       ^^^^^^^^
   |

C901 `__call__` is too complex (12 > 10)
  --> backend/api/auth/dependencies.py:45:15
   |
43 |         self.allow_unverified = allow_unverified
44 |
45 |     async def __call__(
   |               ^^^^^^^^
46 |         self,
47 |         request: Request,
   |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/api/auth/migration.py:163:17
    |
161 |                       db_connection.execute(sql)
162 |                       db_connection.commit()
163 | /                 except Exception as e:
164 | |                     # Table might already exist, log and continue
165 | |                     if "already exists" not in str(e).lower():
166 | |                         logger.error(f"Migration statement failed: {str(e)}")
167 | |                         logger.error(f"SQL: {sql[:100]}...")
168 | |                         return False
    | |____________________________________^
169 |
170 |               logger.info("Authentication tables migration completed successfully")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/api/auth/migration.py:201:17
    |
199 |                       db_connection.execute(f"DROP TABLE IF EXISTS {table}")
200 |                       db_connection.commit()
201 | /                 except Exception as e:
202 | |                     logger.error(f"Failed to drop table {table}: {str(e)}")
    | |___________________________________________________________________________^
203 |
204 |               logger.info("Authentication tables rollback completed")
    |

C901 `validate_password_strength` is too complex (13 > 10)
   --> backend/api/auth/password_security.py:145:9
    |
144 |     @classmethod
145 |     def validate_password_strength(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^
146 |         cls, password: str, username: str | None = None
147 |     ) -> tuple[bool, list[str]]:
    |

PERF401 Use `list.extend` to create a transformed list
   --> backend/api/auth/password_security.py:378:13
    |
376 |         all_chars = uppercase + lowercase + digits + special
377 |         for _ in range(length - len(password)):
378 |             password.append(secrets.choice(all_chars))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
379 |
380 |         # Shuffle to avoid predictable patterns
    |
help: Replace for loop with list.extend

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/api/auth/rbac.py:569:13
    |
567 |                   if context and context.get("owner_id") == user.id:
568 |                       return True
569 | /             elif policy.policy_type == "department":
570 | |                 # Check department-based access
571 | |                 if context and context.get("department") == user.department:
    | |____________________________________________________________________________^
572 |                       return True
    |
help: Combine `if` statements using `and`

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> backend/api/auth/rbac.py:605:19
    |
603 |         """Clear all cached permissions for a user."""
604 |         keys_to_remove = [
605 |             k for k in self._permission_cache.keys() if k.startswith(f"{user_id}:")
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
606 |         ]
607 |         for key in keys_to_remove:
    |
help: Remove `.keys()`

PERF401 Use `list.extend` to create a transformed list
   --> backend/api/cors_config.py:213:17
    |
211 |           for origin in origins:
212 |               if any(pattern in origin.lower() for pattern in localhost_patterns):
213 | /                 security_issues.append(
214 | |                     f"Localhost origin '{origin}' should not be used in production"
215 | |                 )
    | |_________________^
216 |
217 |           # Must have at least one origin
    |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
   --> backend/api/cors_config.py:226:17
    |
224 |           for origin in origins:
225 |               if origin.startswith("http://") and not origin.startswith("https://"):
226 | /                 security_issues.append(
227 | |                     f"Origin '{origin}' should use HTTPS in production"
228 | |                 )
    | |_________________^
229 |
230 |           if security_issues:
    |
help: Replace for loop with list.extend

SIM103 Return the negated condition directly
   --> backend/api/cors_config.py:284:5
    |
282 |       # Must contain domain after protocol
283 |       protocol_part = origin.split("://", 1)
284 | /     if len(protocol_part) != 2 or not protocol_part[1]:
285 | |         return False
286 | |
287 | |     return True
    | |_______________^
    |
help: Inline condition

N805 First argument of a method should be named `self`
  --> backend/api/error_handling.py:39:31
   |
37 |     """Enum helper that sets value equal to the member name."""
38 |
39 |     def _generate_next_value_(name, start, count, last_values):
   |                               ^^^^
40 |         return name
   |
help: Rename `name` to `self`

C901 `create_error_response` is too complex (11 > 10)
   --> backend/api/error_handling.py:496:5
    |
496 | def create_error_response(
    |     ^^^^^^^^^^^^^^^^^^^^^
497 |     exception: Union[APIException, HTTPException, Exception],
498 |     request: Request | None = None,
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/api/middleware/error_handling.py:308:13
    |
307 |               # Record error metrics for 4xx and 5xx responses
308 | /             if response.status_code >= 400:
309 | |                 # Try to extract error information from response
310 | |                 if hasattr(response, "body"):
    | |_____________________________________________^
311 |                       try:
312 |                           body = json.loads(response.body.decode())
    |
help: Combine `if` statements using `and`

C401 Unnecessary generator (rewrite as a set comprehension)
   --> backend/api/middleware/rate_limit_monitor.py:228:26
    |
226 |         )
227 |
228 |         unique_ips = len(set(e.client_ip for e in recent_events))
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
229 |
230 |         response_times = [e.response_time for e in recent_events]
    |
help: Rewrite as a set comprehension

C401 Unnecessary generator (rewrite as a set comprehension)
   --> backend/api/middleware/rate_limit_monitor.py:281:21
    |
280 |         # Endpoints accessed
281 |         endpoints = set(e.endpoint for e in events)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
282 |
283 |         # Request pattern
    |
help: Rewrite as a set comprehension

C401 Unnecessary generator (rewrite as a set comprehension)
   --> backend/api/middleware/rate_limit_monitor.py:313:26
    |
311 |         total_requests = len(events)
312 |         rate_limited_requests = sum(1 for e in events if e.status_code == 429)
313 |         unique_ips = len(set(e.client_ip for e in events))
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
314 |
315 |         # Response time stats
    |
help: Rewrite as a set comprehension

C401 Unnecessary generator (rewrite as a set comprehension)
   --> backend/api/middleware/rate_limit_monitor.py:390:25
    |
389 |             # Unique endpoints
390 |             endpoints = set(e.endpoint for e in events)
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
391 |
392 |             # User agents
    |
help: Rewrite as a set comprehension

C401 Unnecessary generator (rewrite as a set comprehension)
   --> backend/api/middleware/rate_limit_monitor.py:393:27
    |
392 |             # User agents
393 |             user_agents = set(e.user_agent for e in events if e.user_agent)
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
394 |
395 |             # Suspicion score (higher = more suspicious)
    |
help: Rewrite as a set comprehension

B007 Loop control variable `endpoint` not used within loop body
   --> backend/api/middleware/rate_limiting.py:296:17
    |
294 |             )
295 |
296 |             for endpoint, rule in self.config.endpoint_limits.items():
    |                 ^^^^^^^^
297 |                 rule.requests = int(rule.requests * multiplier)
    |
help: Rename unused `endpoint` to `_endpoint`

PERF102 When using only the values of a dict use the `values()` method
   --> backend/api/middleware/rate_limiting.py:296:35
    |
294 |             )
295 |
296 |             for endpoint, rule in self.config.endpoint_limits.items():
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
297 |                 rule.requests = int(rule.requests * multiplier)
    |
help: Replace `.items()` with `.values()`

C901 `_set_secure_cookie_attributes` is too complex (11 > 10)
   --> backend/api/middleware/security_headers.py:653:9
    |
651 |         return secrets.token_hex(16)
652 |
653 |     def _set_secure_cookie_attributes(self, response: Response) -> None:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
654 |         """Set secure attributes for cookies."""
655 |         if not self.config.secure_cookies:
    |

B019 Use of `functools.lru_cache` or `functools.cache` on methods can lead to memory leaks
   --> backend/api/production_cors.py:124:5
    |
122 |         self.validation_cache.clear()
123 |
124 |     @lru_cache(maxsize=1000)
    |     ^^^^^^^^^^^^^^^^^^^^^^^^
125 |     def validate_origin(self, origin: str) -> tuple[bool, str]:
126 |         """
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/api/production_cors.py:232:13
    |
230 |               ip = ipaddress.ip_address(ip_str)
231 |
232 | /             if self.security_policy.block_private_ips:
233 | |                 if ip.is_private or ip.is_loopback or ip.is_link_local:
    | |_______________________________________________________________________^
234 |                       return False, f"Private/loopback IP not allowed: {ip}"
    |
help: Combine `if` statements using `and`

SIM105 Use `contextlib.suppress(ValueError)` instead of `try`-`except`-`pass`
   --> backend/api/rate_limit_config.py:154:9
    |
152 |       # Apply specific overrides
153 |       if global_limit := os.getenv("RATE_LIMIT_GLOBAL_LIMIT"):
154 | /         try:
155 | |             base_config.global_ip_limit.requests = int(global_limit)
156 | |         except ValueError:
157 | |             pass
    | |________________^
158 |
159 |       if default_limit := os.getenv("RATE_LIMIT_DEFAULT_LIMIT"):
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(ValueError): ...`

SIM105 Use `contextlib.suppress(ValueError)` instead of `try`-`except`-`pass`
   --> backend/api/rate_limit_config.py:160:9
    |
159 |       if default_limit := os.getenv("RATE_LIMIT_DEFAULT_LIMIT"):
160 | /         try:
161 | |             base_config.default_limit.requests = int(default_limit)
162 | |         except ValueError:
163 | |             pass
    | |________________^
164 |
165 |       if upload_limit := os.getenv("RATE_LIMIT_UPLOAD_LIMIT"):
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(ValueError): ...`

C901 `process_rag_query` is too complex (16 > 10)
  --> backend/api/routes/async_rag.py:76:15
   |
74 |         self.rag_service = rag_service
75 |
76 |     async def process_rag_query(
   |               ^^^^^^^^^^^^^^^^^
77 |         self,
78 |         query: str,
   |

C901 `websocket_rag_endpoint` is too complex (11 > 10)
   --> backend/api/routes/async_rag.py:300:11
    |
299 | @router.websocket("/stream")
300 | async def websocket_rag_endpoint(
    |           ^^^^^^^^^^^^^^^^^^^^^^
301 |     websocket: WebSocket,
302 |     ws_manager: WebSocketManager = Depends(get_websocket_manager),
    |

C901 `upload_document` is too complex (13 > 10)
   --> backend/api/routes/documents.py:454:11
    |
452 |     },
453 | )
454 | async def upload_document(
    |           ^^^^^^^^^^^^^^^
455 |     # File upload (multipart/form-data)
456 |     file: UploadFile = File(..., description="PDF file to upload"),
    |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> backend/api/routes/metrics_websocket.py:83:17
   |
81 |                       data = await self.websocket.receive_text()
82 |                       await self.handle_client_message(json.loads(data))
83 | /                 except json.JSONDecodeError as e:
84 | |                     await self.send_error(f"Invalid JSON: {e}")
   | |_______________________________________________________________^
85 |                   except Exception as e:
86 |                       logger.error(f"Error handling client message: {e}")
   |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/api/routes/metrics_websocket.py:130:17
    |
128 |                       metric_type = MetricType(metric_str.lower())
129 |                       new_subscriptions.add(metric_type)
130 | /                 except ValueError:
131 | |                     await self.send_error(f"Invalid metric type: {metric_str}")
132 | |                     return
    | |__________________________^
133 |
134 |               # Update subscriptions
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/api/routes/metrics_websocket.py:179:21
    |
177 |                           metric_type = MetricType(metric_str.lower())
178 |                           self.subscriptions.discard(metric_type)
179 | /                     except ValueError:
180 | |                         await self.send_error(f"Invalid metric type: {metric_str}")
181 | |                         return
    | |______________________________^
182 |
183 |               # Update global tracking
    |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/api/routes/metrics_websocket.py:332:17
    |
330 |               if self.streaming_task and not self.streaming_task.done():
331 |                   self.streaming_task.cancel()
332 | /                 try:
333 | |                     await self.streaming_task
334 | |                 except asyncio.CancelledError:
335 | |                     pass
    | |________________________^
336 |
337 |               # Unsubscribe from metrics updates
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

B007 Loop control variable `client_id` not used within loop body
   --> backend/api/routes/metrics_websocket.py:452:13
    |
450 |         # Count subscriptions by metric type
451 |         metric_counts = {}
452 |         for client_id, subscriptions in active_subscriptions.items():
    |             ^^^^^^^^^
453 |             stats["total_subscriptions"] += len(subscriptions)
454 |             for metric in subscriptions:
    |
help: Rename unused `client_id` to `_client_id`

PERF102 When using only the values of a dict use the `values()` method
   --> backend/api/routes/metrics_websocket.py:452:41
    |
450 |         # Count subscriptions by metric type
451 |         metric_counts = {}
452 |         for client_id, subscriptions in active_subscriptions.items():
    |                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
453 |             stats["total_subscriptions"] += len(subscriptions)
454 |             for metric in subscriptions:
    |
help: Replace `.items()` with `.values()`

B007 Loop control variable `client_id` not used within loop body
   --> backend/api/routes/metrics_websocket.py:462:13
    |
461 |         # Connections by metric count
462 |         for client_id, subscriptions in active_subscriptions.items():
    |             ^^^^^^^^^
463 |             count = len(subscriptions)
464 |             stats["connections_by_metrics"][count] = (
    |
help: Rename unused `client_id` to `_client_id`

PERF102 When using only the values of a dict use the `values()` method
   --> backend/api/routes/metrics_websocket.py:462:41
    |
461 |         # Connections by metric count
462 |         for client_id, subscriptions in active_subscriptions.items():
    |                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
463 |             count = len(subscriptions)
464 |             stats["connections_by_metrics"][count] = (
    |
help: Replace `.items()` with `.values()`

PERF401 Use a list comprehension to create a transformed list
   --> backend/api/routes/performance_monitoring.py:314:13
    |
312 |           traces_data = []
313 |           for trace in slow_traces:
314 | /             traces_data.append(
315 | |                 {
316 | |                     "trace_id": trace.trace_id,
317 | |                     "trace_type": trace.trace_type.value,
318 | |                     "duration_ms": trace.duration_ms,
319 | |                     "has_errors": trace.has_errors,
320 | |                     "error_count": trace.error_count,
321 | |                     "user_id": trace.user_id,
322 | |                     "session_id": trace.session_id,
323 | |                     "root_operation": trace.root_span.operation_name,
324 | |                     "start_time": trace.root_span.start_time.isoformat(),
325 | |                 }
326 | |             )
    | |_____________^
327 |
328 |           return {"status": "success", "data": traces_data}
    |
help: Replace for loop with list comprehension

PERF401 Use a list comprehension to create a transformed list
   --> backend/api/routes/performance_monitoring.py:346:13
    |
344 |           traces_data = []
345 |           for trace in error_traces:
346 | /             traces_data.append(
347 | |                 {
348 | |                     "trace_id": trace.trace_id,
349 | |                     "trace_type": trace.trace_type.value,
350 | |                     "duration_ms": trace.duration_ms,
351 | |                     "error_count": trace.error_count,
352 | |                     "user_id": trace.user_id,
353 | |                     "session_id": trace.session_id,
354 | |                     "root_operation": trace.root_span.operation_name,
355 | |                     "start_time": trace.root_span.start_time.isoformat(),
356 | |                     "root_error": trace.root_span.error,
357 | |                 }
358 | |             )
    | |_____________^
359 |
360 |           return {"status": "success", "data": traces_data}
    |
help: Replace for loop with list comprehension

PERF401 Use a list comprehension to create a transformed list
   --> backend/api/routes/rate_limit_admin.py:203:13
    |
201 |         results = []
202 |         for ip_data in suspicious_ips[:limit]:
203 |             results.append(SuspiciousIPResponse(**ip_data))
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
204 |
205 |         return results
    |
help: Replace for loop with list comprehension

E712 Avoid equality comparisons to `False`; use `not Role.is_system_role:` for false checks
   --> backend/api/routes/rbac_admin.py:147:30
    |
146 |     if not include_system:
147 |         query = query.filter(Role.is_system_role == False)
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
148 |
149 |     roles = query.order_by(Role.priority, Role.name).all()
    |
help: Replace with `not Role.is_system_role`

PERF401 Use a list comprehension to create a transformed list
   --> backend/api/routes/rbac_admin.py:153:9
    |
151 |       response = []
152 |       for role in roles:
153 | /         response.append(
154 | |             RoleResponse(
155 | |                 id=role.id,
156 | |                 name=role.name,
157 | |                 description=role.description,
158 | |                 is_system_role=role.is_system_role,
159 | |                 priority=role.priority,
160 | |                 permissions=[f"{p.resource}:{p.action}" for p in role.permissions],
161 | |                 user_count=len(role.users),
162 | |                 created_at=role.created_at,
163 | |                 parent_role=role.parent_role.name if role.parent_role else None,
164 | |             )
165 | |         )
    | |_________^
166 |
167 |       logger.info(f"User {current_user.email} listed {len(response)} roles")
    |
help: Replace for loop with list comprehension

PERF401 Use a list comprehension to create a transformed list
   --> backend/api/routes/rbac_admin.py:374:9
    |
372 |       response = []
373 |       for permission in permissions:
374 | /         response.append(
375 | |             PermissionResponse(
376 | |                 id=permission.id,
377 | |                 name=permission.name,
378 | |                 resource=permission.resource,
379 | |                 action=permission.action,
380 | |                 description=permission.description,
381 | |                 is_system_permission=permission.is_system_permission,
382 | |                 role_count=len(permission.roles),
383 | |             )
384 | |         )
    | |_________^
385 |
386 |       return response
    |
help: Replace for loop with list comprehension

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/api/routes/settings.py:252:9
    |
250 |       try:
251 |           # Update API key if provided
252 | /         if request.gemini_api_key is not None:
253 | |             # Don't update if it's a masked value
254 | |             if not request.gemini_api_key.startswith("●"):
    | |__________________________________________________________^
255 |                   settings_manager.set_setting(
256 |                       "gemini_api_key", request.gemini_api_key.strip()
    |
help: Combine `if` statements using `and`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/api/routes/system.py:347:17
    |
345 |                   try:
346 |                       standards.append(ComplianceStandard(std))
347 | /                 except ValueError:
348 | |                     logger.warning(f"Unknown compliance standard: {std}")
    | |_________________________________________________________________________^
349 |
350 |           # Validate all secrets
    |

C901 `detailed_health_check` is too complex (16 > 10)
   --> backend/api/routes/system.py:448:11
    |
447 | @router.get("/health/detailed", response_model=BaseResponse)
448 | async def detailed_health_check(
    |           ^^^^^^^^^^^^^^^^^^^^^
449 |     db: DatabaseConnection = Depends(get_db),
450 |     rag_service: EnhancedRAGService = Depends(get_enhanced_rag),
    |

C901 `performance_health_check` is too complex (13 > 10)
   --> backend/api/routes/system.py:791:11
    |
790 | @router.get("/health/performance", response_model=BaseResponse)
791 | async def performance_health_check():
    |           ^^^^^^^^^^^^^^^^^^^^^^^^
792 |     """Real-time performance metrics and health indicators."""
793 |     try:
    |

C901 `secure_endpoint` is too complex (14 > 10)
  --> backend/api/security/endpoint_protection.py:36:5
   |
36 | def secure_endpoint(
   |     ^^^^^^^^^^^^^^^
37 |     resource: str,
38 |     action: str,
   |

C901 `decorator` is too complex (13 > 10)
  --> backend/api/security/endpoint_protection.py:61:9
   |
59 |     """
60 |
61 |     def decorator(func: AsyncEndpoint) -> AsyncEndpoint:
   |         ^^^^^^^^^
62 |         @wraps(func)
63 |         async def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:
   |

C901 `wrapper` is too complex (12 > 10)
  --> backend/api/security/endpoint_protection.py:63:19
   |
61 |     def decorator(func: AsyncEndpoint) -> AsyncEndpoint:
62 |         @wraps(func)
63 |         async def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:
   |                   ^^^^^^^
64 |             # Extract request if available
65 |             request = kwargs.get("request")
   |

E722 Do not use bare `except`
  --> backend/api/security/endpoint_protection.py:78:29
   |
76 | …                         user = await get_current_user(auth)
77 | …                         kwargs["current_user"] = user
78 | …                     except:
   |                       ^^^^^^
79 | …                         raise HTTPException(
80 | …                             status_code=status.HTTP_401_UNAUTHORIZED,
   |

E722 Do not use bare `except`
   --> backend/api/security/endpoint_protection.py:107:21
    |
105 |                         db = get_db()
106 |                         kwargs["db"] = db
107 |                     except:
    |                     ^^^^^^
108 |                         raise HTTPException(
109 |                             status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/api/security/endpoint_protection.py:611:9
    |
609 |       masked_data = data.copy()
610 |       for field in fields:
611 | /         if field in masked_data:
612 | |             if isinstance(masked_data[field], str):
    | |___________________________________________________^
613 |                   # Keep first and last 2 characters
614 |                   value = masked_data[field]
    |
help: Combine `if` statements using `and`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/api/security/ip_whitelist.py:231:13
    |
229 |                   )
230 |                   self.ip_rules.append(rule)
231 | /             except ValueError as e:
232 | |                 logger.error(f"Invalid IP range in production config: {ip_range} - {e}")
    | |________________________________________________________________________________________^
233 |
234 |           # Load blocked IP ranges
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/api/security/ip_whitelist.py:246:13
    |
244 |                   )
245 |                   self.ip_rules.append(rule)
246 | /             except ValueError as e:
247 | |                 logger.error(f"Invalid IP range in production config: {ip_range} - {e}")
    | |________________________________________________________________________________________^
248 |
249 |           # Load geo-blocking rules
    |

C901 `check_ip_access` is too complex (11 > 10)
   --> backend/api/security/ip_whitelist.py:343:15
    |
341 |             self.ip_cache.clear()
342 |
343 |     async def check_ip_access(
    |               ^^^^^^^^^^^^^^^
344 |         self, ip_address: str, request: Request | None = None
345 |     ) -> tuple[IPAccessAction, str]:
    |

C901 `_validate_signature` is too complex (16 > 10)
   --> backend/api/security/request_signing.py:445:15
    |
443 |             )
444 |
445 |     async def _validate_signature(
    |               ^^^^^^^^^^^^^^^^^^^
446 |         self, request: Request, signature_info: RequestSignature
447 |     ) -> SignatureValidationResult:
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/api/streaming_models.py:187:9
    |
185 |       def validate_expected_hash(cls, v: str | None) -> str | None:
186 |           """Validate SHA-256 hash format."""
187 | /         if v is not None:
188 | |             if not re.match(r"^[a-fA-F0-9]{64}$", v):
    | |_____________________________________________________^
189 |                   raise ValueError("Invalid SHA-256 hash format")
190 |           return v
    |
help: Combine `if` statements using `and`

B007 Loop control variable `room_name` not used within loop body
   --> backend/api/websocket_manager.py:121:17
    |
119 |             del self.active_connections[client_id]
120 |             # Remove from all rooms
121 |             for room_name, members in self.rooms.items():
    |                 ^^^^^^^^^
122 |                 if client_id in members:
123 |                     members.remove(client_id)
    |
help: Rename unused `room_name` to `_room_name`

PERF102 When using only the values of a dict use the `values()` method
   --> backend/api/websocket_manager.py:121:39
    |
119 |             del self.active_connections[client_id]
120 |             # Remove from all rooms
121 |             for room_name, members in self.rooms.items():
    |                                       ^^^^^^^^^^^^^^^^
122 |                 if client_id in members:
123 |                     members.remove(client_id)
    |
help: Replace `.items()` with `.values()`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/api/websocket_manager.py:153:13
    |
151 |               try:
152 |                   await websocket.send_text(message)
153 | /             except Exception as e:
154 | |                 logger.error(f"Failed to broadcast to {client_id}: {e}")
155 | |                 disconnected.append(client_id)
    | |______________________________________________^
156 |           # Clean up broken connections
157 |           for client_id in disconnected:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/api/websocket_manager.py:374:13
    |
372 |                       logger.debug(f"Cleaned up {len(tasks_to_remove)} old RAG tasks")
373 |
374 | /             except asyncio.CancelledError:
375 | |                 break
    | |_____________________^
376 |               except Exception as e:
377 |                   logger.error(f"Error in RAG task cleanup: {e}")
    |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/api/websocket_manager.py:786:13
    |
784 |           if self._cleanup_task and not self._cleanup_task.done():
785 |               self._cleanup_task.cancel()
786 | /             try:
787 | |                 await self._cleanup_task
788 | |             except asyncio.CancelledError:
789 | |                 pass
    | |____________________^
790 |
791 |           # Cancel all RAG tasks
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF401 Use `list.extend` to create a transformed list
   --> backend/config/environment.py:124:17
    |
122 |           for indicator in dev_indicators:
123 |               if indicator in cors_origins.lower():
124 | /                 issues.append(
125 | |                     f"CORS origins contain development indicator '{indicator}' in production"
126 | |                 )
    | |_________________^
127 |
128 |       # Development environment checks
    |
help: Replace for loop with list.extend

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/config/redis_cluster.py:340:13
    |
338 |                   await self._update_connection_stats()
339 |                   await asyncio.sleep(self.pool_config.health_check_interval)
340 | /             except Exception as e:
341 | |                 logger.error(f"Health monitor error: {e}")
342 | |                 await asyncio.sleep(self.pool_config.health_check_interval)
    | |___________________________________________________________________________^
343 |
344 |       async def _check_node_health(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/config/redis_cluster.py:359:17
    |
357 |                       self._health_status[f"{node.host}:{node.port}"] = True
358 |                       await client.aclose()
359 | /                 except Exception:
360 | |                     self._health_status[f"{node.host}:{node.port}"] = False
    | |___________________________________________________________________________^
361 |           else:
362 |               # For standalone/sentinel, check primary connection
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/config/redis_cluster.py:412:13
    |
410 |                   return self._deserialize(value)
411 |
412 | /             except (ConnectionError, TimeoutError) as e:
413 | |                 logger.warning(f"Redis get failed (attempt {attempt + 1}): {e}")
414 | |                 if attempt == 2:  # Last attempt
415 | |                     await self._handle_connection_error()
416 | |                     return default
417 | |                 await asyncio.sleep(0.1 * (attempt + 1))
    | |________________________________________________________^
418 |               except Exception as e:
419 |                   logger.error(f"Redis get error for key {key}: {e}")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/config/redis_cluster.py:453:13
    |
451 |                   return bool(result)
452 |
453 | /             except (ConnectionError, TimeoutError) as e:
454 | |                 logger.warning(f"Redis set failed (attempt {attempt + 1}): {e}")
455 | |                 if attempt == 2:  # Last attempt
456 | |                     await self._handle_connection_error()
457 | |                     return False
458 | |                 await asyncio.sleep(0.1 * (attempt + 1))
    | |________________________________________________________^
459 |               except Exception as e:
460 |                   logger.error(f"Redis set error for key {key}: {e}")
    |

N805 First argument of a method should be named `self`
  --> backend/config/secrets_integration.py:33:31
   |
31 |     """Classifies the different secret use-cases."""
32 |
33 |     def _generate_next_value_(name, start, count, last_values):
   |                               ^^^^
34 |         return name.lower()
   |
help: Rename `name` to `self`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/config/secrets_integration.py:247:13
    |
245 |                       raise ValueError(f"Required secret missing: {secret_def.key}")
246 |
247 | /             except Exception as e:
248 | |                 logger.error(f"Failed to load secret {secret_def.key}: {e}")
249 | |                 if secret_def.required:
250 | |                     raise
    | |_________________________^
251 |
252 |           # Store decrypted secrets (in production, keep encrypted until needed)
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/config/secrets_integration.py:292:9
    |
291 |           # Generate secure secret if missing and not required
292 | /         if not secret_def.required and not secret_value:
293 | |             if secret_def.secret_type in {
294 | |                 SecretType.JWT_SECRET,
295 | |                 SecretType.ENCRYPTION_KEY,
296 | |                 SecretType.WEBHOOK_SECRET,
297 | |             }:
    | |______________^
298 |                   secret_value = await self._generate_secret(secret_def)
299 |                   if secret_value:
    |
help: Combine `if` statements using `and`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/config/secrets_integration.py:557:13
    |
555 |                   await asyncio.sleep(3600)
556 |
557 | /             except Exception as e:
558 | |                 logger.error(f"Error in rotation monitor: {e}")
559 | |                 await asyncio.sleep(300)  # Wait 5 minutes on error
    | |________________________________________^
560 |
561 |       async def _access_monitor(self):
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/config/secrets_integration.py:590:13
    |
588 |                   await asyncio.sleep(600)
589 |
590 | /             except Exception as e:
591 | |                 logger.error(f"Error in access monitor: {e}")
592 | |                 await asyncio.sleep(300)
    | |________________________________________^
593 |
594 |       def _track_secret_access(self, secret_key: str):
    |

PERF403 Use a dictionary comprehension instead of a for-loop
   --> backend/config/secrets_integration.py:671:13
    |
669 |         # Add secrets to configuration
670 |         for secret_key, secret_value in self.decrypted_secrets.items():
671 |             config[secret_key] = secret_value
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
672 |
673 |         # Add derived configurations
    |
help: Replace for loop with dict comprehension

SIM103 Return the condition `parsed.netloc` directly
  --> backend/config/validation.py:53:13
   |
52 |               # Must have netloc (domain)
53 | /             if not parsed.netloc:
54 | |                 return False
55 | |
56 | |             return True
   | |_______________________^
57 |
58 |           except Exception:
   |
help: Replace with `return parsed.netloc`

SIM103 Return the condition `not origin.endswith("/")` directly
  --> backend/config/validation.py:80:9
   |
79 |           # Should not end with slash
80 | /         if origin.endswith("/"):
81 | |             return False
82 | |
83 | |         return True
   | |___________________^
84 |
85 |       @staticmethod
   |
help: Replace with `return not origin.endswith("/")`

SIM110 Use `return all(pattern not in secret_lower for pattern in weak_patterns)` instead of `for` loop
   --> backend/config/validation.py:191:9
    |
190 |           secret_lower = secret.lower()
191 | /         for pattern in weak_patterns:
192 | |             if pattern in secret_lower:
193 | |                 return False
194 | |
195 | |         return True
    | |___________________^
196 |
197 |       @staticmethod
    |
help: Replace with `return all(pattern not in secret_lower for pattern in weak_patterns)`

SIM110 Use `return all(pattern not in api_key_lower for pattern in placeholder_patterns)` instead of `for` loop
   --> backend/config/validation.py:237:9
    |
236 |           api_key_lower = api_key.lower()
237 | /         for pattern in placeholder_patterns:
238 | |             if pattern in api_key_lower:
239 | |                 return False
240 | |
241 | |         return True
    | |___________________^
    |
help: Replace with `return all(pattern not in api_key_lower for pattern in placeholder_patterns)`

C901 `validate_production_security` is too complex (11 > 10)
   --> backend/config/validation.py:248:9
    |
247 |     @staticmethod
248 |     def validate_production_security(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
249 |         config: dict[str, Any], environment: str
250 |     ) -> list[str]:
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/config/validation.py:333:21
    |
331 |                   # Check if key name suggests it's sensitive
332 |                   if any(sensitive in key.lower() for sensitive in sensitive_keys):
333 | /                     if isinstance(value, str):
334 | |                         # Check if value looks like a hardcoded secret
335 | |                         if (
336 | |                             len(value) > 10
337 | |                             and not value.startswith("${")  # Environment variable
338 | |                             and not value.startswith("$(")
339 | |                         ):  # Command substitution
    | |__________________________^
340 |                               issues.append(
341 |                                   f"Potential hardcoded secret at {current_path}"
    |
help: Combine `if` statements using `and`

SIM108 Use ternary operator `auth = f":{self.password.get_secret_value()}@" if self.password else ""` instead of `if`-`else`-block
   --> backend/core/enhanced_config.py:127:9
    |
125 |           scheme = "rediss" if self.ssl else "redis"
126 |
127 | /         if self.password:
128 | |             auth = f":{self.password.get_secret_value()}@"
129 | |         else:
130 | |             auth = ""
    | |_____________________^
131 |
132 |           return f"{scheme}://{auth}{self.host}:{self.port}/{self.database}"
    |
help: Replace `if`-`else`-block with `auth = f":{self.password.get_secret_value()}@" if self.password else ""`

N805 First argument of a method should be named `self`
   --> backend/core/enhanced_config.py:332:30
    |
331 |     @field_validator("environment")
332 |     def validate_environment(cls, v):
    |                              ^^^
333 |         if isinstance(v, str):
334 |             return Environment(v)
    |
help: Rename `cls` to `self`

C901 `from_env` is too complex (13 > 10)
   --> backend/core/enhanced_config.py:338:9
    |
337 |     @classmethod
338 |     def from_env(
    |         ^^^^^^^^
339 |         cls, secrets_manager: SecretsManager | None = None
340 |     ) -> "ApplicationConfig":
    |

S105 Possible hardcoded password assigned to: "SMTP_PASSWORD"
  --> backend/core/secrets.py:34:21
   |
32 |     JWT_PUBLIC_KEY = "jwt_public_key"
33 |     REDIS_URL = "redis_url"
34 |     SMTP_PASSWORD = "smtp_password"
   |                     ^^^^^^^^^^^^^^^
35 |     ENCRYPTION_KEY = "encryption_key"
36 |     OAUTH_SECRET = "oauth_secret"
   |

S105 Possible hardcoded password assigned to: "OAUTH_SECRET"
  --> backend/core/secrets.py:36:20
   |
34 |     SMTP_PASSWORD = "smtp_password"
35 |     ENCRYPTION_KEY = "encryption_key"
36 |     OAUTH_SECRET = "oauth_secret"
   |                    ^^^^^^^^^^^^^^
37 |     WEBHOOK_SECRET = "webhook_secret"
38 |     SIGNING_KEY = "signing_key"
   |

S105 Possible hardcoded password assigned to: "WEBHOOK_SECRET"
  --> backend/core/secrets.py:37:22
   |
35 |     ENCRYPTION_KEY = "encryption_key"
36 |     OAUTH_SECRET = "oauth_secret"
37 |     WEBHOOK_SECRET = "webhook_secret"
   |                      ^^^^^^^^^^^^^^^^
38 |     SIGNING_KEY = "signing_key"
   |

N805 First argument of a method should be named `self`
   --> backend/core/secrets.py:111:30
    |
110 |     @field_validator("environment")
111 |     def validate_environment(cls, v):
    |                              ^^^
112 |         allowed = ["development", "staging", "production", "test"]
113 |         if v not in allowed:
    |
help: Rename `cls` to `self`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/core/secrets.py:960:13
    |
958 |               self._audit_log_operation("set", key, success, self.config.primary_provider)
959 |
960 | /             if success:
961 | |                 # Clear cache for this key
962 | |                 if key in self._cache:
    | |______________________________________^
963 |                       del self._cache[key]
    |
help: Combine `if` statements using `and`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/core/secrets.py:990:13
    |
988 |               )
989 |
990 | /             if success:
991 | |                 # Clear cache for this key
992 | |                 if key in self._cache:
    | |______________________________________^
993 |                       del self._cache[key]
    |
help: Combine `if` statements using `and`

SIM102 Use a single `if` statement instead of nested `if` statements
    --> backend/core/secrets.py:1015:13
     |
1014 |           for provider_type, provider in self._providers.items():
1015 | /             if provider.health_check():
1016 | |                 if provider.delete_secret(key):
     | |_______________________________________________^
1017 |                       deleted = True
1018 |                       self._audit_log_operation("delete", key, True, provider_type)
     |
help: Combine `if` statements using `and`

B007 Loop control variable `provider_type` not used within loop body
    --> backend/core/secrets.py:1043:13
     |
1041 |         all_secrets = set()
1042 |
1043 |         for provider_type, provider in self._providers.items():
     |             ^^^^^^^^^^^^^
1044 |             if provider.health_check():
1045 |                 secrets = provider.list_secrets(prefix)
     |
help: Rename unused `provider_type` to `_provider_type`

PERF102 When using only the values of a dict use the `values()` method
    --> backend/core/secrets.py:1043:40
     |
1041 |         all_secrets = set()
1042 |
1043 |         for provider_type, provider in self._providers.items():
     |                                        ^^^^^^^^^^^^^^^^^^^^^
1044 |             if provider.health_check():
1045 |                 secrets = provider.list_secrets(prefix)
     |
help: Replace `.items()` with `.values()`

C414 Unnecessary `list()` call within `sorted()`
    --> backend/core/secrets.py:1048:16
     |
1046 |                 all_secrets.update(secrets)
1047 |
1048 |         return sorted(list(all_secrets))
     |                ^^^^^^^^^^^^^^^^^^^^^^^^^
1049 |
1050 |     def check_rotation_needed(self) -> list[tuple[str, SecretMetadata]]:
     |
help: Remove the inner `list()` call

E741 Ambiguous variable name: `l`
    --> backend/core/secrets.py:1137:23
     |
1135 |         if start_time:
1136 |             logs = [
1137 |                 l for l in logs if datetime.fromisoformat(l["timestamp"]) >= start_time
     |                       ^
1138 |             ]
     |

E741 Ambiguous variable name: `l`
    --> backend/core/secrets.py:1142:23
     |
1140 |         if end_time:
1141 |             logs = [
1142 |                 l for l in logs if datetime.fromisoformat(l["timestamp"]) <= end_time
     |                       ^
1143 |             ]
     |

E741 Ambiguous variable name: `l`
    --> backend/core/secrets.py:1146:27
     |
1145 |         if operation:
1146 |             logs = [l for l in logs if l["operation"] == operation]
     |                           ^
1147 |
1148 |         return logs
     |

B007 Loop control variable `secret_type` not used within loop body
   --> backend/core/secrets_migration.py:100:34
    |
 98 |         ]
 99 |
100 |         for env_var, secret_key, secret_type in secret_env_vars:
    |                                  ^^^^^^^^^^^
101 |             value = os.getenv(env_var)
102 |             if value:
    |
help: Rename unused `secret_type` to `_secret_type`

C901 `_determine_secret_type` is too complex (11 > 10)
   --> backend/core/secrets_migration.py:274:9
    |
272 |         return results
273 |
274 |     def _determine_secret_type(self, key: str) -> SecretType:
    |         ^^^^^^^^^^^^^^^^^^^^^^
275 |         """Determine the type of secret based on the key name."""
276 |         key_lower = key.lower()
    |

C901 `cleanup_old_secrets` is too complex (12 > 10)
   --> backend/core/secrets_migration.py:301:9
    |
299 |             return SecretType.API_KEY  # Default
300 |
301 |     def cleanup_old_secrets(self, secrets: dict[str, tuple[str, str]]) -> None:
    |         ^^^^^^^^^^^^^^^^^^^
302 |         """
303 |         Clean up old secret storage locations after successful migration.
    |

B007 Loop control variable `value` not used within loop body
   --> backend/core/secrets_migration.py:323:26
    |
321 |         cleaned = []
322 |
323 |         for secret_key, (value, source) in secrets.items():
    |                          ^^^^^
324 |             # Only clean up if successfully migrated
325 |             if secret_key not in [m["key"] for m in self.migration_report["migrated"]]:
    |
help: Rename unused `value` to `_value`

PERF401 Use `list.extend` to create a transformed list
   --> backend/core/secrets_migration.py:397:17
    |
395 |               report.append("-" * 30)
396 |               for item in self.migration_report["migrated"]:
397 | /                 report.append(
398 | |                     f"  ✓ {item['key']} ({item['type']}) from {item['source']}"
399 | |                 )
    | |_________________^
400 |               report.append("")
    |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
   --> backend/core/secrets_migration.py:406:17
    |
404 |               report.append("-" * 30)
405 |               for item in self.migration_report["failed"]:
406 | /                 report.append(
407 | |                     f"  ✗ {item['key']} from {item['source']}: {item['error']}"
408 | |                 )
    | |_________________^
409 |               report.append("")
    |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
   --> backend/core/secrets_migration.py:415:17
    |
413 |               report.append("-" * 30)
414 |               for item in self.migration_report["skipped"]:
415 | /                 report.append(
416 | |                     f"  - {item['key']} from {item['source']}: {item['reason']}"
417 | |                 )
    | |_________________^
418 |               report.append("")
    |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
   --> backend/core/secrets_migration.py:424:17
    |
422 |             report.append("-" * 30)
423 |             for warning in self.migration_report["warnings"]:
424 |                 report.append(f"  ⚠ {warning}")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
425 |             report.append("")
    |
help: Replace for loop with list.extend

S608 Possible SQL injection vector through string-based query construction
   --> backend/database/postgresql_config.py:359:36
    |
358 |                 # Count records
359 |                 count_query = text(f"SELECT COUNT(*) FROM {table_name}")
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
360 |                 total_records = sqlite_session.execute(count_query).scalar()
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/database/postgresql_config.py:370:25
    |
368 |                       # Read batch from SQLite
369 |                       select_query = text(
370 | /                         f"SELECT * FROM {table_name} "
371 | |                         f"LIMIT {self.batch_size} OFFSET {offset}"
    | |__________________________________________________________________^
372 |                       )
373 |                       rows = sqlite_session.execute(select_query).fetchall()
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/database/postgresql_config.py:423:26
    |
421 |                 # Count records in both databases
422 |                 sqlite_count = sqlite_session.execute(
423 |                     text(f"SELECT COUNT(*) FROM {table_name}")
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
424 |                 ).scalar()
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/database/postgresql_config.py:427:26
    |
426 |                 postgres_count = postgres_session.execute(
427 |                     text(f"SELECT COUNT(*) FROM {table_name}")
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
428 |                 ).scalar()
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/database/postgresql_config.py:503:13
    |
501 |           # Use PostgreSQL COPY for better performance
502 |           insert_query = text(
503 | /             f"INSERT INTO {table_name} ({','.join(row_dicts[0].keys())}) "
504 | |             f"VALUES ({','.join([':' + k for k in row_dicts[0].keys()])})"
    | |__________________________________________________________________________^
505 |           )
    |

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> backend/database/postgresql_config.py:504:46
    |
502 |         insert_query = text(
503 |             f"INSERT INTO {table_name} ({','.join(row_dicts[0].keys())}) "
504 |             f"VALUES ({','.join([':' + k for k in row_dicts[0].keys()])})"
    |                                              ^^^^^^^^^^^^^^^^^^^^^^^^
505 |         )
    |
help: Remove `.keys()`

S608 Possible SQL injection vector through string-based query construction
   --> backend/database/postgresql_config.py:526:26
    |
524 |                 # Get max value
525 |                 max_value = session.execute(
526 |                     text(f"SELECT MAX({column_name}) FROM {table_name}")
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
527 |                 ).scalar()
    |

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
   --> backend/database/postgresql_config.py:628:13
    |
626 |           with self.engine.connect() as conn:
627 |               # Enable pg_stat_statements if not already enabled
628 | /             try:
629 | |                 conn.execute(text("CREATE EXTENSION IF NOT EXISTS pg_stat_statements"))
630 | |             except:
631 | |                 pass
    | |____________________^
632 |
633 |               # Get slow queries
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
   --> backend/database/postgresql_config.py:630:13
    |
628 |             try:
629 |                 conn.execute(text("CREATE EXTENSION IF NOT EXISTS pg_stat_statements"))
630 |             except:
    |             ^^^^^^
631 |                 pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> backend/database/postgresql_config.py:630:13
    |
628 |               try:
629 |                   conn.execute(text("CREATE EXTENSION IF NOT EXISTS pg_stat_statements"))
630 | /             except:
631 | |                 pass
    | |____________________^
632 |
633 |               # Get slow queries
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/database/production_config.py:219:13
    |
217 |                   logger.info(f"Read replica engine {i} created: {replica_url[:30]}...")
218 |
219 | /             except Exception as e:
220 | |                 logger.error(f"Failed to create read replica {i}: {e}")
    | |_______________________________________________________________________^
221 |                   # Continue with other replicas
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/database/production_config.py:321:13
    |
319 |                   await asyncio.sleep(30)  # Update every 30 seconds
320 |
321 | /             except Exception as e:
322 | |                 logger.error(f"Metrics update failed: {e}")
323 | |                 await asyncio.sleep(60)  # Wait longer on error
    | |_______________________________________^
324 |
325 |       async def _test_connections(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/database/production_config.py:344:13
    |
342 |                       await result.scalar()
343 |                       logger.info(f"Read replica {i} connection successful")
344 | /             except Exception as e:
345 | |                 logger.error(f"Read replica {i} connection failed: {e}")
    | |________________________________________________________________________^
346 |                   # Don't fail initialization for read replica failures
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> backend/database/production_config.py:408:16
    |
406 |             import random
407 |
408 |             if random.random() < self.performance_config.read_weight:
    |                ^^^^^^^^^^^^^^^
409 |                 return random.choice(self.read_engines)
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> backend/database/production_config.py:409:24
    |
408 |             if random.random() < self.performance_config.read_weight:
409 |                 return random.choice(self.read_engines)
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
410 |
411 |         return self.master_engine
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/database/production_config.py:523:17
    |
521 |                           }
522 |                       )
523 | /                 except Exception as e:
524 | |                     replica_health.append(
525 | |                         {"replica_id": i, "status": "unhealthy", "error": str(e)}
526 | |                     )
527 | |                     health_status["status"] = "degraded"
    | |________________________________________________________^
528 |
529 |               health_status["connections"]["replicas"] = replica_health
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/database/production_config.py:627:17
    |
625 |                       await read_engine.dispose()
626 |                       logger.info(f"Read replica {i} engine closed")
627 | /                 except Exception as e:
628 | |                     logger.error(f"Error closing read replica {i}: {e}")
    | |________________________________________________________________________^
629 |
630 |               logger.info("All database connections closed")
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/database/query_optimizer.py:185:25
    |
183 |                 try:
184 |                     count_result = self.db.fetch_one(
185 |                         f"SELECT COUNT(*) as count FROM {table_name}"
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
186 |                     )
187 |                     self._table_statistics[table_name] = {
    |

E722 Do not use bare `except`
   --> backend/database/query_optimizer.py:190:17
    |
188 |                         "row_count": count_result["count"] if count_result else 0
189 |                     }
190 |                 except:
    |                 ^^^^^^
191 |                     self._table_statistics[table_name] = {"row_count": 0}
    |

E722 Do not use bare `except`
   --> backend/database/query_optimizer.py:271:9
    |
269 |             plan_rows = self.db.fetch_all(f"EXPLAIN QUERY PLAN {query}")
270 |             return [dict(row) for row in plan_rows]
271 |         except:
    |         ^^^^^^
272 |             return []
    |

C401 Unnecessary generator (rewrite as a set comprehension)
   --> backend/database/query_optimizer.py:455:29
    |
453 |         for index_info in self._index_info[table_name]:
454 |             # Calculate match score
455 |             index_columns = set(col.lower() for col in index_info["columns"])
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
456 |             matching_columns = where_columns.intersection(index_columns)
    |
help: Rewrite as a set comprehension

PERF401 Use a list comprehension to create a transformed list
   --> backend/database/query_optimizer.py:587:17
    |
585 |           for pattern in function_patterns:
586 |               if re.search(pattern, query_lower):
587 | /                 issues_found.append(
588 | |                     "Function call in WHERE clause prevents index usage"
589 | |                 )
    | |_________________^
590 |
591 |           # Look for LIKE with leading wildcard
    |
help: Replace for loop with list comprehension

C901 `main` is too complex (11 > 10)
   --> backend/database/query_optimizer.py:699:5
    |
699 | def main():
    |     ^^^^
700 |     """CLI interface for the Dynamic Query Optimizer."""
701 |     import argparse
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/database/read_write_splitter.py:213:13
    |
211 |                   self._check_endpoint_health()
212 |                   self._check_replication_lag()
213 | /             except Exception as e:
214 | |                 logger.error(f"Health monitoring error: {e}")
    | |_____________________________________________________________^
215 |
216 |       def _check_endpoint_health(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/database/read_write_splitter.py:234:13
    |
232 |                       logger.warning(f"Endpoint {endpoint_id} failed health check")
233 |
234 | /             except Exception as e:
235 | |                 endpoint.is_healthy = False
236 | |                 endpoint.last_health_check = time.time()
237 | |                 logger.error(f"Health check failed for {endpoint_id}: {e}")
    | |___________________________________________________________________________^
238 |
239 |       def _check_replication_lag(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/database/read_write_splitter.py:663:17
    |
661 |                   try:
662 |                       connection.close_all_connections()
663 | /                 except Exception as e:
664 | |                     logger.warning(f"Error closing connections for {endpoint_id}: {e}")
    | |_______________________________________________________________________________________^
665 |
666 |           logger.info("Read/Write splitter shutdown complete")
    |

E722 Do not use bare `except`
   --> backend/database/read_write_splitter.py:706:13
    |
704 |                 splitter.execute_query("CREATE TEMP TABLE test_table (id INTEGER)")
705 |                 print("Write query executed successfully")
706 |             except:
    |             ^^^^^^
707 |                 print("Write query test skipped (read-only)")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/database/sharding_manager.py:498:13
    |
496 |                   self._check_shard_health()
497 |                   self._update_shard_statistics()
498 | /             except Exception as e:
499 | |                 logger.error(f"Health monitor error: {e}")
    | |__________________________________________________________^
500 |
501 |       def _rebalancer_worker(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/database/sharding_manager.py:507:13
    |
505 |                   if self.enable_auto_migration:
506 |                       self._check_rebalancing_needed()
507 | /             except Exception as e:
508 | |                 logger.error(f"Rebalancer error: {e}")
    | |______________________________________________________^
509 |
510 |       def _check_shard_health(self) -> None:
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/database/sharding_manager.py:916:51
    |
915 |                 # Get all data from source
916 |                 data_rows = source_conn.fetch_all(f"SELECT * FROM {table_name}")
    |                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
917 |
918 |                 # Redistribute data to appropriate shards
    |

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> backend/database/sharding_manager.py:921:24
    |
919 |                 for row in data_rows:
920 |                     # Extract shard key from row
921 |                     if self.config.shard_key.column_name in row.keys():
    |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
922 |                         key_value = row[self.config.shard_key.column_name]
923 |                         target_shard_id = self._find_shard_for_key(key_value)
    |
help: Remove `.keys()`

S608 Possible SQL injection vector through string-based query construction
   --> backend/database/sharding_manager.py:934:48
    |
932 |                                   values = [row[col] for col in columns]
933 |
934 |                                   insert_query = f"""
    |  ________________________________________________^
935 | |                                     INSERT OR REPLACE INTO {table_name}
936 | |                                     ({', '.join(columns)}) VALUES ({placeholders})
937 | |                                 """
    | |___________________________________^
938 |
939 |                                   target_conn.execute(insert_query, tuple(values))
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/database/sharding_manager.py:979:37
    |
977 | …                     table_name = table_row["name"]
978 | …                     count_result = connection.fetch_one(
979 | …                         f"SELECT COUNT(*) as count FROM {table_name}"
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
980 | …                     )
981 | …                     if count_result:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
    --> backend/database/sharding_manager.py:1107:13
     |
1105 |                   self.shard_connections[shard_id].close_all_connections()
1106 |                   del self.shard_connections[shard_id]
1107 | /             except Exception as e:
1108 | |                 logger.warning(f"Error closing connection for shard {shard_id}: {e}")
     | |_____________________________________________________________________________________^
1109 |
1110 |           for shard_id in list(self.shard_pools.keys()):
     |

PERF203 `try`-`except` within a loop incurs performance overhead
    --> backend/database/sharding_manager.py:1114:13
     |
1112 |                   self.shard_pools[shard_id].shutdown()
1113 |                   del self.shard_pools[shard_id]
1114 | /             except Exception as e:
1115 | |                 logger.warning(f"Error shutting down pool for shard {shard_id}: {e}")
     | |_____________________________________________________________________________________^
1116 |
1117 |           logger.info("Sharding manager shutdown complete")
     |

PERF203 `try`-`except` within a loop incurs performance overhead
    --> backend/database/sharding_manager.py:1181:17
     |
1179 |                       target_shards = shard_manager.route_query(query, params)
1180 |                       print(f"Query: {query[:50]}... -> Shards: {target_shards}")
1181 | /                 except Exception as e:
1182 | |                     print(f"Query routing failed: {e}")
     | |_______________________________________________________^
1183 |
1184 |           if args.stats:
     |

SIM103 Return the negated condition directly
   --> backend/middleware/cache_optimization_middleware.py:160:9
    |
158 |           path = str(request.url.path)
159 |           route_config = self.config.route_configs.get(path)
160 | /         if route_config and not route_config.get("enabled", True):
161 | |             return False
162 | |
163 | |         return True
    | |___________________^
164 |
165 |       def should_cache_response(self, response: Response) -> bool:
    |
help: Inline condition

SIM103 Return the negated condition directly
   --> backend/middleware/cache_optimization_middleware.py:178:9
    |
176 |           # Check cache control headers
177 |           cache_control = response.headers.get("cache-control", "")
178 | /         if "no-cache" in cache_control or "no-store" in cache_control:
179 | |             return False
180 | |
181 | |         return True
    | |___________________^
    |
help: Inline condition

E722 Do not use bare `except`
   --> backend/middleware/cache_optimization_middleware.py:459:13
    |
457 |                 # Would decode JWT and extract user_id
458 |                 return f"token_{hashlib.sha256(token.encode()).hexdigest()[:8]}"
459 |             except:
    |             ^^^^^^
460 |                 pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> backend/middleware/cache_optimization_middleware.py:459:13
    |
457 |                   # Would decode JWT and extract user_id
458 |                   return f"token_{hashlib.sha256(token.encode()).hexdigest()[:8]}"
459 | /             except:
460 | |                 pass
    | |____________________^
461 |
462 |           # Try to get from session
    |

B023 Function definition does not bind loop variable `path`
   --> backend/middleware/cache_optimization_middleware.py:517:52
    |
515 |                 # This would make an internal HTTP request
516 |                 # For now, just a placeholder
517 |                 return {"preloaded": True, "path": path}
    |                                                    ^^^^
518 |
519 |             if self.warming_service:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/apm_service.py:662:17
    |
660 |                       # Sleep for 1 minute
661 |                       time.sleep(60)
662 | /                 except Exception as e:
663 | |                     logger.error(f"Error in background monitoring: {e}")
664 | |                     time.sleep(60)
    | |__________________________________^
665 |
666 |           thread = threading.Thread(target=monitor, daemon=True)
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> backend/services/apm_service.py:710:16
    |
708 |         import random
709 |
710 |         return random.random() < self.sampling_rate
    |                ^^^^^^^^^^^^^^^
711 |
712 |     # ========================================================================
    |

PERF401 Use `list.extend` to create a transformed list
   --> backend/services/apm_service.py:889:17
    |
887 |             # Child spans
888 |             for span in trace.spans:
889 |                 otel_spans.append(self._convert_to_otel_format(span))
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
890 |
891 |         return otel_spans
    |
help: Replace for loop with list.extend

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/async_error_handling.py:313:13
    |
311 |                   return  # Success
312 |
313 | /             except Exception as error:
314 | |                 last_error = error
315 | |                 attempt += 1
316 | |
317 | |                 # Handle error
318 | |                 error_context = await self.handle_error(
319 | |                     error, operation, task_id, client_id, metadata={"attempt": attempt}
320 | |                 )
321 | |
322 | |                 # Check if we should retry
323 | |                 if not config:
324 | |                     config = self.recovery_configs.get(
325 | |                         error_context.category, RecoveryConfig()
326 | |                     )
327 | |
328 | |                 if attempt > config.max_retries:
329 | |                     logger.error(
330 | |                         f"Max retries ({config.max_retries}) exceeded for {operation}"
331 | |                     )
332 | |                     break
333 | |
334 | |                 # Don't retry certain error categories
335 | |                 if error_context.category in [
336 | |                     ErrorCategory.VALIDATION,
337 | |                     ErrorCategory.USER_INPUT,
338 | |                 ]:
339 | |                     logger.info(
340 | |                         f"Not retrying {error_context.category.value} error for {operation}"
341 | |                     )
342 | |                     break
343 | |
344 | |                 # Calculate delay with exponential backoff
345 | |                 delay = min(
346 | |                     config.base_delay * (config.backoff_multiplier ** (attempt - 1)),
347 | |                     config.max_delay,
348 | |                 )
349 | |
350 | |                 # Add jitter if enabled
351 | |                 if config.jitter:
352 | |                     import random
353 | |
354 | |                     delay *= 0.5 + random.random() * 0.5
355 | |
356 | |                 logger.info(
357 | |                     f"Retrying {operation} in {delay:.2f}s (attempt {attempt}/{config.max_retries})"
358 | |                 )
359 | |                 await asyncio.sleep(delay)
    | |__________________________________________^
360 |
361 |           # All retries failed
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> backend/services/async_error_handling.py:354:36
    |
352 |                     import random
353 |
354 |                     delay *= 0.5 + random.random() * 0.5
    |                                    ^^^^^^^^^^^^^^^
355 |
356 |                 logger.info(
    |

B007 Loop control variable `operation_key` not used within loop body
   --> backend/services/async_error_handling.py:405:13
    |
403 |         severity_stats = {}
404 |
405 |         for operation_key, errors in self.error_history.items():
    |             ^^^^^^^^^^^^^
406 |             for error_context in errors:
407 |                 category = error_context.category.value
    |
help: Rename unused `operation_key` to `_operation_key`

PERF401 Use `list.extend` to create a transformed list
   --> backend/services/async_error_handling.py:430:21
    |
428 |               for error_context in errors:
429 |                   if error_context.last_occurrence >= cutoff_time:
430 | /                     recent_errors.append(
431 | |                         {
432 | |                             "operation": operation_key,
433 | |                             "category": error_context.category.value,
434 | |                             "severity": error_context.severity.value,
435 | |                             "attempt_count": error_context.attempt_count,
436 | |                             "last_occurrence": error_context.last_occurrence.isoformat(),
437 | |                             "error_message": str(error_context.error)[
438 | |                                 :200
439 | |                             ],  # Truncate long messages
440 | |                         }
441 | |                     )
    | |_____________________^
442 |
443 |           return {
    |
help: Replace for loop with list.extend

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/async_task_manager.py:478:13
    |
476 |                       logger.debug(f"Cleaned up {len(tasks_to_remove)} completed tasks")
477 |
478 | /             except Exception as e:
479 | |                 logger.error(f"Error in task cleanup: {e}")
    | |___________________________________________________________^
    |

S105 Possible hardcoded password assigned to: "PASSWORD_CHANGE"
  --> backend/services/audit_logging_service.py:52:23
   |
50 |     USER_LOGOUT = "user.logout"
51 |     USER_REGISTER = "user.register"
52 |     PASSWORD_CHANGE = "user.password_change"
   |                       ^^^^^^^^^^^^^^^^^^^^^^
53 |     PASSWORD_RESET = "user.password_reset"
54 |     MFA_ENABLE = "user.mfa_enable"
   |

S105 Possible hardcoded password assigned to: "PASSWORD_RESET"
  --> backend/services/audit_logging_service.py:53:22
   |
51 |     USER_REGISTER = "user.register"
52 |     PASSWORD_CHANGE = "user.password_change"
53 |     PASSWORD_RESET = "user.password_reset"
   |                      ^^^^^^^^^^^^^^^^^^^^^
54 |     MFA_ENABLE = "user.mfa_enable"
55 |     MFA_DISABLE = "user.mfa_disable"
   |

B007 Loop control variable `level_name` not used within loop body
   --> backend/services/cache_coherency_manager.py:452:17
    |
451 |             # Delete from all cache levels
452 |             for level_name, level in self.cache_levels.items():
    |                 ^^^^^^^^^^
453 |                 if await level.delete(key):
454 |                     success_count += 1
    |
help: Rename unused `level_name` to `_level_name`

PERF102 When using only the values of a dict use the `values()` method
   --> backend/services/cache_coherency_manager.py:452:38
    |
451 |             # Delete from all cache levels
452 |             for level_name, level in self.cache_levels.items():
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^
453 |                 if await level.delete(key):
454 |                     success_count += 1
    |
help: Replace `.items()` with `.values()`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_coherency_manager.py:494:13
    |
492 |                       success_count += 1
493 |                       self.entry_versions[key][level_name] = version
494 | /             except Exception as e:
495 | |                 logger.error(f"Write-through failed for level {level_name}: {e}")
    | |_________________________________________________________________________________^
496 |
497 |           self.stats["write_through_operations"] += 1
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_coherency_manager.py:590:17
    |
588 |                           success_count += 1
589 |                           self.entry_versions[key][level_name] = version
590 | /                 except Exception as e:
591 | |                     logger.error(f"Broadcast write failed for level {level_name}: {e}")
    | |_______________________________________________________________________________________^
592 |
593 |           except asyncio.TimeoutError:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_coherency_manager.py:677:13
    |
675 |                           "checksum": version.checksum,
676 |                       }
677 | /             except Exception as e:
678 | |                 logger.error(f"Error checking coherency for {level_name}: {e}")
    | |_______________________________________________________________________________^
679 |
680 |           coherency_info["versions"] = versions
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_coherency_manager.py:767:13
    |
765 |                       latest_version = version
766 |                       latest_value = value
767 | /             except Exception as e:
768 | |                 logger.error(f"Error getting version from {level_name}: {e}")
    | |_____________________________________________________________________________^
769 |
770 |           # Sync all levels to the latest version
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_coherency_manager.py:793:13
    |
791 |                   await level.set(key, value, ttl_seconds=None, version=version)
792 |                   self.entry_versions[key][level_name] = version
793 | /             except Exception as e:
794 | |                 logger.error(f"Error syncing level {level_name}: {e}")
    | |______________________________________________________________________^
795 |
796 |           self.stats["sync_operations"] += 1
    |

C901 `_process_write_behind_queue` is too complex (11 > 10)
   --> backend/services/cache_coherency_manager.py:832:15
    |
830 |         logger.info("Stopped cache coherency background processing")
831 |
832 |     async def _process_write_behind_queue(self):
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
833 |         """Process write-behind operations."""
834 |         while self.is_running:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_coherency_manager.py:868:21
    |
866 |                                   )
867 |
868 | /                     except Exception as e:
869 | |                         logger.error(f"Error in write-behind operation: {e}")
    | |_____________________________________________________________________________^
870 |
871 |                   logger.debug(f"Processed {len(batch)} write-behind operations")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_coherency_manager.py:917:13
    |
915 |                       )
916 |
917 | /             except asyncio.CancelledError:
918 | |                 break
    | |_____________________^
919 |               except Exception as e:
920 |                   logger.error(f"Error in periodic coherency check: {e}")
    |

C901 `_cleanup_expired_versions` is too complex (11 > 10)
   --> backend/services/cache_coherency_manager.py:922:15
    |
920 |                 logger.error(f"Error in periodic coherency check: {e}")
921 |
922 |     async def _cleanup_expired_versions(self):
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^
923 |         """Clean up expired version information."""
924 |         while self.is_running:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_coherency_manager.py:954:13
    |
952 |                       )
953 |
954 | /             except asyncio.CancelledError:
955 | |                 break
    | |_____________________^
956 |               except Exception as e:
957 |                   logger.error(f"Error in version cleanup: {e}")
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/services/cache_coherency_manager.py:967:9
    |
965 |           self.coherency_events.append(event)
966 |
967 | /         if self.config.enable_coherency_monitoring:
968 | |             # Log significant events
969 | |             if event.event_type in ["write", "invalidate"]:
    | |___________________________________________________________^
970 |                   logger.debug(
971 |                       f"Coherency event: {event.event_type} for key {event.key} in {event.cache_level}"
    |
help: Combine `if` statements using `and`

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/cache_optimization_service.py:176:13
    |
174 |           if self._analysis_task:
175 |               self._analysis_task.cancel()
176 | /             try:
177 | |                 await self._analysis_task
178 | |             except asyncio.CancelledError:
179 | |                 pass
    | |____________________^
180 |
181 |           if self._warming_task:
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/cache_optimization_service.py:183:13
    |
181 |           if self._warming_task:
182 |               self._warming_task.cancel()
183 | /             try:
184 | |                 await self._warming_task
185 | |             except asyncio.CancelledError:
186 | |                 pass
    | |____________________^
187 |
188 |           logger.info("Cache optimization service stopped")
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_optimization_service.py:211:13
    |
209 |                   await asyncio.sleep(300)  # 5 minutes
210 |
211 | /             except asyncio.CancelledError:
212 | |                 break
    | |_____________________^
213 |               except Exception as e:
214 |                   logger.error(f"Error in optimization analysis loop: {e}")
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/services/cache_optimization_service.py:329:9
    |
328 |           # Check for regular patterns
329 | /         if len(intervals) >= 3:
330 | |             # Calculate coefficient of variation
331 | |             if mean(intervals) > 0:
    | |___________________________________^
332 |                   cv = (stdev(intervals) / mean(intervals)) if len(intervals) > 1 else 0
333 |                   # Lower CV indicates more regular pattern
    |
help: Combine `if` statements using `and`

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> backend/services/cache_optimization_service.py:365:21
    |
363 |             pattern_keys = [
364 |                 key
365 |                 for key in self.access_history.keys()
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
366 |                 if self._extract_pattern(key) == pattern.pattern_template
367 |             ]
    |
help: Remove `.keys()`

B007 Loop control variable `pattern_id` not used within loop body
   --> backend/services/cache_optimization_service.py:441:17
    |
439 |             candidates = []
440 |
441 |             for pattern_id, pattern in self.access_patterns.items():
    |                 ^^^^^^^^^^
442 |                 if pattern.hit_rate < 70:  # Focus on patterns with poor hit rates
443 |                     warming_candidates = (
    |
help: Rename unused `pattern_id` to `_pattern_id`

PERF102 When using only the values of a dict use the `values()` method
   --> backend/services/cache_optimization_service.py:441:40
    |
439 |             candidates = []
440 |
441 |             for pattern_id, pattern in self.access_patterns.items():
    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^
442 |                 if pattern.hit_rate < 70:  # Focus on patterns with poor hit rates
443 |                     warming_candidates = (
    |
help: Replace `.items()` with `.values()`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_optimization_service.py:551:13
    |
549 |                   await asyncio.sleep(60)  # Check every minute
550 |
551 | /             except asyncio.CancelledError:
552 | |                 break
    | |_____________________^
553 |               except Exception as e:
554 |                   logger.error(f"Error in warming loop: {e}")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/cache_optimization_service.py:622:17
    |
620 |                       await asyncio.sleep(0.1)
621 |
622 | /                 except Exception as e:
623 | |                     logger.error(f"Error warming key {key}: {e}")
624 | |                     failed_warms += 1
    | |_____________________________________^
625 |
626 |               # Complete job
    |

B007 Loop control variable `layer` not used within loop body
   --> backend/services/cache_telemetry_service.py:585:13
    |
583 |         all_metrics = self.get_all_layer_metrics()
584 |
585 |         for layer, metrics in all_metrics.items():
    |             ^^^^^
586 |             layer_recommendations = self._generate_layer_recommendations(metrics)
587 |             recommendations.extend(layer_recommendations)
    |
help: Rename unused `layer` to `_layer`

PERF102 When using only the values of a dict use the `values()` method
   --> backend/services/cache_telemetry_service.py:585:31
    |
583 |         all_metrics = self.get_all_layer_metrics()
584 |
585 |         for layer, metrics in all_metrics.items():
    |                               ^^^^^^^^^^^^^^^^^
586 |             layer_recommendations = self._generate_layer_recommendations(metrics)
587 |             recommendations.extend(layer_recommendations)
    |
help: Replace `.items()` with `.values()`

SIM103 Return the negated condition directly
   --> backend/services/cache_warming_service.py:254:9
    |
252 |           if pattern_parts[0] and not key.startswith(pattern_parts[0]):
253 |               return False
254 | /         if pattern_parts[-1] and not key.endswith(pattern_parts[-1]):
255 | |             return False
256 | |
257 | |         return True
    | |___________________^
258 |
259 |       # ========================================================================
    |
help: Inline condition

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/services/cache_warming_service.py:360:13
    |
358 |           # Schedule warming tasks for high-probability keys
359 |           for key, probability in predictions.items():
360 | /             if probability >= self.config["warming_threshold_probability"]:
361 | |                 if key not in self.warming_tasks and not self.redis_cache.exists(key):
    | |______________________________________________________________________________________^
362 |                       # Determine priority based on probability
363 |                       if probability >= 0.8:
    |
help: Combine `if` statements using `and`

C901 `_analyze_access_patterns` is too complex (11 > 10)
   --> backend/services/cache_warming_service.py:384:15
    |
382 |         )
383 |
384 |     async def _analyze_access_patterns(self) -> dict[str, float]:
    |               ^^^^^^^^^^^^^^^^^^^^^^^^
385 |         """Analyze access patterns to predict future cache needs."""
386 |         predictions = {}
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/services/cache_warming_service.py:412:13
    |
410 |                   if self._in_typical_access_window(profile, current_time):
411 |                       probability += 0.3
412 | /             elif profile.access_pattern == AccessPattern.SEASONAL:
413 | |                 # Seasonal pattern prediction
414 | |                 if self._predict_seasonal_access(profile, current_time):
    | |________________________________________________________________________^
415 |                       probability += 0.25
    |
help: Combine `if` statements using `and`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/services/cache_warming_service.py:451:9
    |
449 |           """Predict if seasonal pattern indicates access is likely."""
450 |           # Simple implementation - would be more sophisticated in production
451 | /         if profile.seasonality_score > 0.7:  # High seasonality
452 | |             # Check day-of-week pattern
453 | |             if profile.access_times:
    | |____________________________________^
454 |                   days = [t.weekday() for t in profile.access_times]
455 |                   current_day = current_time.weekday()
    |
help: Combine `if` statements using `and`

B007 Loop control variable `profile` not used within loop body
   --> backend/services/cache_warming_service.py:515:26
    |
513 |             # Warm sequential keys in batches
514 |             sorted_keys = sorted(keys, key=lambda x: x[0])  # Sort by key name
515 |             for i, (key, profile) in enumerate(sorted_keys[:5]):  # Batch of 5
    |                          ^^^^^^^
516 |                 self.add_warming_task(
517 |                     key=key,
    |
help: Rename unused `profile` to `_profile`

B007 Loop control variable `profile` not used within loop body
   --> backend/services/cache_warming_service.py:571:24
    |
569 |         )
570 |
571 |         for other_key, profile in self.smart_cache.key_profiles.items():
    |                        ^^^^^^^
572 |             if other_key == key:
573 |                 continue
    |
help: Rename unused `profile` to `_profile`

PERF102 When using only the keys of a dict use the `keys()` method
   --> backend/services/cache_warming_service.py:571:35
    |
569 |         )
570 |
571 |         for other_key, profile in self.smart_cache.key_profiles.items():
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
572 |             if other_key == key:
573 |                 continue
    |
help: Replace `.items()` with `.keys()`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/services/cache_warming_service.py:722:13
    |
720 |           finally:
721 |               # Clean up from active tasks
722 | /             if task.key in self.warming_tasks:
723 | |                 if task.completed or task.attempts >= 3:
    | |________________________________________________________^
724 |                       del self.warming_tasks[task.key]
    |
help: Combine `if` statements using `and`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> backend/services/cache_warming_service.py:755:13
    |
754 |           for key, profile in self.smart_cache.key_profiles.items():
755 | /             if not self.redis_cache.exists(key):
756 | |                 # Check if key is commonly accessed during business hours
757 | |                 if profile.access_times:
    | |________________________________________^
758 |                       business_accesses = [
759 |                           t for t in profile.access_times if 9 <= t.hour <= 17
    |
help: Combine `if` statements using `and`

E722 Do not use bare `except`
   --> backend/services/centralized_logging_service.py:182:13
    |
180 |                 )
181 |                 log_record["timestamp"] = dt.isoformat()
182 |             except:
    |             ^^^^^^
183 |                 log_record["timestamp"] = datetime.utcnow().isoformat()
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/centralized_logging_service.py:903:17
    |
901 |                               f"Deleted old log file: {log_file}"
902 |                           )
903 | /                 except Exception as e:
904 | |                     logging.getLogger(__name__).error(
905 | |                         f"Failed to delete log file {log_file}: {e}"
906 | |                     )
    | |_____________________^
907 |
908 |           # Clean up Elasticsearch indices
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/centralized_logging_service.py:933:21
    |
931 |                                   f"Deleted old Elasticsearch index: {index_name}"
932 |                               )
933 | /                     except (ValueError, IndexError):
934 | |                         # Skip indices that don't match expected format
935 | |                         continue
    | |________________________________^
936 |
937 |               except Exception as e:
    |

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   --> backend/services/circuit_breaker_service.py:737:9
    |
735 |       @circuit_breaker("async_api", CircuitBreakerConfig(timeout=10))
736 |       async def call_async_api():
737 | /         async with aiohttp.ClientSession() as session:
738 | |             async with session.get("https://httpbin.org/delay/1") as response:
    | |______________________________________________________________________________^
739 |                   return await response.json()
    |
help: Combine `with` statements

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/circuit_breaker_service.py:750:17
    |
748 |                       _ = call_external_api()
749 |                       print(f"Call {i+1}: Success")
750 | /                 except Exception as e:
751 | |                     print(f"Call {i+1}: Failed - {e}")
    | |______________________________________________________^
752 |
753 |               # Test async circuit breaker
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/circuit_breaker_service.py:759:17
    |
757 |                       _ = await call_async_api()
758 |                       print(f"Async call {i+1}: Success")
759 | /                 except Exception as e:
760 | |                     print(f"Async call {i+1}: Failed - {e}")
    | |____________________________________________________________^
761 |
762 |               # Get stats
    |

E722 Do not use bare `except`
   --> backend/services/connection_pool_manager.py:158:9
    |
156 |             cursor.fetchone()
157 |             return True
158 |         except:
    |         ^^^^^^
159 |             return False
    |

B007 Loop control variable `i` not used within loop body
   --> backend/services/connection_pool_manager.py:216:17
    |
214 |             )
215 |
216 |             for i in range(self.config.initial_connections):
    |                 ^
217 |                 connection = self._create_new_connection()
218 |                 managed_conn = ManagedConnection(connection, self)
    |
help: Rename unused `i` to `_i`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/connection_pool_manager.py:289:13
    |
287 |                   self._cleanup_stale_connections()
288 |                   self._update_pool_statistics()
289 | /             except Exception as e:
290 | |                 logger.error(f"Health monitor error: {e}")
    | |__________________________________________________________^
291 |
292 |       def _pool_optimizer_worker(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/connection_pool_manager.py:302:13
    |
301 |                   self._balance_connection_load()
302 | /             except Exception as e:
303 | |                 logger.error(f"Pool optimizer error: {e}")
    | |__________________________________________________________^
304 |
305 |       def _check_connection_health(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/connection_pool_manager.py:359:25
    |
357 |                               if conn.metrics.connection_id != conn_id:
358 |                                   new_idle_queue.put(conn)
359 | /                         except queue.Empty:
360 | |                             break
    | |_________________________________^
361 |                       self._idle_connections = new_idle_queue
362 |                   except:
    |

E722 Do not use bare `except`
   --> backend/services/connection_pool_manager.py:362:17
    |
360 |                             break
361 |                     self._idle_connections = new_idle_queue
362 |                 except:
    |                 ^^^^^^
363 |                     pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> backend/services/connection_pool_manager.py:362:17
    |
360 |                               break
361 |                       self._idle_connections = new_idle_queue
362 | /                 except:
363 | |                     pass
    | |________________________^
364 |
365 |                   # Close the actual connection
    |

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
   --> backend/services/connection_pool_manager.py:366:17
    |
365 |                   # Close the actual connection
366 | /                 try:
367 | |                     managed_conn.connection.close()
368 | |                 except:
369 | |                     pass
    | |________________________^
370 |
371 |                   self._stats.total_connections -= 1
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
   --> backend/services/connection_pool_manager.py:368:17
    |
366 |                 try:
367 |                     managed_conn.connection.close()
368 |                 except:
    |                 ^^^^^^
369 |                     pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> backend/services/connection_pool_manager.py:368:17
    |
366 |                   try:
367 |                       managed_conn.connection.close()
368 | /                 except:
369 | |                     pass
    | |________________________^
370 |
371 |                   self._stats.total_connections -= 1
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/connection_pool_manager.py:395:21
    |
393 |                           self._idle_connections.put(managed_conn)
394 |                           self._stats.total_connections += 1
395 | /                     except Exception as e:
396 | |                         logger.error(
397 | |                             f"Failed to create new connection during scaling: {e}"
398 | |                         )
399 | |                         break
    | |_____________________________^
400 |
401 |                   logger.info(
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/connection_pool_manager.py:416:21
    |
414 |                               managed_conn = self._idle_connections.get_nowait()
415 |                               self._remove_connection(managed_conn.metrics.connection_id)
416 | /                     except queue.Empty:
417 | |                         break
    | |_____________________________^
418 |
419 |                   if excess_connections > 0:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/connection_pool_manager.py:467:21
    |
465 |                           self._idle_connections.put(managed_conn)
466 |                           self._stats.total_connections += 1
467 | /                     except Exception as e:
468 | |                         logger.error(
469 | |                             f"Failed to create connection during adaptive scaling: {e}"
470 | |                         )
471 | |                         break
    | |_____________________________^
472 |
473 |                   logger.info(
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/connection_pool_manager.py:494:21
    |
492 |                               managed_conn = self._idle_connections.get_nowait()
493 |                               self._remove_connection(managed_conn.metrics.connection_id)
494 | /                     except queue.Empty:
495 | |                         break
    | |_____________________________^
496 |
497 |                   if connections_to_remove > 0:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/connection_pool_manager.py:806:17
    |
804 |                       connections_created += 1
805 |
806 | /                 except Exception as e:
807 | |                     logger.error(f"Failed to create connection during warming: {e}")
808 | |                     break
    | |_________________________^
809 |
810 |           if connections_created > 0:
    |

E722 Do not use bare `except`
   --> backend/services/custom_metrics_collector.py:305:17
    |
303 |                         db_size_mb = 0
304 |                     metrics["database_size_mb"] = db_size_mb
305 |                 except:
    |                 ^^^^^^
306 |                     metrics["database_size_mb"] = 0
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/custom_metrics_collector.py:695:13
    |
693 |                   await asyncio.sleep(self.collection_interval)
694 |
695 | /             except Exception as e:
696 | |                 logger.error(f"Error in continuous collection: {e}")
697 | |                 await asyncio.sleep(30)  # Wait 30 seconds before retrying
    | |_______________________________________^
698 |
699 |       def start_metrics_server(self, port: int = 8000):
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/db_performance_monitor.py:298:13
    |
296 |                   self._persist_metrics()
297 |
298 | /             except Exception as e:
299 | |                 logger.error(f"Monitoring error: {e}")
    | |______________________________________________________^
300 |
301 |       def _alert_worker(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/db_performance_monitor.py:307:13
    |
305 |                   self._check_alert_conditions()
306 |                   self._resolve_alerts()
307 | /             except Exception as e:
308 | |                 logger.error(f"Alert processing error: {e}")
    | |____________________________________________________________^
309 |
310 |       def _collect_database_metrics(self) -> None:
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> backend/services/db_performance_monitor.py:403:21
    |
401 |                                   )
402 |                               )
403 | /                     except Exception:
404 | |                         pass  # Skip failed PRAGMA queries
    | |____________________________^
405 |
406 |               except Exception as e:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/db_performance_monitor.py:403:21
    |
401 |                                   )
402 |                               )
403 | /                     except Exception:
404 | |                         pass  # Skip failed PRAGMA queries
    | |____________________________^
405 |
406 |               except Exception as e:
    |

PERF402 Use `list` or `list.copy` to create a copy of a list
   --> backend/services/db_performance_monitor.py:702:21
    |
700 |                 # Only persist latest metric for each name
701 |                 for metric in self._current_metrics.values():
702 |                     current_metrics.append(metric)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
703 |
704 |             # Batch insert metrics
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/db_performance_monitor.py:721:17
    |
719 |                           ),
720 |                       )
721 | /                 except Exception as e:
722 | |                     logger.debug(f"Failed to persist metric {metric.name}: {e}")
    | |________________________________________________________________________________^
723 |
724 |           except Exception as e:
    |

C901 `get_database_health` is too complex (21 > 10)
   --> backend/services/db_performance_monitor.py:959:9
    |
957 |             ]
958 |
959 |     def get_database_health(self) -> DatabaseHealthStatus:
    |         ^^^^^^^^^^^^^^^^^^^
960 |         """Calculate overall database health status."""
961 |         try:
    |

C901 `main` is too complex (13 > 10)
    --> backend/services/db_performance_monitor.py:1157:5
     |
1157 | def main():
     |     ^^^^
1158 |     """CLI interface for the Database Performance Monitor."""
1159 |     import argparse
     |

E712 Avoid equality comparisons to `True`; use `EncryptionKey.is_active:` for truth checks
   --> backend/services/encryption_service.py:640:53
    |
638 |         cutoff_date = datetime.utcnow() - timedelta(days=self.key_rotation_days)
639 |
640 |         query = self.db.query(EncryptionKey).filter(EncryptionKey.is_active == True)
    |                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
641 |
642 |         if not force:
    |
help: Replace with `EncryptionKey.is_active`

E711 Comparison to `None` should be `cond is None`
   --> backend/services/encryption_service.py:644:46
    |
642 |         if not force:
643 |             query = query.filter(
644 |                 (EncryptionKey.rotated_at == None)
    |                                              ^^^^
645 |                 | (EncryptionKey.rotated_at < cutoff_date)
646 |             )
    |
help: Replace with `cond is None`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/encryption_service.py:675:13
    |
674 |                   logger.info(f"Rotated key: {key_record.key_id}")
675 | /             except Exception as e:
676 | |                 logger.error(f"Failed to rotate key {key_record.key_id}: {e}")
677 | |                 stats["failed"] += 1
    | |____________________________________^
678 |
679 |           self.db.commit()
    |

E712 Avoid equality comparisons to `True`; use `ConsentRecord.is_active:` for truth checks
   --> backend/services/gdpr_compliance_service.py:326:47
    |
324 |         """
325 |         query = self.db.query(ConsentRecord).filter(
326 |             ConsentRecord.user_id == user_id, ConsentRecord.is_active == True
    |                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
327 |         )
    |
help: Replace with `ConsentRecord.is_active`

E712 Avoid equality comparisons to `True`; use `ConsentRecord.is_active:` for truth checks
   --> backend/services/gdpr_compliance_service.py:368:34
    |
367 |         if active_only:
368 |             query = query.filter(ConsentRecord.is_active == True)
    |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
369 |
370 |         consents = query.all()
    |
help: Replace with `ConsentRecord.is_active`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/gdpr_compliance_service.py:753:13
    |
751 |                   self._send_breach_notification(user_id, breach)
752 |                   notified_count += 1
753 | /             except Exception as e:
754 | |                 logger.error(f"Failed to notify user {user_id}: {e}")
    | |_____________________________________________________________________^
755 |
756 |           breach.notification_sent = True
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> backend/services/health_check_service.py:607:13
    |
605 |                           except (OSError, PermissionError):
606 |                               continue
607 | /             except Exception:
608 | |                 pass
    | |____________________^
609 |
610 |               # Determine status
    |

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   --> backend/services/health_check_service.py:762:21
    |
760 |               if google_api_key:
761 |                   try:
762 | /                     async with aiohttp.ClientSession() as session:
763 | |                         async with session.get(
764 | |                             "https://generativelanguage.googleapis.com/v1/models",
765 | |                             params={"key": google_api_key},
766 | |                             timeout=aiohttp.ClientTimeout(total=5),
767 | |                         ) as response:
    | |______________________________________^
768 |                               if response.status == 200:
769 |                                   external_services.append(
    |
help: Combine `with` statements

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> backend/services/health_check_service.py:988:55
    |
986 |     def get_all_checks_status(self) -> dict[str, Any]:
987 |         """Get status of all registered health checks."""
988 |         return {name: self.get_check_status(name) for name in self.health_checks.keys()}
    |                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
help: Remove `.keys()`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/incremental_backup_service.py:113:13
    |
111 |                   checksum_map[relative_path] = checksum
112 |
113 | /             except (OSError, PermissionError) as e:
114 | |                 logger.warning(f"Cannot access file {file_path}: {e}")
115 | |                 continue
    | |________________________^
116 |
117 |           snapshot = IncrementalSnapshot(
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/incremental_backup_service.py:198:13
    |
196 |                       )
197 |
198 | /             except (OSError, PermissionError) as e:
199 | |                 logger.warning(f"Cannot access file {file_path}: {e}")
200 | |                 continue
    | |________________________^
201 |
202 |           # Check for deleted files
    |

PERF401 Use `list.extend` to create a transformed list
   --> backend/services/incremental_backup_service.py:205:17
    |
203 |           for relative_path in self.last_snapshot.checksum_map:
204 |               if relative_path not in current_files:
205 | /                 changes.append(
206 | |                     ChangeRecord(
207 | |                         path=relative_path,
208 | |                         change_type=ChangeType.DELETED,
209 | |                         timestamp=datetime.utcnow(),
210 | |                         size=0,
211 | |                         checksum="",
212 | |                     )
213 | |                 )
    | |_________________^
214 |
215 |           logger.info(f"Detected {len(changes)} changes since last snapshot")
    |
help: Replace for loop with list.extend

S608 Possible SQL injection vector through string-based query construction
   --> backend/services/incremental_backup_service.py:379:48
    |
377 |                     # Additionally validated with _validate_table_name() above.
378 |                     # COUNT queries cannot be parameterized for table names in standard SQL
379 |                     result = conn.execute(text(f"SELECT COUNT(*) FROM {table}"))
    |                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
380 |                     count = result.scalar()
381 |                     total_records += count
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/services/incremental_backup_service.py:388:29
    |
386 |                       result = conn.execute(
387 |                           text(
388 | /                             f"""
389 | |                         SELECT MD5(ARRAY_AGG(ROW(t.*)::text ORDER BY (SELECT 1))::text)
390 | |                         FROM {table} t
391 | |                     """
    | |_______________________^
392 |                           )
393 |                       )
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/services/incremental_backup_service.py:401:29
    |
399 |                       conn.execute(
400 |                           text(
401 | /                             f"""
402 | |                         INSERT INTO {self.snapshot_table}
403 | |                         (snapshot_id, table_name, record_count, checksum, metadata)
404 | |                         VALUES (:snapshot_id, :table_name, :record_count, :checksum, :metadata)
405 | |                     """
    | |_______________________^
406 |                           ),
407 |                           {
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/services/incremental_backup_service.py:447:21
    |
445 |               result = conn.execute(
446 |                   text(
447 | /                     f"""
448 | |                 SELECT table_name, checksum FROM {self.snapshot_table}
449 | |                 WHERE snapshot_id = :snapshot_id
450 | |             """
    | |_______________^
451 |                   ),
452 |                   {"snapshot_id": since_snapshot_id},
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/services/incremental_backup_service.py:472:29
    |
470 |                       result = conn.execute(
471 |                           text(
472 | /                             f"""
473 | |                         SELECT MD5(ARRAY_AGG(ROW(t.*)::text ORDER BY (SELECT 1))::text)
474 | |                         FROM {table} t
475 | |                     """
    | |_______________________^
476 |                           )
477 |                       )
    |

S608 Possible SQL injection vector through string-based query construction
   --> backend/services/incremental_backup_service.py:484:52
    |
482 |                         # SAFETY: Table names come from validated database results and validated above
483 |                         # COUNT queries cannot parameterize table names in standard SQL
484 |                         result = conn.execute(text(f"SELECT COUNT(*) FROM {table}"))
    |                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
485 |                         count = result.scalar()
    |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/integrated_performance_monitor.py:137:17
    |
135 |               if self._health_check_task:
136 |                   self._health_check_task.cancel()
137 | /                 try:
138 | |                     await self._health_check_task
139 | |                 except asyncio.CancelledError:
140 | |                     pass
    | |________________________^
141 |
142 |               # Stop services
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/integrated_performance_monitor.py:163:13
    |
161 |                   await asyncio.sleep(300)  # Every 5 minutes
162 |
163 | /             except asyncio.CancelledError:
164 | |                 break
    | |_____________________^
165 |               except Exception as e:
166 |                   logger.error(f"Error in health check loop: {e}")
    |

C901 `update_configuration` is too complex (12 > 10)
   --> backend/services/integrated_performance_monitor.py:355:9
    |
353 |     # ========================================================================
354 |
355 |     def update_configuration(self, config: dict[str, Any]) -> bool:
    |         ^^^^^^^^^^^^^^^^^^^^
356 |         """Update configuration for all services."""
357 |         try:
    |

C901 `_generate_trend_summary` is too complex (12 > 10)
   --> backend/services/integrated_performance_monitor.py:638:9
    |
636 |             return "declining"
637 |
638 |     def _generate_trend_summary(self, apm_trends: dict, cache_trends: dict) -> str:
    |         ^^^^^^^^^^^^^^^^^^^^^^^
639 |         """Generate human-readable trend summary."""
640 |         try:
    |

B007 Loop control variable `score` not used within loop body
   --> backend/services/l1_memory_cache.py:502:13
    |
501 |         # Evict entries until we have enough space
502 |         for score, key, entry, level in all_entries:
    |             ^^^^^
503 |             if (
504 |                 freed_bytes >= required_bytes
    |
help: Rename unused `score` to `_score`

B007 Loop control variable `score` not used within loop body
   --> backend/services/l1_memory_cache.py:545:13
    |
544 |         # Evict entries
545 |         for score, key, entry in entries:
    |             ^^^^^
546 |             if freed_bytes >= required_bytes:
547 |                 break
    |
help: Rename unused `score` to `_score`

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/l1_memory_cache.py:597:13
    |
595 |           if self._cleanup_task:
596 |               self._cleanup_task.cancel()
597 | /             try:
598 | |                 await self._cleanup_task
599 | |             except asyncio.CancelledError:
600 | |                 pass
    | |____________________^
601 |
602 |           logger.info("Stopped background cache cleanup")
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/l1_memory_cache.py:613:13
    |
611 |                   await asyncio.to_thread(self._perform_maintenance)
612 |
613 | /             except asyncio.CancelledError:
614 | |                 break
    | |_____________________^
615 |               except Exception as e:
616 |                   logger.error(f"Error in background cleanup: {e}")
    |

E722 Do not use bare `except`
   --> backend/services/l1_memory_cache.py:667:9
    |
666 |             return sys.getsizeof(value)
667 |         except:
    |         ^^^^^^
668 |             # Fallback estimation
669 |             if isinstance(value, str):
    |

S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
   --> backend/services/l2_redis_cache.py:126:20
    |
124 |         """Create entry from Redis data."""
125 |         try:
126 |             data = pickle.loads(redis_data)
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^
127 |             metadata = data.get("metadata", {})
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> backend/services/l2_redis_cache.py:317:38
    |
315 |                 import random
316 |
317 |                 entry.ttl_seconds += random.randint(-int(jitter), int(jitter))
    |                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
318 |
319 |             # Handle hot data TTL extension
    |

C901 `mget` is too complex (11 > 10)
   --> backend/services/l2_redis_cache.py:416:15
    |
414 |     # ========================================================================
415 |
416 |     async def mget(self, keys: list[str]) -> dict[str, Any]:
    |               ^^^^
417 |         """Get multiple keys from cache."""
418 |         results = {}
    |

S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
   --> backend/services/l2_redis_cache.py:552:21
    |
551 |             decompressed_data = zlib.decompress(entry.value)
552 |             value = pickle.loads(decompressed_data)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
553 |
554 |             self.stats["decompressions"] += 1
    |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/l2_redis_cache.py:638:13
    |
636 |           if self.write_behind_task:
637 |               self.write_behind_task.cancel()
638 | /             try:
639 | |                 await self.write_behind_task
640 | |             except asyncio.CancelledError:
641 | |                 pass
    | |____________________^
642 |
643 |           # Flush remaining queue
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/l2_redis_cache.py:655:13
    |
653 |                   await self._flush_write_behind_queue()
654 |
655 | /             except asyncio.CancelledError:
656 | |                 break
    | |_____________________^
657 |               except Exception as e:
658 |                   logger.error(f"Error in write-behind loop: {e}")
    |

PERF401 Use a list comprehension to create a transformed list
   --> backend/services/l2_redis_cache.py:673:17
    |
671 |         ):
672 |             if self.write_behind_queue:
673 |                 batch.append(self.write_behind_queue.popleft())
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
674 |
675 |         if not batch:
    |
help: Replace for loop with list comprehension

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/l2_redis_cache.py:686:13
    |
684 |                       await self._update_entry_metadata(key, entry)
685 |                       update_count += 1
686 | /             except Exception as e:
687 | |                 logger.error(f"Error in write-behind operation for key {key}: {e}")
    | |___________________________________________________________________________________^
688 |
689 |           self.stats["write_behind_operations"] += update_count
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/l3_cdn_cache.py:406:13
    |
404 |                       results[url] = False
405 |
406 | /             except Exception as e:
407 | |                 logger.error(f"Error prefetching content {url}: {e}")
408 | |                 results[url] = False
    | |____________________________________^
409 |
410 |           logger.info(f"Prefetched {sum(results.values())}/{len(urls)} URLs")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/l3_cdn_cache.py:587:13
    |
585 |                   await asyncio.sleep(10)
586 |
587 | /             except Exception as e:
588 | |                 logger.error(f"Error checking invalidation status: {e}")
589 | |                 break
    | |_____________________^
590 |
591 |           logger.warning(
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/l3_cdn_cache.py:632:13
    |
630 |                   logger.debug(f"Warming edge location {edge_location} for {cdn_url}")
631 |
632 | /             except Exception as e:
633 | |                 logger.error(f"Error warming edge location {edge_location}: {e}")
    | |_________________________________________________________________________________^
634 |
635 |       def _generate_cdn_url(
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/l3_cdn_cache.py:754:17
    |
752 |                               metrics[metric_name] = latest["Average"]
753 |
754 | /                 except Exception as e:
755 | |                     logger.error(f"Error getting metric {metric_name}: {e}")
    | |____________________________________________________________________________^
756 |
757 |               return {
    |

C901 `_execute_rag_query` is too complex (12 > 10)
  --> backend/services/memory_efficient_rag.py:78:15
   |
76 |             self._active_processors.discard(processor)
77 |
78 |     async def _execute_rag_query(
   |               ^^^^^^^^^^^^^^^^^^
79 |         self,
80 |         processor: "RAGMemoryContext",
   |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
  --> backend/services/monitoring_integration_service.py:79:17
   |
77 |               if self._integration_task and not self._integration_task.done():
78 |                   self._integration_task.cancel()
79 | /                 try:
80 | |                     await self._integration_task
81 | |                 except asyncio.CancelledError:
82 | |                     pass
   | |________________________^
83 |
84 |               # Stop metrics collector
   |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/monitoring_integration_service.py:110:13
    |
108 |                   await asyncio.sleep(5)  # Integration check every 5 seconds
109 |
110 | /             except asyncio.CancelledError:
111 | |                 break
    | |_____________________^
112 |               except Exception as e:
113 |                   logger.error(f"Error in integration bridge: {e}")
    |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/performance_alerting_service.py:487:13
    |
485 |           if self._evaluation_task:
486 |               self._evaluation_task.cancel()
487 | /             try:
488 | |                 await self._evaluation_task
489 | |             except asyncio.CancelledError:
490 | |                 pass
    | |____________________^
491 |
492 |           if self._cleanup_task:
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/performance_alerting_service.py:494:13
    |
492 |           if self._cleanup_task:
493 |               self._cleanup_task.cancel()
494 | /             try:
495 | |                 await self._cleanup_task
496 | |             except asyncio.CancelledError:
497 | |                 pass
    | |____________________^
498 |
499 |           logger.info("Performance alerting monitoring stopped")
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/performance_alerting_service.py:513:13
    |
511 |                   await asyncio.sleep(30)
512 |
513 | /             except asyncio.CancelledError:
514 | |                 break
    | |_____________________^
515 |               except Exception as e:
516 |                   logger.error(f"Error in alert evaluation loop: {e}")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/performance_alerting_service.py:529:13
    |
527 |                   await asyncio.sleep(600)
528 |
529 | /             except asyncio.CancelledError:
530 | |                 break
    | |_____________________^
531 |               except Exception as e:
532 |                   logger.error(f"Error in cleanup loop: {e}")
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> backend/services/performance_alerting_service.py:742:13
    |
740 |                       condition=rule.condition,
741 |                   )
742 | /             except Exception:
743 | |                 pass  # Fall back to default
    | |____________________^
744 |
745 |           return (
    |

B007 Loop control variable `op_name` not used within loop body
   --> backend/services/performance_dashboard_service.py:164:13
    |
163 |         # Calculate averages
164 |         for op_name, stats in operation_stats.items():
    |             ^^^^^^^
165 |             stats["avg_duration_ms"] = (
166 |                 stats["total_duration"] / stats["count"] if stats["count"] > 0 else 0
    |
help: Rename unused `op_name` to `_op_name`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/performance_dashboard_service.py:255:13
    |
253 |                   else:
254 |                       disconnected_connections.append(connection)
255 | /             except Exception as e:
256 | |                 logger.error(f"Error broadcasting to WebSocket: {e}")
257 | |                 disconnected_connections.append(connection)
    | |___________________________________________________________^
258 |
259 |           # Clean up disconnected connections
    |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/performance_dashboard_service.py:316:13
    |
314 |           if self._update_task:
315 |               self._update_task.cancel()
316 | /             try:
317 | |                 await self._update_task
318 | |             except asyncio.CancelledError:
319 | |                 pass
    | |____________________^
320 |               logger.info("Real-time dashboard updates stopped")
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/performance_dashboard_service.py:350:13
    |
348 |                   await asyncio.sleep(25)  # Total 30 seconds between detailed updates
349 |
350 | /             except asyncio.CancelledError:
351 | |                 break
    | |_____________________^
352 |               except Exception as e:
353 |                   logger.error(f"Error in real-time update loop: {e}")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/performance_dashboard_service.py:384:17
    |
382 |                       message = json.loads(data)
383 |                       await self._handle_client_message(websocket, message)
384 | /                 except WebSocketDisconnect:
385 | |                     break
    | |_________________________^
386 |                   except Exception as e:
387 |                       logger.error(f"Error handling WebSocket message: {e}")
    |

PERF401 Use a list comprehension to create a transformed list
   --> backend/services/performance_dashboard_service.py:500:21
    |
498 |             for span in trace.spans:
499 |                 if span.parent_span_id == parent_span_id:
500 |                     children.append(build_node(span, build_children(span.span_id)))
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
501 |             return children
    |
help: Replace for loop with list comprehension

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/production_monitoring.py:375:13
    |
373 |                   await asyncio.sleep(60)  # Collect every minute
374 |
375 | /             except Exception as e:
376 | |                 logger.error(f"Error collecting system metrics: {e}")
377 | |                 await asyncio.sleep(60)
    | |_______________________________________^
378 |
379 |       async def _collect_application_metrics(self):
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/production_monitoring.py:427:13
    |
425 |                   await asyncio.sleep(60)  # Collect every minute
426 |
427 | /             except Exception as e:
428 | |                 logger.error(f"Error collecting application metrics: {e}")
429 | |                 await asyncio.sleep(60)
    | |_______________________________________^
430 |
431 |       async def _run_health_check_loop(self, health_check: HealthCheck):
    |

C901 `_run_health_check_loop` is too complex (11 > 10)
   --> backend/services/production_monitoring.py:431:15
    |
429 |                 await asyncio.sleep(60)
430 |
431 |     async def _run_health_check_loop(self, health_check: HealthCheck):
    |               ^^^^^^^^^^^^^^^^^^^^^^
432 |         """Run health check in a loop."""
433 |         while True:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/production_monitoring.py:912:13
    |
910 |                   await asyncio.sleep(60)
911 |
912 | /             except Exception as e:
913 | |                 logger.error(f"Error processing alerts: {e}")
914 | |                 await asyncio.sleep(60)
    | |_______________________________________^
915 |
916 |       async def _cleanup_metrics_history(self):
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/production_monitoring.py:933:13
    |
931 |                   await asyncio.sleep(3600)  # Cleanup every hour
932 |
933 | /             except Exception as e:
934 | |                 logger.error(f"Error cleaning up metrics: {e}")
935 | |                 await asyncio.sleep(3600)
    | |_________________________________________^
936 |
937 |       def get_overall_health(self) -> dict[str, Any]:
    |

S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
   --> backend/services/query_cache_manager.py:246:20
    |
244 |         """Decompress data from storage."""
245 |         if not self.enable_compression:
246 |             return pickle.loads(compressed_data)
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
247 |
248 |         import zlib
    |

S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
   --> backend/services/query_cache_manager.py:251:16
    |
250 |         pickled_data = zlib.decompress(compressed_data)
251 |         return pickle.loads(pickled_data)
    |                ^^^^^^^^^^^^^^^^^^^^^^^^^^
252 |
253 |     def get(
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/query_cache_manager.py:605:13
    |
603 |                   self._cleanup_expired_entries()
604 |                   self._update_statistics()
605 | /             except Exception as e:
606 | |                 logger.error(f"Cache cleanup error: {e}")
    | |_________________________________________________________^
607 |
608 |       def _cleanup_expired_entries(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/query_cache_manager.py:629:13
    |
627 |               try:
628 |                   self._warm_cache()
629 | /             except Exception as e:
630 | |                 logger.error(f"Cache warming error: {e}")
    | |_________________________________________________________^
631 |
632 |       def _warm_cache(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/query_cache_manager.py:678:13
    |
676 |                   )
677 |
678 | /             except Exception as e:
679 | |                 logger.warning(f"Failed to warm cache for query: {e}")
    | |______________________________________________________________________^
680 |
681 |           if warmed_count > 0:
    |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/real_time_metrics_collector.py:201:17
    |
199 |               if task and not task.done():
200 |                   task.cancel()
201 | /                 try:
202 | |                     await task
203 | |                 except asyncio.CancelledError:
204 | |                     pass
    | |________________________^
205 |
206 |           logger.info("Real-time metrics collection stopped")
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/real_time_metrics_collector.py:547:13
    |
545 |                   else:
546 |                       callback(metrics_update)
547 | /             except Exception as e:
548 | |                 logger.error(f"Error notifying metric subscriber: {e}")
    | |_______________________________________________________________________^
549 |
550 |       async def _stream_metrics_loop(self):
    |

E722 Do not use bare `except`
   --> backend/services/redis_cache_service.py:652:13
    |
650 |                     "keyspace_misses": redis_info.get("keyspace_misses"),
651 |                 }
652 |             except:
    |             ^^^^^^
653 |                 pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> backend/services/redis_cache_service.py:652:13
    |
650 |                       "keyspace_misses": redis_info.get("keyspace_misses"),
651 |                   }
652 | /             except:
653 | |                 pass
    | |____________________^
654 |
655 |           return stats
    |

S301 `pickle` and modules that wrap it can be unsafe when used to deserialize untrusted data, possible security issue
   --> backend/services/redis_cache_service.py:705:16
    |
703 |             value = zlib.decompress(value[11:])
704 |
705 |         return pickle.loads(value)
    |                ^^^^^^^^^^^^^^^^^^^
706 |
707 |     def close(self):
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/redis_cluster_manager.py:298:13
    |
296 |                   logger.debug(f"Initialized client for node {node_id}")
297 |
298 | /             except Exception as e:
299 | |                 logger.error(f"Failed to initialize client for {node.address}: {e}")
    | |____________________________________________________________________________________^
300 |
301 |       async def _initialize_sentinel_health(self):
    |

B007 Loop control variable `master_name` not used within loop body
   --> backend/services/redis_cluster_manager.py:306:17
    |
304 |             # Get master info
305 |             masters = self._sentinel_client.sentinel_masters()
306 |             for master_name, master_info in masters.items():
    |                 ^^^^^^^^^^^
307 |                 master_id = f"{master_info['ip']}:{master_info['port']}"
308 |                 self._node_health[master_id] = NodeHealth(
    |
help: Rename unused `master_name` to `_master_name`

PERF102 When using only the values of a dict use the `values()` method
   --> backend/services/redis_cluster_manager.py:306:45
    |
304 |             # Get master info
305 |             masters = self._sentinel_client.sentinel_masters()
306 |             for master_name, master_info in masters.items():
    |                                             ^^^^^^^^^^^^^
307 |                 master_id = f"{master_info['ip']}:{master_info['port']}"
308 |                 self._node_health[master_id] = NodeHealth(
    |
help: Replace `.items()` with `.values()`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/redis_cluster_manager.py:342:13
    |
340 |                   await self._check_cluster_health()
341 |                   await asyncio.sleep(self.config.health_check_interval)
342 | /             except asyncio.CancelledError:
343 | |                 break
    | |_____________________^
344 |               except Exception as e:
345 |                   logger.error(f"Error in cluster health monitoring: {e}")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/redis_cluster_manager.py:381:13
    |
379 |                           healthy_nodes += 1
380 |
381 | /             except Exception as e:
382 | |                 health.update_failure(str(e))
383 | |                 logger.warning(f"Health check failed for node {node_id}: {e}")
    | |______________________________________________________________________________^
384 |
385 |           # Update cluster metrics
    |

C901 `shutdown` is too complex (11 > 10)
   --> backend/services/redis_cluster_manager.py:654:15
    |
652 |     # ========================================================================
653 |
654 |     async def shutdown(self):
    |               ^^^^^^^^
655 |         """Shutdown cluster manager and cleanup resources."""
656 |         logger.info("Shutting down Redis cluster manager")
    |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/redis_cluster_manager.py:662:13
    |
660 |           if self._monitoring_task:
661 |               self._monitoring_task.cancel()
662 | /             try:
663 | |                 await self._monitoring_task
664 | |             except asyncio.CancelledError:
665 | |                 pass
    | |____________________^
666 |
667 |           # Close all connections
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/redis_cluster_manager.py:674:13
    |
672 |                   elif hasattr(client, "connection_pool"):
673 |                       await asyncio.to_thread(client.connection_pool.disconnect)
674 | /             except Exception as e:
675 | |                 logger.error(f"Error closing client connection: {e}")
    | |_____________________________________________________________________^
676 |
677 |           if self._cluster_client:
    |

PERF401 Use a list comprehension to create a transformed list
   --> backend/services/redis_cluster_manager.py:705:13
    |
703 |           nodes = []
704 |           for node_config in config_dict.get("nodes", []):
705 | /             nodes.append(
706 | |                 RedisNodeConfig(
707 | |                     host=node_config["host"],
708 | |                     port=node_config["port"],
709 | |                     role=NodeRole(node_config.get("role", "master")),
710 | |                     password=node_config.get("password"),
711 | |                     db=node_config.get("db", 0),
712 | |                     max_connections=node_config.get("max_connections", 100),
713 | |                 )
714 | |             )
    | |_____________^
715 |
716 |           # Parse sentinel nodes if present
    |
help: Replace for loop with list comprehension

PERF401 Use a list comprehension to create a transformed list
   --> backend/services/redis_cluster_manager.py:719:13
    |
717 |           sentinel_nodes = []
718 |           for sentinel_config in config_dict.get("sentinel_nodes", []):
719 | /             sentinel_nodes.append(
720 | |                 RedisNodeConfig(
721 | |                     host=sentinel_config["host"],
722 | |                     port=sentinel_config["port"],
723 | |                     role=NodeRole.SENTINEL,
724 | |                     password=sentinel_config.get("password"),
725 | |                 )
726 | |             )
    | |_____________^
727 |
728 |           # Create cluster config
    |
help: Replace for loop with list comprehension

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/redis_monitoring.py:431:13
    |
429 |           if self.monitoring_task:
430 |               self.monitoring_task.cancel()
431 | /             try:
432 | |                 await self.monitoring_task
433 | |             except asyncio.CancelledError:
434 | |                 pass
    | |____________________^
435 |
436 |           logger.info("Stopped Redis monitoring")
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/redis_monitoring.py:457:13
    |
455 |                   await asyncio.sleep(self.monitoring_interval)
456 |
457 | /             except asyncio.CancelledError:
458 | |                 break
    | |_____________________^
459 |               except Exception as e:
460 |                   logger.error(f"Error in monitoring loop: {e}")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/redis_monitoring.py:601:13
    |
599 |                   else:
600 |                       handler(message, severity, timestamp)
601 | /             except Exception as e:
602 | |                 logger.error(f"Alert handler failed: {e}")
    | |__________________________________________________________^
603 |
604 |       def add_alert_rule(self, rule: AlertRule):
    |

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   --> backend/services/redis_monitoring.py:801:9
    |
800 |       try:
801 | /         async with aiohttp.ClientSession() as session:
802 | |             async with session.post(webhook_url, json=payload) as resp:
    | |_______________________________________________________________________^
803 |                   if resp.status != 200:
804 |                       logger.error(f"Webhook alert failed: {resp.status}")
    |
help: Combine `with` statements

S105 Possible hardcoded password assigned to: "SECRET_ACCESS_COUNT"
  --> backend/services/secrets_monitoring_service.py:58:27
   |
56 |     """Monitoring metrics for secrets."""
57 |
58 |     SECRET_ACCESS_COUNT = "secret_access_count"
   |                           ^^^^^^^^^^^^^^^^^^^^^
59 |     SECRET_ACCESS_FREQUENCY = "secret_access_frequency"
60 |     SECRET_AGE = "secret_age"
   |

S105 Possible hardcoded password assigned to: "SECRET_ACCESS_FREQUENCY"
  --> backend/services/secrets_monitoring_service.py:59:31
   |
58 |     SECRET_ACCESS_COUNT = "secret_access_count"
59 |     SECRET_ACCESS_FREQUENCY = "secret_access_frequency"
   |                               ^^^^^^^^^^^^^^^^^^^^^^^^^
60 |     SECRET_AGE = "secret_age"
61 |     ROTATION_OVERDUE = "rotation_overdue"
   |

S105 Possible hardcoded password assigned to: "SECRET_AGE"
  --> backend/services/secrets_monitoring_service.py:60:18
   |
58 |     SECRET_ACCESS_COUNT = "secret_access_count"
59 |     SECRET_ACCESS_FREQUENCY = "secret_access_frequency"
60 |     SECRET_AGE = "secret_age"
   |                  ^^^^^^^^^^^^
61 |     ROTATION_OVERDUE = "rotation_overdue"
62 |     VALIDATION_FAILURES = "validation_failures"
   |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/secrets_monitoring_service.py:280:13
    |
278 |           if self.monitoring_task and not self.monitoring_task.done():
279 |               self.monitoring_task.cancel()
280 | /             try:
281 | |                 await self.monitoring_task
282 | |             except asyncio.CancelledError:
283 | |                 pass
    | |____________________^
284 |
285 |           if self.cleanup_task and not self.cleanup_task.done():
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/secrets_monitoring_service.py:287:13
    |
285 |           if self.cleanup_task and not self.cleanup_task.done():
286 |               self.cleanup_task.cancel()
287 | /             try:
288 | |                 await self.cleanup_task
289 | |             except asyncio.CancelledError:
290 | |                 pass
    | |____________________^
291 |
292 |           logger.info("Stopped secrets monitoring background tasks")
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/secrets_monitoring_service.py:302:13
    |
300 |                   await self._process_alerts()
301 |                   await asyncio.sleep(30)  # Check every 30 seconds
302 | /             except asyncio.CancelledError:
303 | |                 break
    | |_____________________^
304 |               except Exception as e:
305 |                   logger.error(f"Error in monitoring loop: {e}")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/secrets_monitoring_service.py:314:13
    |
312 |                   await self._cleanup_old_data()
313 |                   await asyncio.sleep(3600)  # Cleanup every hour
314 | /             except asyncio.CancelledError:
315 | |                 break
    | |_____________________^
316 |               except Exception as e:
317 |                   logger.error(f"Error in cleanup loop: {e}")
    |

E722 Do not use bare `except`
   --> backend/services/secrets_monitoring_service.py:450:25
    |
448 |                             )
449 |                             access_times.append(timestamp.hour)
450 |                         except:
    |                         ^^^^^^
451 |                             continue
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> backend/services/secrets_monitoring_service.py:450:25
    |
448 |                               )
449 |                               access_times.append(timestamp.hour)
450 | /                         except:
451 | |                             continue
    | |____________________________________^
452 |
453 |                       # In real implementation, extract IP from request context
    |

S307 Use of possibly insecure function; consider using `ast.literal_eval`
   --> backend/services/secrets_monitoring_service.py:554:20
    |
553 |             # Evaluate the condition
554 |             return eval(condition)
    |                    ^^^^^^^^^^^^^^^
555 |         except Exception as e:
556 |             logger.error(f"Error evaluating condition '{condition}': {e}")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/secrets_monitoring_service.py:778:21
    |
776 |                               f"Sent webhook alert to {webhook_url}: {alert.alert_id}"
777 |                           )
778 | /                     except Exception as e:
779 | |                         logger.error(
780 | |                             f"Failed to send webhook alert to {webhook_url}: {e}"
781 | |                         )
    | |_________________________^
782 |
783 |           except Exception as e:
    |

C901 `validate_secret` is too complex (11 > 10)
   --> backend/services/secrets_validation_service.py:337:15
    |
335 |         }
336 |
337 |     async def validate_secret(
    |               ^^^^^^^^^^^^^^^
338 |         self,
339 |         secret_name: str,
    |

B007 Loop control variable `rule_name` not used within loop body
   --> backend/services/secrets_validation_service.py:379:13
    |
378 |         # Run validation rules
379 |         for rule_name, rule in self.validation_rules.items():
    |             ^^^^^^^^^
380 |             if not rule.enabled:
381 |                 continue
    |
help: Rename unused `rule_name` to `_rule_name`

PERF102 When using only the values of a dict use the `values()` method
   --> backend/services/secrets_validation_service.py:379:32
    |
378 |         # Run validation rules
379 |         for rule_name, rule in self.validation_rules.items():
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^
380 |             if not rule.enabled:
381 |                 continue
    |
help: Replace `.items()` with `.values()`

C416 Unnecessary list comprehension (rewrite using `list()`)
   --> backend/services/secrets_validation_service.py:415:41
    |
413 |             "entropy_bits": calculate_entropy(secret_value),
414 |             "character_classes": self._count_character_classes(secret_value),
415 |             "validation_rules_run": len([r for r in report.validation_results]),
    |                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
416 |             "environment": environment,
417 |             "compliance_standards": [s.value for s in compliance_standards],
    |
help: Rewrite using `list()`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/secrets_validation_service.py:454:13
    |
452 |               try:
453 |                   results[secret_name] = await task
454 | /             except Exception as e:
455 | |                 logger.error(f"Failed to validate secret {secret_name}: {e}")
456 | |                 # Create error report
457 | |                 results[secret_name] = SecretValidationReport(
458 | |                     secret_name=secret_name,
459 | |                     environment=environment,
460 | |                     timestamp=datetime.utcnow(),
461 | |                     overall_status="fail",
462 | |                     validation_results=[
463 | |                         ValidationResult(
464 | |                             rule_name="validation_error",
465 | |                             passed=False,
466 | |                             severity=ValidationSeverity.CRITICAL,
467 | |                             message=f"Validation failed: {str(e)}",
468 | |                         )
469 | |                     ],
470 | |                 )
    | |_________________^
471 |
472 |           return results
    |

C901 `_execute_validation_rule` is too complex (11 > 10)
   --> backend/services/secrets_validation_service.py:474:15
    |
472 |         return results
473 |
474 |     async def _execute_validation_rule(
    |               ^^^^^^^^^^^^^^^^^^^^^^^^
475 |         self,
476 |         rule: ValidationRule,
    |

PERF401 Use a list comprehension to create a transformed list
   --> backend/services/secrets_validation_service.py:621:17
    |
619 |         for pattern in weak_patterns:
620 |             if pattern in secret_lower:
621 |                 found_patterns.append(pattern)
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
622 |
623 |         # Check for sequential patterns if enabled
    |
help: Replace for loop with list comprehension

E722 Do not use bare `except`
   --> backend/services/secrets_validation_service.py:780:9
    |
778 |                 else None
779 |             )
780 |         except:
    |         ^^^^^^
781 |             metadata = None
    |

PERF401 Use a list comprehension to create a transformed list
   --> backend/services/secrets_validation_service.py:939:17
    |
937 |         for seq in alpha_sequences:
938 |             if seq in text_lower or seq[::-1] in text_lower:
939 |                 patterns.append(f"alphabetical_sequence:{seq}")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
940 |
941 |         # Check for numerical sequences
    |
help: Replace for loop with list comprehension

PERF401 Use a list comprehension to create a transformed list
   --> backend/services/secrets_validation_service.py:970:17
    |
968 |         for pattern in keyboard_patterns:
969 |             if pattern in text_lower:
970 |                 patterns.append(f"keyboard_pattern:{pattern}")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
971 |
972 |         return patterns
    |
help: Replace for loop with list comprehension

B007 Loop control variable `secret_name` not used within loop body
    --> backend/services/secrets_validation_service.py:1072:17
     |
1070 |             }
1071 |
1072 |             for secret_name, validation_report in validation_reports.items():
     |                 ^^^^^^^^^^^
1073 |                 status = validation_report.compliance_status.get(
1074 |                     standard, "not_applicable"
     |
help: Rename unused `secret_name` to `_secret_name`

PERF102 When using only the values of a dict use the `values()` method
    --> backend/services/secrets_validation_service.py:1072:51
     |
1070 |             }
1071 |
1072 |             for secret_name, validation_report in validation_reports.items():
     |                                                   ^^^^^^^^^^^^^^^^^^^^^^^^
1073 |                 status = validation_report.compliance_status.get(
1074 |                     standard, "not_applicable"
     |
help: Replace `.items()` with `.values()`

SIM105 Use `contextlib.suppress(ValueError)` instead of `try`-`except`-`pass`
   --> backend/services/simple_alerting_service.py:247:9
    |
245 |       def remove_alert_callback(self, callback: Callable[[Alert], None]):
246 |           """Remove an alert callback."""
247 | /         try:
248 | |             self.alert_callbacks.remove(callback)
249 | |         except ValueError:
250 | |             pass
    | |________________^
251 |
252 |       def evaluate_metrics(self, metrics_data: dict[str, Any]):
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(ValueError): ...`

B007 Loop control variable `category_name` not used within loop body
   --> backend/services/simple_alerting_service.py:296:17
    |
295 |             # Search in nested structures
296 |             for category_name, category_data in metrics_data.items():
    |                 ^^^^^^^^^^^^^
297 |                 if isinstance(category_data, dict) and metric_name in category_data:
298 |                     return float(category_data[metric_name])
    |
help: Rename unused `category_name` to `_category_name`

PERF102 When using only the values of a dict use the `values()` method
   --> backend/services/simple_alerting_service.py:296:49
    |
295 |             # Search in nested structures
296 |             for category_name, category_data in metrics_data.items():
    |                                                 ^^^^^^^^^^^^^^^^^^
297 |                 if isinstance(category_data, dict) and metric_name in category_data:
298 |                     return float(category_data[metric_name])
    |
help: Replace `.items()` with `.values()`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/simple_alerting_service.py:367:17
    |
365 |                   try:
366 |                       callback(alert)
367 | /                 except Exception as e:
368 | |                     logger.error(f"Error in alert callback: {e}")
    | |_________________________________________________________________^
369 |
370 |           except Exception as e:
    |

C901 `process_pdf_streaming` is too complex (12 > 10)
  --> backend/services/streaming_pdf_service.py:52:15
   |
50 |         }
51 |
52 |     async def process_pdf_streaming(
   |               ^^^^^^^^^^^^^^^^^^^^^
53 |         self,
54 |         session: UploadSession,
   |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/streaming_pdf_service.py:211:21
    |
209 |                               }
210 |                           )
211 | /                     except Exception as e:
212 | |                         logger.warning(f"Error processing page {page_idx + 1}: {e}")
213 | |                         # Add empty page to maintain page numbering
214 | |                         chunk_pages.append(
215 | |                             {
216 | |                                 "page_number": page_idx + 1,
217 | |                                 "text": "",
218 | |                                 "metadata": {"error": str(e)},
219 | |                             }
220 | |                         )
    | |_________________________^
221 |
222 |                   yield {
    |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> backend/services/streaming_upload_service.py:89:13
   |
87 |                   await asyncio.sleep(self.cleanup_interval_seconds)
88 |                   await self._cleanup_expired()
89 | /             except asyncio.CancelledError:
90 | |                 break
   | |_____________________^
91 |               except Exception as e:
92 |                   logger.error(f"Error in cleanup task: {e}")
   |

C901 `process_chunk` is too complex (13 > 10)
   --> backend/services/streaming_upload_service.py:254:15
    |
252 |         return optimal_size
253 |
254 |     async def process_chunk(
    |               ^^^^^^^^^^^^^
255 |         self,
256 |         session_id: UUID,
    |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/streaming_upload_service.py:652:13
    |
650 |           if self._cleanup_task and not self._cleanup_task.done():
651 |               self._cleanup_task.cancel()
652 | /             try:
653 | |                 await self._cleanup_task
654 | |             except asyncio.CancelledError:
655 | |                 pass
    | |____________________^
656 |
657 |           # Clean up all active sessions
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

C901 `_analyze_pdf_content_streaming` is too complex (11 > 10)
   --> backend/services/streaming_validation_service.py:226:15
    |
224 |         return result
225 |
226 |     async def _analyze_pdf_content_streaming(
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
227 |         self, file_handle, scan_size: int, chunk_size: int
228 |     ) -> dict:
    |

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> backend/services/streaming_validation_service.py:256:37
    |
254 |             # Security threat tracking
255 |             security_threats = {
256 |                 threat_type: [] for threat_type in self.SECURITY_PATTERNS.keys()
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
257 |             }
    |
help: Remove `.keys()`

B007 Loop control variable `i` not used within loop body
   --> backend/services/streaming_validation_service.py:351:17
    |
349 |             page_pattern = rb"/Type\s*/Page\b"
350 |             page_matches = list(re.finditer(page_pattern, chunk))
351 |             for i, match in enumerate(page_matches):
    |                 ^
352 |                 pages_found.add(match.start())
    |
help: Rename unused `i` to `_i`

PERF401 Use `list.extend` to create a transformed list
   --> backend/services/streaming_validation_service.py:459:33
    |
457 |                           for pattern in patterns:
458 |                               if re.search(pattern, chunk_data[:1024], re.IGNORECASE):
459 | /                                 warnings.append(
460 | |                                     f"Potential {threat_type.replace('_', ' ')} detected in file header"
461 | |                                 )
    | |_________________________________^
462 |
463 |               # Check for null bytes (potential corruption indicator)
    |
help: Replace for loop with list.extend

C901 `trace_decorator` is too complex (13 > 10)
   --> backend/services/tracing_service.py:256:9
    |
254 |             raise
255 |
256 |     def trace_decorator(
    |         ^^^^^^^^^^^^^^^
257 |         self,
258 |         name: str | None = None,
    |

C901 `decorator` is too complex (12 > 10)
   --> backend/services/tracing_service.py:278:13
    |
276 |         """
277 |
278 |         def decorator(func: Callable) -> Callable:
    |             ^^^^^^^^^
279 |             span_name = name or f"{func.__module__}.{func.__name__}"
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/transaction_log_backup.py:248:13
    |
246 |                   await asyncio.sleep(5)  # Check every 5 seconds
247 |
248 | /             except Exception as e:
249 | |                 logger.error(f"Error in WAL archive monitor: {e}")
250 | |                 await asyncio.sleep(10)
    | |_______________________________________^
251 |
252 |       async def _process_wal_file(self, wal_file: Path):
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/transaction_log_backup.py:512:13
    |
510 |                   await asyncio.sleep(3600)
511 |
512 | /             except Exception as e:
513 | |                 logger.error(f"Error in cleanup task: {e}")
514 | |                 await asyncio.sleep(3600)
    | |_________________________________________^
515 |
516 |       async def _parse_wal_file_info(self, wal_file: Path) -> dict[str, Any]:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/transaction_log_backup.py:694:13
    |
692 |                       )
693 |
694 | /             except Exception as e:
695 | |                 logger.error(f"Failed to start backup for {database_id}: {e}")
696 | |                 results[database_id] = False
    | |____________________________________________^
697 |
698 |           return results
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/transaction_log_backup.py:710:13
    |
708 |                   )
709 |
710 | /             except Exception as e:
711 | |                 logger.error(f"Failed to stop backup for {database_id}: {e}")
    | |_____________________________________________________________________________^
712 |
713 |       def get_service_status(self) -> dict[str, Any]:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> backend/services/upload_resumption_service.py:67:13
   |
65 |                   await asyncio.sleep(self.cleanup_interval_minutes * 60)
66 |                   await self._cleanup_expired_resume_data()
67 | /             except asyncio.CancelledError:
68 | |                 break
   | |_____________________^
69 |               except Exception as e:
70 |                   logger.error(f"Error in resumption cleanup task: {e}")
   |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/upload_resumption_service.py:360:17
    |
358 |                               resumable.append(resume_info)
359 |
360 | /                 except (ValueError, KeyError) as e:
361 | |                     logger.debug(f"Skipping invalid state file {state_file}: {e}")
362 | |                     continue
    | |____________________________^
363 |
364 |           except Exception as e:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> backend/services/upload_resumption_service.py:424:17
    |
422 |                                   )
423 |
424 | /                 except Exception as e:
425 | |                     logger.debug(f"Error processing state file {state_file}: {e}")
426 | |                     # Consider the file corrupted, add to cleanup
427 | |                     try:
428 | |                         session_id = UUID(state_file.stem)
429 | |                         expired_sessions.append(session_id)
430 | |                     except ValueError:
431 | |                         # Invalid filename, remove directly
432 | |                         try:
433 | |                             state_file.unlink()
434 | |                             logger.info(f"Removed corrupted state file: {state_file}")
435 | |                         except Exception:
436 | |                             pass
    | |________________________________^
437 |
438 |               # Clean up expired sessions
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> backend/services/upload_resumption_service.py:435:25
    |
433 |                               state_file.unlink()
434 |                               logger.info(f"Removed corrupted state file: {state_file}")
435 | /                         except Exception:
436 | |                             pass
    | |________________________________^
437 |
438 |               # Clean up expired sessions
    |

SIM105 Use `contextlib.suppress(asyncio.CancelledError)` instead of `try`-`except`-`pass`
   --> backend/services/upload_resumption_service.py:469:13
    |
467 |           if self._cleanup_task and not self._cleanup_task.done():
468 |               self._cleanup_task.cancel()
469 | /             try:
470 | |                 await self._cleanup_task
471 | |             except asyncio.CancelledError:
472 | |                 pass
    | |____________________^
473 |
474 |           # Clear memory cache
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(asyncio.CancelledError): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
  --> check_llama_imports.py:34:13
   |
32 |                   else:
33 |                       print(f"  ❌ {name} - Not found")
34 | /             except Exception as e:
35 | |                 print(f"  ❌ {name} - Error: {e}")
   | |__________________________________________________^
36 |
37 |       except Exception as e:
   |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> check_llama_imports.py:68:13
   |
66 |                   else:
67 |                       print(f"  ❌ {name} - Not found")
68 | /             except Exception as e:
69 | |                 print(f"  ❌ {name} - Error: {e}")
   | |__________________________________________________^
70 |
71 |       except Exception as e:
   |

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
   --> check_memory_simple.py:179:13
    |
177 |           file_path = Path(test_file)
178 |           if file_path.exists() and file_path.stat().st_size < 1000:  # Only small test files
179 | /             try:
180 | |                 # file_path.unlink()  # Keep config file for reference
181 | |                 cleaned += 1
182 | |             except:
183 | |                 pass
    | |____________________^
184 |
185 |       if cleaned > 0:
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
   --> check_memory_simple.py:182:13
    |
180 |                 # file_path.unlink()  # Keep config file for reference
181 |                 cleaned += 1
182 |             except:
    |             ^^^^^^
183 |                 pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> check_memory_simple.py:182:13
    |
180 |                   # file_path.unlink()  # Keep config file for reference
181 |                   cleaned += 1
182 | /             except:
183 | |                 pass
    | |____________________^
184 |
185 |       if cleaned > 0:
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> config.py:377:9
    |
375 |                       if api_key and api_key.strip():
376 |                           return api_key.strip()
377 | /         except Exception:
378 | |             pass  # 配置文件不存在或损坏，使用默认值
    | |________________^
379 |
380 |           return None
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> emergency_repair.py:110:13
    |
108 |                   cursor.execute(table_sql)
109 |                   self.log("✓ Table created/verified")
110 | /             except Exception as e:
111 | |                 self.log(f"✗ Table creation failed: {e}")
    | |_________________________________________________________^
112 |
113 |           conn.commit()
    |

W293 Blank line contains whitespace
   --> emergency_repair.py:179:1
    |
177 |     doc_id = str(uuid.uuid4())
178 |     now = datetime.now()
179 |
    | ^^^^
180 |     conn = sqlite3.connect(DB_PATH)
181 |     cursor = conn.cursor()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:182:1
    |
180 |     conn = sqlite3.connect(DB_PATH)
181 |     cursor = conn.cursor()
182 |
    | ^^^^
183 |     cursor.execute("""
184 |         INSERT INTO documents (id, title, content, metadata, created_at, updated_at)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:187:1
    |
185 |         VALUES (?, ?, ?, ?, ?, ?)
186 |     """, (doc_id, doc.title, doc.content, json.dumps(doc.metadata), now, now))
187 |
    | ^^^^
188 |     conn.commit()
189 |     conn.close()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:190:1
    |
188 |     conn.commit()
189 |     conn.close()
190 |
    | ^^^^
191 |     return Document(
192 |         id=doc_id,
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:204:1
    |
202 |     conn = sqlite3.connect(DB_PATH)
203 |     cursor = conn.cursor()
204 |
    | ^^^^
205 |     cursor.execute("""
206 |         SELECT id, title, content, metadata, created_at, updated_at
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:209:1
    |
207 |         FROM documents WHERE id = ?
208 |     """, (doc_id,))
209 |
    | ^^^^
210 |     row = cursor.fetchone()
211 |     conn.close()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:212:1
    |
210 |     row = cursor.fetchone()
211 |     conn.close()
212 |
    | ^^^^
213 |     if not row:
214 |         raise HTTPException(status_code=404, detail="Document not found")
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:215:1
    |
213 |     if not row:
214 |         raise HTTPException(status_code=404, detail="Document not found")
215 |
    | ^^^^
216 |     return Document(
217 |         id=row[0],
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:229:1
    |
227 |     conn = sqlite3.connect(DB_PATH)
228 |     cursor = conn.cursor()
229 |
    | ^^^^
230 |     cursor.execute("""
231 |         SELECT id, title, content, metadata, created_at, updated_at
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:234:1
    |
232 |         FROM documents ORDER BY created_at DESC LIMIT 100
233 |     """)
234 |
    | ^^^^
235 |     rows = cursor.fetchall()
236 |     conn.close()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:237:1
    |
235 |     rows = cursor.fetchall()
236 |     conn.close()
237 |
    | ^^^^
238 |     return [
239 |         Document(
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:259:1
    |
257 |     coll_id = str(uuid.uuid4())
258 |     now = datetime.now()
259 |
    | ^^^^
260 |     conn = sqlite3.connect(DB_PATH)
261 |     cursor = conn.cursor()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:262:1
    |
260 |     conn = sqlite3.connect(DB_PATH)
261 |     cursor = conn.cursor()
262 |
    | ^^^^
263 |     cursor.execute("""
264 |         INSERT INTO collections (id, name, description, created_at, updated_at)
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:267:1
    |
265 |         VALUES (?, ?, ?, ?, ?)
266 |     """, (coll_id, collection.name, collection.description, now, now))
267 |
    | ^^^^
268 |     conn.commit()
269 |     conn.close()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:270:1
    |
268 |     conn.commit()
269 |     conn.close()
270 |
    | ^^^^
271 |     return {
272 |         "id": coll_id,
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:284:1
    |
282 |     index_id = str(uuid.uuid4())
283 |     now = datetime.now()
284 |
    | ^^^^
285 |     conn = sqlite3.connect(DB_PATH)
286 |     cursor = conn.cursor()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:287:1
    |
285 |     conn = sqlite3.connect(DB_PATH)
286 |     cursor = conn.cursor()
287 |
    | ^^^^
288 |     cursor.execute("""
289 |         INSERT INTO multi_document_indexes
    |
help: Remove whitespace from blank line

W291 Trailing whitespace
   --> emergency_repair.py:289:43
    |
288 |     cursor.execute("""
289 |         INSERT INTO multi_document_indexes
    |                                           ^
290 |         (id, collection_id, name, description, config, created_at, updated_at)
291 |         VALUES (?, ?, ?, ?, ?, ?, ?)
    |
help: Remove trailing whitespace

W293 Blank line contains whitespace
   --> emergency_repair.py:301:1
    |
299 |         now
300 |     ))
301 |
    | ^^^^
302 |     conn.commit()
303 |     conn.close()
    |
help: Remove whitespace from blank line

W293 Blank line contains whitespace
   --> emergency_repair.py:304:1
    |
302 |     conn.commit()
303 |     conn.close()
304 |
    | ^^^^
305 |     return {
306 |         "id": index_id,
    |
help: Remove whitespace from blank line

S108 Probable insecure usage of temporary file or directory: "/dev/shm"
  --> gunicorn.conf.py:38:55
   |
37 | # Memory management
38 | worker_tmp_dir = os.getenv("GUNICORN_WORKER_TMP_DIR", "/dev/shm")  # Use RAM for temp files
   |                                                       ^^^^^^^^^^
39 | worker_class_str = worker_class
   |

S108 Probable insecure usage of temporary file or directory: "/tmp/gunicorn.pid"
  --> gunicorn.conf.py:96:42
   |
95 | # PID file
96 | pidfile = os.getenv("GUNICORN_PID_FILE", "/tmp/gunicorn.pid")
   |                                          ^^^^^^^^^^^^^^^^^^^
97 |
98 | # Daemon mode
   |

F811 Redefinition of unused `when_ready` from line 125
   --> gunicorn.conf.py:174:5
    |
174 | def when_ready(server):
    |     ^^^^^^^^^^ `when_ready` redefined here
175 |     """Called when server is ready."""
176 |     server.log.info("Server is ready. Listening on: %s", server.address)
    |
   ::: gunicorn.conf.py:125:5
    |
123 | # ============================================================================
124 |
125 | def when_ready(server):
    |     ---------- previous definition of `when_ready` here
126 |     """Called when the server is started and ready to accept connections."""
127 |     server.log.info("AI PDF Scholar server is ready. Workers: %d", server.num_workers)
    |
help: Remove definition: `when_ready`

UP036 Version block is outdated for minimum Python version
  --> run_complete_uat.py:62:12
   |
61 |         # Check Python version
62 |         if sys.version_info >= (3, 8):
   |            ^^^^^^^^^^^^^^^^^^^^^^^^^^
63 |             prerequisites.append(("Python >= 3.8", True, f"Python {sys.version_info.major}.{sys.version_info.minor}"))
64 |         else:
   |
help: Remove outdated version block

PERF203 `try`-`except` within a loop incurs performance overhead
  --> run_complete_uat.py:77:13
   |
75 |                   __import__(module)
76 |                   prerequisites.append((f"Module: {module}", True, "Available"))
77 | /             except ImportError:
78 | |                 prerequisites.append((f"Module: {module}", False, "Missing"))
   | |_____________________________________________________________________________^
79 |
80 |           # Check database
   |

F841 Local variable `db` is assigned to but never used
  --> run_complete_uat.py:83:13
   |
81 |         try:
82 |             from src.database.connection import DatabaseConnection
83 |             db = DatabaseConnection(":memory:")  # Use memory database for testing
   |             ^^
84 |             prerequisites.append(("Database Connection", True, "Available"))
85 |         except Exception as e:
   |
help: Remove assignment to unused variable `db`

C901 `start_api_server` is too complex (29 > 10)
   --> run_complete_uat.py:105:15
    |
103 |         return all_passed
104 |
105 |     async def start_api_server(self) -> bool:
    |               ^^^^^^^^^^^^^^^^
106 |         """Start API server for testing"""
107 |         if self.args.skip_api:
    |

S602 `subprocess` call with `shell=True` seems safe, but may be changed in the future; consider rewriting without `shell`
   --> run_complete_uat.py:119:30
    |
117 |                 import subprocess
118 |                 try:
119 |                     result = subprocess.run(
    |                              ^^^^^^^^^^^^^^
120 |                         'netstat -ano | findstr :8000',
121 |                         shell=True,
    |

S607 Starting a process with a partial executable path
   --> run_complete_uat.py:120:25
    |
118 |                 try:
119 |                     result = subprocess.run(
120 |                         'netstat -ano | findstr :8000',
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
121 |                         shell=True,
122 |                         capture_output=True,
    |

S602 `subprocess` call with `shell=True` identified, security issue
   --> run_complete_uat.py:134:33
    |
132 |                             logger.info(f"Killing stale processes on port 8000: {pids}")
133 |                             for pid in pids:
134 |                                 subprocess.run(f'taskkill /F /PID {pid}', shell=True, capture_output=True)
    |                                 ^^^^^^^^^^^^^^
135 |                 except:
136 |                     pass  # Ignore errors, proceed anyway
    |

E722 Do not use bare `except`
   --> run_complete_uat.py:135:17
    |
133 |                             for pid in pids:
134 |                                 subprocess.run(f'taskkill /F /PID {pid}', shell=True, capture_output=True)
135 |                 except:
    |                 ^^^^^^
136 |                     pass  # Ignore errors, proceed anyway
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> run_complete_uat.py:135:17
    |
133 |                               for pid in pids:
134 |                                   subprocess.run(f'taskkill /F /PID {pid}', shell=True, capture_output=True)
135 | /                 except:
136 | |                     pass  # Ignore errors, proceed anyway
    | |________________________^
137 |
138 |               # Check if server is already running
    |

E722 Do not use bare `except`
   --> run_complete_uat.py:146:17
    |
144 |                             logger.info("API server already running")
145 |                             return True
146 |                 except:
    |                 ^^^^^^
147 |                     pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> run_complete_uat.py:146:17
    |
144 |                               logger.info("API server already running")
145 |                               return True
146 | /                 except:
147 | |                     pass
    | |________________________^
148 |
149 |               # Start API server using simplified version to avoid database connection issues
    |

S603 `subprocess` call: check for execution of untrusted input
   --> run_complete_uat.py:157:39
    |
156 |             # Capture output for debugging but prevent deadlock
157 |             self.api_server_process = subprocess.Popen(
    |                                       ^^^^^^^^^^^^^^^^
158 |                 cmd,
159 |                 cwd=project_root,
    |

E722 Do not use bare `except`
   --> run_complete_uat.py:189:17
    |
187 |                             output = self.api_server_process.stdout.read(1000)
188 |                             logger.info(f"Server output: {output}")
189 |                 except:
    |                 ^^^^^^
190 |                     pass  # Not critical if we can't read output
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> run_complete_uat.py:189:17
    |
187 |                               output = self.api_server_process.stdout.read(1000)
188 |                               logger.info(f"Server output: {output}")
189 | /                 except:
190 | |                     pass  # Not critical if we can't read output
    | |________________________^
191 |
192 |               # Wait for server to start
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> run_complete_uat.py:222:29
    |
220 |   …                             elif response.status == 500:
221 |   …                                 logger.warning(f"Server responded with 500 at {url}, may have startup issues")
222 | / …                     except aiohttp.ClientConnectorError:
223 | | …                         continue  # Connection refused, server not ready yet
    | |__________________________________^
224 |   …                     except Exception as e:
225 |   …                         logger.debug(f"Error checking {url}: {e}")
    |

S603 `subprocess` call: check for execution of untrusted input
   --> run_complete_uat.py:343:22
    |
341 |         try:
342 |             # Run pytest on the tests directory
343 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
344 |                 [sys.executable, '-m', 'pytest', 'tests/', '-v', '--tb=short'],
345 |                 cwd=project_root,
    |

F841 Local variable `backend_result` is assigned to but never used
   --> run_complete_uat.py:478:13
    |
476 |             print("RUNNING BACKEND SERVICE UAT")
477 |             print("=" * 50)
478 |             backend_result = await self.run_backend_uat()
    |             ^^^^^^^^^^^^^^
479 |
480 |             # Run API UAT
    |
help: Remove assignment to unused variable `backend_result`

F841 Local variable `api_result` is assigned to but never used
   --> run_complete_uat.py:484:13
    |
482 |             print("RUNNING API ENDPOINT UAT")
483 |             print("=" * 50)
484 |             api_result = await self.run_api_uat()
    |             ^^^^^^^^^^
485 |
486 |             # Run PDF workflow UAT
    |
help: Remove assignment to unused variable `api_result`

F841 Local variable `pdf_result` is assigned to but never used
   --> run_complete_uat.py:490:13
    |
488 |             print("RUNNING REAL PDF WORKFLOW UAT")
489 |             print("=" * 50)
490 |             pdf_result = await self.run_pdf_workflow_uat()
    |             ^^^^^^^^^^
491 |
492 |             # Generate comprehensive report
    |
help: Remove assignment to unused variable `pdf_result`

S108 Probable insecure usage of temporary file or directory: "/tmp/ai_pdf_scholar_maintenance"
   --> scripts/alert_response_automation.py:241:37
    |
239 |         try:
240 |             # Check for maintenance mode flag file
241 |             maintenance_file = Path("/tmp/ai_pdf_scholar_maintenance")
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
242 |             return maintenance_file.exists()
243 |         except Exception:
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/alert_response_automation.py:253:9
    |
251 |                   deployment_key = "deployment_in_progress"
252 |                   return self.redis_client.exists(deployment_key)
253 | /         except Exception:
254 | |             pass
    | |________________^
255 |           return False
    |

C901 `handle_memory_pressure` is too complex (15 > 10)
   --> scripts/alert_response_automation.py:261:15
    |
259 |     # ============================================================================
260 |
261 |     async def handle_memory_pressure(self, alert: AlertData) -> RemediationAction:
    |               ^^^^^^^^^^^^^^^^^^^^^^
262 |         """Handle critical memory usage alerts."""
263 |         start_time = time.time()
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:274:36
    |
272 |             if not self.config.TEST_MODE:
273 |                 try:
274 |                     subprocess.run(["sync"], check=True, timeout=30)
    |                                    ^^^^^^^^
275 |                     subprocess.run(
276 |                         ["echo", "3", ">", "/proc/sys/vm/drop_caches"],
    |

S602 `subprocess` call with `shell=True` identified, security issue
   --> scripts/alert_response_automation.py:275:21
    |
273 |                 try:
274 |                     subprocess.run(["sync"], check=True, timeout=30)
275 |                     subprocess.run(
    |                     ^^^^^^^^^^^^^^
276 |                         ["echo", "3", ">", "/proc/sys/vm/drop_caches"],
277 |                         shell=True,
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:276:25
    |
274 |                     subprocess.run(["sync"], check=True, timeout=30)
275 |                     subprocess.run(
276 |                         ["echo", "3", ">", "/proc/sys/vm/drop_caches"],
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
277 |                         shell=True,
278 |                         check=False,
    |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/alert_response_automation.py:308:29
    |
306 |                     try:
307 |                         if not self.config.TEST_MODE:
308 |                             subprocess.run(
    |                             ^^^^^^^^^^^^^^
309 |                                 ["systemctl", "restart", service],
310 |                                 check=True,
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:309:33
    |
307 |                         if not self.config.TEST_MODE:
308 |                             subprocess.run(
309 |                                 ["systemctl", "restart", service],
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
310 |                                 check=True,
311 |                                 timeout=60,
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/alert_response_automation.py:314:21
    |
312 |                               )
313 |                           actions_taken.append(f"restarted_{service}")
314 | /                     except Exception as e:
315 | |                         logger.warning(f"Service restart failed for {service}: {e}")
    | |____________________________________________________________________________________^
316 |
317 |               # 4. Garbage collection trigger
    |

C901 `handle_cpu_pressure` is too complex (14 > 10)
   --> scripts/alert_response_automation.py:359:15
    |
357 |             )
358 |
359 |     async def handle_cpu_pressure(self, alert: AlertData) -> RemediationAction:
    |               ^^^^^^^^^^^^^^^^^^^
360 |         """Handle critical CPU usage alerts."""
361 |         start_time = time.time()
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/alert_response_automation.py:382:17
    |
380 |                               }
381 |                           )
382 | /                 except (psutil.NoSuchProcess, psutil.AccessDenied):
383 | |                     continue
    | |____________________________^
384 |
385 |               # 2. Renice high-CPU processes (make them lower priority)
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:416:25
    |
414 |                 if not self.config.TEST_MODE:
415 |                     subprocess.run(
416 |                         ["systemctl", "stop", "ai-pdf-scholar-indexing"],
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
417 |                         check=False,
418 |                         timeout=30,
    |

C901 `handle_service_down` is too complex (14 > 10)
   --> scripts/alert_response_automation.py:453:15
    |
451 |             )
452 |
453 |     async def handle_service_down(self, alert: AlertData) -> RemediationAction:
    |               ^^^^^^^^^^^^^^^^^^^
454 |         """Handle service down alerts."""
455 |         start_time = time.time()
    |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/alert_response_automation.py:465:26
    |
463 |             # 1. Check service status
464 |             try:
465 |                 result = subprocess.run(
    |                          ^^^^^^^^^^^^^^
466 |                     ["systemctl", "is-active", service_name],
467 |                     capture_output=True,
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:466:21
    |
464 |             try:
465 |                 result = subprocess.run(
466 |                     ["systemctl", "is-active", service_name],
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
467 |                     capture_output=True,
468 |                     text=True,
    |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/alert_response_automation.py:489:33
    |
487 |                         try:
488 |                             if not self.config.TEST_MODE:
489 |                                 subprocess.run(
    |                                 ^^^^^^^^^^^^^^
490 |                                     ["systemctl", "restart", service_name],
491 |                                     check=True,
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:490:37
    |
488 | …                     if not self.config.TEST_MODE:
489 | …                         subprocess.run(
490 | …                             ["systemctl", "restart", service_name],
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
491 | …                             check=True,
492 | …                             timeout=60,
    |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/alert_response_automation.py:505:38
    |
503 | …                     # Wait and check if restart was successful
504 | …                     await asyncio.sleep(5)
505 | …                     result = subprocess.run(
    |                                ^^^^^^^^^^^^^^
506 | …                         ["systemctl", "is-active", service_name],
507 | …                         capture_output=True,
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:506:33
    |
504 | …                     await asyncio.sleep(5)
505 | …                     result = subprocess.run(
506 | …                         ["systemctl", "is-active", service_name],
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
507 | …                         capture_output=True,
508 | …                         text=True,
    |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/alert_response_automation.py:522:29
    |
520 |                     try:
521 |                         if not self.config.TEST_MODE:
522 |                             subprocess.run(
    |                             ^^^^^^^^^^^^^^
523 |                                 ["systemctl", "restart", service_name],
524 |                                 check=True,
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:523:33
    |
521 |                         if not self.config.TEST_MODE:
522 |                             subprocess.run(
523 |                                 ["systemctl", "restart", service_name],
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
524 |                                 check=True,
525 |                                 timeout=60,
    |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/alert_response_automation.py:537:34
    |
535 |                 for dep_service in dependency_services:
536 |                     try:
537 |                         result = subprocess.run(
    |                                  ^^^^^^^^^^^^^^
538 |                             ["systemctl", "is-active", dep_service],
539 |                             capture_output=True,
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:538:29
    |
536 |                     try:
537 |                         result = subprocess.run(
538 |                             ["systemctl", "is-active", dep_service],
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
539 |                             capture_output=True,
540 |                             text=True,
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/alert_response_automation.py:548:21
    |
546 |                           if dep_status not in ["active"]:
547 |                               logger.warning(f"Dependency {dep_service} is {dep_status}")
548 | /                     except Exception:
549 | |                         continue
    | |________________________________^
550 |
551 |               execution_time = time.time() - start_time
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/alert_response_automation.py:548:21
    |
546 |                           if dep_status not in ["active"]:
547 |                               logger.warning(f"Dependency {dep_service} is {dep_status}")
548 | /                     except Exception:
549 | |                         continue
    | |________________________________^
550 |
551 |               execution_time = time.time() - start_time
    |

C901 `handle_cache_performance` is too complex (18 > 10)
   --> scripts/alert_response_automation.py:575:15
    |
573 |             )
574 |
575 |     async def handle_cache_performance(self, alert: AlertData) -> RemediationAction:
    |               ^^^^^^^^^^^^^^^^^^^^^^^^
576 |         """Handle low cache hit rate alerts."""
577 |         start_time = time.time()
    |

B007 Loop control variable `query` not used within loop body
   --> scripts/alert_response_automation.py:605:29
    |
603 |                         # This would make actual API calls to warm the cache
604 |                         # For now, we'll simulate cache warming
605 |                         for query in popular_queries[:5]:  # Warm top 5
    |                             ^^^^^
606 |                             # Make API call to /api/rag/query to warm cache
607 |                             try:
    |
help: Rename unused `query` to `_query`

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/alert_response_automation.py:610:29
    |
608 |                                   # This would be an actual API call in production
609 |                                   actions_taken.append("warmed_cache_for_query")
610 | /                             except Exception:
611 | |                                 continue
    | |________________________________________^
612 |
613 |                   except Exception as e:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/alert_response_automation.py:610:29
    |
608 |                                   # This would be an actual API call in production
609 |                                   actions_taken.append("warmed_cache_for_query")
610 | /                             except Exception:
611 | |                                 continue
    | |________________________________________^
612 |
613 |                   except Exception as e:
    |

C901 `handle_disk_space` is too complex (31 > 10)
   --> scripts/alert_response_automation.py:682:15
    |
680 |             )
681 |
682 |     async def handle_disk_space(self, alert: AlertData) -> RemediationAction:
    |               ^^^^^^^^^^^^^^^^^
683 |         """Handle low disk space alerts."""
684 |         start_time = time.time()
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:696:25
    |
694 |                 if not self.config.TEST_MODE:
695 |                     subprocess.run(
696 |                         ["logrotate", "/etc/logrotate.conf"], check=True, timeout=60
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
697 |                     )
698 |                 actions_taken.append("log_rotation_completed")
    |

S108 Probable insecure usage of temporary file or directory: "/tmp"
   --> scripts/alert_response_automation.py:703:26
    |
702 |             # 2. Clean temporary files
703 |             temp_dirs = ["/tmp", "/var/tmp", Path.home() / ".ai_pdf_scholar" / "temp"]
    |                          ^^^^^^
704 |             total_cleaned = 0
    |

S108 Probable insecure usage of temporary file or directory: "/var/tmp"
   --> scripts/alert_response_automation.py:703:34
    |
702 |             # 2. Clean temporary files
703 |             temp_dirs = ["/tmp", "/var/tmp", Path.home() / ".ai_pdf_scholar" / "temp"]
    |                                  ^^^^^^^^^^
704 |             total_cleaned = 0
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/alert_response_automation.py:722:33
    |
720 |                                           cleaned_count += 1
721 |                                           total_cleaned += 1
722 | /                                 except Exception:
723 | |                                     continue
    | |____________________________________________^
724 |
725 |                           if cleaned_count > 0:
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/alert_response_automation.py:751:33
    |
749 |                                               f"deleted_old_log_{log_file.name}"
750 |                                           )
751 | /                                 except Exception:
752 | |                                     continue
    | |____________________________________________^
753 |               except Exception as e:
754 |                   logger.warning(f"Log cleanup failed: {e}")
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/alert_response_automation.py:774:33
    |
772 |                                               f"deleted_old_backup_{backup_file.name}"
773 |                                           )
774 | /                                 except Exception:
775 | |                                     continue
    | |____________________________________________^
776 |               except Exception as e:
777 |                   logger.warning(f"Application cleanup failed: {e}")
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:783:25
    |
781 |                 if not self.config.TEST_MODE:
782 |                     subprocess.run(
783 |                         ["apt-get", "autoremove", "-y"], check=False, timeout=120
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
784 |                     )
785 |                     subprocess.run(["apt-get", "autoclean"], check=False, timeout=60)
    |

S607 Starting a process with a partial executable path
   --> scripts/alert_response_automation.py:785:36
    |
783 |                         ["apt-get", "autoremove", "-y"], check=False, timeout=120
784 |                     )
785 |                     subprocess.run(["apt-get", "autoclean"], check=False, timeout=60)
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^
786 |                 actions_taken.append("package_cache_cleaned")
787 |             except Exception as e:
    |

C901 `handle_database_performance` is too complex (11 > 10)
   --> scripts/alert_response_automation.py:819:15
    |
817 |             )
818 |
819 |     async def handle_database_performance(self, alert: AlertData) -> RemediationAction:
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
820 |         """Handle slow database query alerts."""
821 |         start_time = time.time()
    |

C901 `handle_error_rate_spike` is too complex (11 > 10)
   --> scripts/alert_response_automation.py:904:15
    |
902 |             )
903 |
904 |     async def handle_error_rate_spike(self, alert: AlertData) -> RemediationAction:
    |               ^^^^^^^^^^^^^^^^^^^^^^^
905 |         """Handle high error rate alerts."""
906 |         start_time = time.time()
    |

C901 `handle_rag_service_down` is too complex (11 > 10)
    --> scripts/alert_response_automation.py:1001:15
     |
 999 |             )
1000 |
1001 |     async def handle_rag_service_down(self, alert: AlertData) -> RemediationAction:
     |               ^^^^^^^^^^^^^^^^^^^^^^^
1002 |         """Handle RAG service unavailable alerts."""
1003 |         start_time = time.time()
     |

S607 Starting a process with a partial executable path
    --> scripts/alert_response_automation.py:1049:25
     |
1047 |                     # Restart the RAG service or reinitialize components
1048 |                     subprocess.run(
1049 |                         ["systemctl", "restart", "ai-pdf-scholar-rag"],
     |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1050 |                         check=False,
1051 |                         timeout=60,
     |

C901 `main` is too complex (13 > 10)
    --> scripts/alert_response_automation.py:1214:11
     |
1214 | async def main():
     |           ^^^^
1215 |     """Main function for running the alert response automation system."""
1216 |     import argparse
     |

SIM118 Use `key in dict` instead of `key in dict.keys()`
    --> scripts/alert_response_automation.py:1316:9
     |
1314 |     print()
1315 |     print("Supported alert types:")
1316 |     for alert_type in automation.remediation_actions.keys():
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1317 |         print(f"  - {alert_type}")
     |
help: Remove `.keys()`

PERF203 `try`-`except` within a loop incurs performance overhead
  --> scripts/api_benchmark.py:88:13
   |
86 |                   await asyncio.sleep(0.01)
87 |
88 | /             except Exception as e:
89 | |                 errors.append(str(e))
90 | |                 logger.warning(f"Request {run + 1} failed: {e}")
   | |________________________________________________________________^
91 |
92 |           if not response_times:
   |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/api_benchmark.py:157:13
    |
155 |                       result
156 |                   )
157 | /             except Exception as e:
158 | |                 logger.error(f"Failed to benchmark {method} {endpoint}: {e}")
159 | |                 results[f"{method}_{endpoint.replace('/', '_').replace('__', '_')}"] = {
160 | |                     "error": str(e)
161 | |                 }
    | |_________________^
162 |
163 |           return results
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/api_benchmark.py:186:13
    |
184 |                       endpoint_key += "_with_params"
185 |                   results[endpoint_key] = result
186 | /             except Exception as e:
187 | |                 logger.error(f"Failed to benchmark {method} {endpoint}: {e}")
188 | |                 endpoint_key = f"{method}_{endpoint.split('?')[0].replace('/', '_').replace('__', '_')}"
189 | |                 results[endpoint_key] = {"error": str(e)}
    | |_________________________________________________________^
190 |
191 |           return results
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/api_benchmark.py:213:13
    |
211 |                   )
212 |                   results[f"POST_rag_query_{i+1}"] = result
213 | /             except Exception as e:
214 | |                 logger.error(f"Failed to benchmark RAG query {i+1}: {e}")
215 | |                 results[f"POST_rag_query_{i+1}"] = {"error": str(e)}
    | |____________________________________________________________________^
216 |
217 |           return results
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/api_benchmark.py:235:13
    |
233 |                       result
234 |                   )
235 | /             except Exception as e:
236 | |                 logger.error(f"Failed to benchmark {method} {endpoint}: {e}")
237 | |                 results[f"{method}_{endpoint.replace('/', '_').replace('__', '_')}"] = {
238 | |                     "error": str(e)
239 | |                 }
    | |_________________^
240 |
241 |           return results
    |

C901 `print_summary` is too complex (17 > 10)
   --> scripts/api_benchmark.py:296:9
    |
294 |         return self.results
295 |
296 |     def print_summary(self):
    |         ^^^^^^^^^^^^^
297 |         """Print comprehensive benchmark summary"""
298 |         print("\n" + "=" * 80)
    |

B007 Loop control variable `endpoint` not used within loop body
   --> scripts/api_benchmark.py:379:17
    |
377 |             if category not in self.results:
378 |                 continue
379 |             for endpoint, result in self.results[category].items():
    |                 ^^^^^^^^
380 |                 if "error" not in result:
381 |                     rt = result.get("response_times_ms", {})
    |
help: Rename unused `endpoint` to `_endpoint`

PERF203 `try`-`except` within a loop incurs performance overhead
  --> scripts/api_docs_sync.py:77:13
   |
75 |                       endpoints.update(file_endpoints)
76 |
77 | /             except Exception as e:
78 | |                 print(f"⚠️  Error parsing {route_file}: {e}")
   | |____________________________________________________________^
79 |
80 |           return endpoints
   |

C901 `_extract_endpoint_info` is too complex (19 > 10)
   --> scripts/api_docs_sync.py:114:9
    |
112 |         return endpoints
113 |
114 |     def _extract_endpoint_info(
    |         ^^^^^^^^^^^^^^^^^^^^^^
115 |         self, decorator: ast.AST, func_node: ast.FunctionDef, lines: list[str]
116 |     ) -> dict[str, Any] | None:
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/api_docs_sync.py:132:9
    |
130 |                   method = decorator.func.attr.upper()
131 |           # Handle direct @get, @post decorators
132 | /         elif isinstance(decorator.func, ast.Name):
133 | |             if decorator.func.id in http_methods:
    | |_________________________________________________^
134 |                   method = decorator.func.id.upper()
    |
help: Combine `if` statements using `and`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/api_docs_sync.py:161:13
    |
159 |                   if isinstance(keyword.value, ast.Constant):
160 |                       metadata["summary"] = keyword.value.value
161 | /             elif keyword.arg == "description":
162 | |                 if isinstance(keyword.value, ast.Constant):
    | |___________________________________________________________^
163 |                       metadata["description"] = keyword.value.value
    |
help: Combine `if` statements using `and`

E722 Do not use bare `except`
   --> scripts/api_docs_sync.py:219:9
    |
217 |                     else str(annotation)
218 |                 )
219 |         except:
    |         ^^^^^^
220 |             return str(type(annotation).__name__)
    |

B007 Loop control variable `endpoint_key` not used within loop body
   --> scripts/api_docs_sync.py:388:17
    |
386 |             md_content.append(f"### {prefix.title()} Endpoints\n")
387 |
388 |             for endpoint_key, endpoint in sorted(group_endpoints):
    |                 ^^^^^^^^^^^^
389 |                 method = endpoint["method"]
390 |                 path = endpoint["path"]
    |
help: Rename unused `endpoint_key` to `_endpoint_key`

B007 Loop control variable `doc_name` not used within loop body
   --> scripts/api_docs_sync.py:497:13
    |
496 |         # Check if documentation files exist
497 |         for doc_name, doc_path in self.doc_files.items():
    |             ^^^^^^^^
498 |             if not doc_path.exists():
499 |                 issues.append(f"Missing documentation file: {doc_path}")
    |
help: Rename unused `doc_name` to `_doc_name`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/api_docs_sync.py:497:35
    |
496 |         # Check if documentation files exist
497 |         for doc_name, doc_path in self.doc_files.items():
    |                                   ^^^^^^^^^^^^^^^^^^^^
498 |             if not doc_path.exists():
499 |                 issues.append(f"Missing documentation file: {doc_path}")
    |
help: Replace `.items()` with `.values()`

PERF401 Use `list.extend` to create a transformed list
   --> scripts/apply_endpoint_security.py:315:13
    |
313 |         report.append("### Unprotected Endpoints (Action Required)")
314 |         for endpoint in unprotected:
315 |             report.append(f"- {endpoint['method']} {endpoint['path']}")
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
316 |         report.append("")
    |
help: Replace for loop with list.extend

C901 `main` is too complex (14 > 10)
   --> scripts/apply_endpoint_security.py:329:5
    |
329 | def main():
    |     ^^^^
330 |     """Main function to apply security to all endpoints."""
331 |     print("🔒 Applying Security to API Endpoints")
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/test_backup.txt"
   --> scripts/backup_encryption_service.py:714:22
    |
713 |     # Test encryption/decryption
714 |     test_file = Path("/tmp/test_backup.txt")
    |                      ^^^^^^^^^^^^^^^^^^^^^^
715 |     encrypted_file = Path("/tmp/test_backup.txt.enc")
716 |     decrypted_file = Path("/tmp/test_backup_decrypted.txt")
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/test_backup.txt.enc"
   --> scripts/backup_encryption_service.py:715:27
    |
713 |     # Test encryption/decryption
714 |     test_file = Path("/tmp/test_backup.txt")
715 |     encrypted_file = Path("/tmp/test_backup.txt.enc")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^
716 |     decrypted_file = Path("/tmp/test_backup_decrypted.txt")
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/test_backup_decrypted.txt"
   --> scripts/backup_encryption_service.py:716:27
    |
714 |     test_file = Path("/tmp/test_backup.txt")
715 |     encrypted_file = Path("/tmp/test_backup.txt.enc")
716 |     decrypted_file = Path("/tmp/test_backup_decrypted.txt")
    |                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
717 |
718 |     # Create test file
    |

F841 Local variable `result` is assigned to but never used
   --> scripts/backup_orchestrator.py:297:17
    |
295 |             if backup_type == BackupType.FULL:
296 |                 # Trigger background save
297 |                 result = redis_client.bgsave()
    |                 ^^^^^^
298 |
299 |                 # Wait for background save to complete
    |
help: Remove assignment to unused variable `result`

C901 `create_backup` is too complex (12 > 10)
   --> scripts/backup_orchestrator.py:616:15
    |
614 |         return retention_map.get(backup_type, timedelta(days=7))
615 |
616 |     async def create_backup(
    |               ^^^^^^^^^^^^^
617 |         self,
618 |         source: BackupSource,
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/backup_orchestrator.py:865:13
    |
863 |                           logger.error(f"Backup failed: {source.name}")
864 |
865 | /             except Exception as e:
866 | |                 logger.error(f"Error backing up {source.name}: {e}")
    | |____________________________________________________________________^
867 |
868 |           # Clean up expired backups
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/backup_orchestrator.py:888:13
    |
886 |                   await asyncio.sleep(sleep_time)
887 |
888 | /             except Exception as e:
889 | |                 logger.error(f"Error in backup orchestrator main loop: {e}")
890 | |                 await asyncio.sleep(60)  # Wait before retrying
    | |_______________________________________^
891 |
892 |       def stop_orchestrator(self):
    |

F841 Local variable `is_pdf` is assigned to but never used
   --> scripts/benchmark_streaming_upload.py:109:9
    |
108 |         # Simulate validation
109 |         is_pdf = file_data.startswith(b"%PDF-")
    |         ^^^^^^
110 |
111 |         # Calculate hash (simulating integrity check)
    |
help: Remove assignment to unused variable `is_pdf`

F841 Local variable `file_hash` is assigned to but never used
   --> scripts/benchmark_streaming_upload.py:114:9
    |
112 |         import hashlib
113 |
114 |         file_hash = hashlib.sha256(file_data).hexdigest()
    |         ^^^^^^^^^
115 |
116 |         memory_monitor.sample("Processing complete")
    |
help: Remove assignment to unused variable `file_hash`

F841 Local variable `validation_result` is assigned to but never used
   --> scripts/benchmark_streaming_upload.py:212:13
    |
210 |         # Validate final file
211 |         if session.temp_file_path:
212 |             validation_result = await validation_service.validate_streaming_upload(
    |             ^^^^^^^^^^^^^^^^^
213 |                 session.temp_file_path
214 |             )
    |
help: Remove assignment to unused variable `validation_result`

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   --> scripts/benchmark_suite.py:228:21
    |
226 |               for run in range(runs):
227 |                   try:
228 | /                     with BenchmarkTimer(self.monitor) as timer:
229 | |                         # Simulate PDF processing operations
230 | |                         # In a real scenario, this would use PyPDF2, pdfplumber, or similar
231 | |                         with open(pdf_file, "rb") as f:
    | |_______________________________________________________^
232 |                               content = f.read()
233 |                               # Simulate text extraction processing
    |
help: Combine `with` statements

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/benchmark_suite.py:253:17
    |
251 |                       metrics.append(metric)
252 |
253 | /                 except Exception as e:
254 | |                     logger.warning(f"PDF processing failed for {pdf_file}: {e}")
255 | |                     continue
    | |____________________________^
256 |
257 |               if metrics:
    |

S306 Use of insecure and deprecated function (`mktemp`)
   --> scripts/benchmark_suite.py:289:35
    |
288 |     def __init__(self, db_path: str | None = None):
289 |         self.db_path = db_path or tempfile.mktemp(suffix=".db")
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
290 |         self.cleanup_db = db_path is None
291 |         self.monitor = PerformanceMonitor()
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/benchmark_suite.py:506:17
    |
504 |                       )
505 |
506 | /                 except Exception as e:
507 | |                     logger.warning(f"Query {query_name} failed on run {run}: {e}")
508 | |                     continue
    | |____________________________^
509 |
510 |               if metrics:
    |

S306 Use of insecure and deprecated function (`mktemp`)
   --> scripts/benchmark_suite.py:633:35
    |
632 |     def __init__(self, db_path: str | None = None):
633 |         self.db_path = db_path or tempfile.mktemp(suffix="_concurrent.db")
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
634 |         self.cleanup_db = db_path is None
635 |         self.monitor = PerformanceMonitor()
    |

B006 Do not use mutable data structures for argument defaults
   --> scripts/benchmark_suite.py:638:42
    |
637 |     def benchmark_concurrent_operations(
638 |         self, thread_counts: list[int] = [1, 2, 4, 8], operations_per_thread: int = 10
    |                                          ^^^^^^^^^^^^
639 |     ) -> list[BenchmarkResult]:
640 |         """Benchmark operations under different concurrency levels."""
    |
help: Replace with `None`; initialize within function

F841 Local variable `created_doc` is assigned to but never used
   --> scripts/benchmark_suite.py:671:21
    |
669 |                         metadata={"worker": worker_id, "concurrent": True},
670 |                     )
671 |                     created_doc = doc_repo.create(doc)
    |                     ^^^^^^^^^^^
672 |
673 |                     end = time.perf_counter()
    |
help: Remove assignment to unused variable `created_doc`

B023 Function definition does not bind loop variable `doc_repo`
   --> scripts/benchmark_suite.py:671:35
    |
669 |                         metadata={"worker": worker_id, "concurrent": True},
670 |                     )
671 |                     created_doc = doc_repo.create(doc)
    |                                   ^^^^^^^^
672 |
673 |                     end = time.perf_counter()
    |

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   --> scripts/benchmark_suite.py:679:13
    |
678 |               # Run concurrent operations
679 | /             with BenchmarkTimer(self.monitor) as timer:
680 | |                 with concurrent.futures.ThreadPoolExecutor(
681 | |                     max_workers=thread_count
682 | |                 ) as executor:
    | |______________________________^
683 |                       futures = [
684 |                           executor.submit(worker_task, worker_id, operations_per_thread)
    |
help: Combine `with` statements

S607 Starting a process with a partial executable path
  --> scripts/benchmark_tests.py:54:13
   |
52 |           # Run optimized unit tests
53 |           result = subprocess.run(
54 | /             [
55 | |                 "python",
56 | |                 "-m",
57 | |                 "pytest",
58 | |                 "tests/",
59 | |                 "-m",
60 | |                 "unit",
61 | |                 "-v",
62 | |                 "--tb=no",
63 | |                 "--disable-warnings",
64 | |                 "-n",
65 | |                 "auto",
66 | |                 "--dist=loadfile",
67 | |             ],
   | |_____________^
68 |               cwd=self.project_root,
69 |               capture_output=True,
   |

S607 Starting a process with a partial executable path
   --> scripts/benchmark_tests.py:95:13
    |
 93 |           # Run comprehensive tests
 94 |           result = subprocess.run(
 95 | /             [
 96 | |                 "python",
 97 | |                 "-m",
 98 | |                 "pytest",
 99 | |                 "test_comprehensive.py",
100 | |                 "-v",
101 | |                 "--tb=no",
102 | |                 "--disable-warnings",
103 | |                 "--timeout=120",
104 | |             ],
    | |_____________^
105 |               cwd=self.project_root,
106 |               capture_output=True,
    |

S607 Starting a process with a partial executable path
   --> scripts/benchmark_tests.py:130:13
    |
128 |           # Run database tests with optimized fixtures
129 |           result = subprocess.run(
130 | /             [
131 | |                 "python",
132 | |                 "-m",
133 | |                 "pytest",
134 | |                 "tests/test_database_connection_optimized.py",
135 | |                 "-v",
136 | |                 "--tb=no",
137 | |                 "--disable-warnings",
138 | |                 "-n",
139 | |                 "auto",
140 | |             ],
    | |_____________^
141 |               cwd=self.project_root,
142 |               capture_output=True,
    |

S607 Starting a process with a partial executable path
   --> scripts/benchmark_tests.py:184:13
    |
183 |           subprocess.run(
184 | /             [
185 | |                 "python",
186 | |                 "-m",
187 | |                 "pytest",
188 | |                 "tests/test_database_connection_optimized.py",
189 | |                 "--tb=no",
190 | |                 "--disable-warnings",
191 | |                 "-q",
192 | |             ],
    | |_____________^
193 |               cwd=self.project_root,
194 |               capture_output=True,
    |

S607 Starting a process with a partial executable path
   --> scripts/benchmark_tests.py:204:13
    |
203 |           subprocess.run(
204 | /             [
205 | |                 "python",
206 | |                 "-m",
207 | |                 "pytest",
208 | |                 "tests/test_database_connection_optimized.py",
209 | |                 "--tb=no",
210 | |                 "--disable-warnings",
211 | |                 "-n",
212 | |                 "auto",
213 | |                 "--dist=loadfile",
214 | |                 "-q",
215 | |             ],
    | |_____________^
216 |               cwd=self.project_root,
217 |               capture_output=True,
    |

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> scripts/cache_analytics.py:242:13
    |
240 |             return dict(patterns)
241 |
242 |         for key in self.smart_cache.key_profiles.keys():
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
243 |             # Extract pattern from key
244 |             if ":" in key:
    |
help: Remove `.keys()`

B007 Loop control variable `key` not used within loop body
   --> scripts/cache_analytics.py:284:13
    |
283 |         # Analyze historical access data
284 |         for key, accesses in self.key_access_history.items():
    |             ^^^
285 |             for timestamp, hit in accesses:
286 |                 hour = timestamp.hour
    |
help: Rename unused `key` to `_key`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/cache_analytics.py:284:30
    |
283 |         # Analyze historical access data
284 |         for key, accesses in self.key_access_history.items():
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
285 |             for timestamp, hit in accesses:
286 |                 hour = timestamp.hour
    |
help: Replace `.items()` with `.values()`

B007 Loop control variable `key` not used within loop body
   --> scripts/cache_analytics.py:305:13
    |
303 |         daily_data = defaultdict(lambda: {"hits": 0, "total": 0})
304 |
305 |         for key, accesses in self.key_access_history.items():
    |             ^^^
306 |             for timestamp, hit in accesses:
307 |                 day = timestamp.strftime("%A")  # Day name
    |
help: Rename unused `key` to `_key`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/cache_analytics.py:305:30
    |
303 |         daily_data = defaultdict(lambda: {"hits": 0, "total": 0})
304 |
305 |         for key, accesses in self.key_access_history.items():
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
306 |             for timestamp, hit in accesses:
307 |                 day = timestamp.strftime("%A")  # Day name
    |
help: Replace `.items()` with `.values()`

PERF401 Use a list comprehension to create a transformed list
   --> scripts/cache_analytics.py:604:13
    |
602 |           df_data = []
603 |           for metric in self.historical_metrics:
604 | /             df_data.append(
605 | |                 {
606 | |                     "timestamp": metric.timestamp,
607 | |                     "hit_rate": metric.hit_rate_percent,
608 | |                     "response_time": metric.avg_response_time_ms,
609 | |                     "memory_utilization": metric.memory_utilization_percent,
610 | |                 }
611 | |             )
    | |_____________^
612 |
613 |           df = pd.DataFrame(df_data)
    |
help: Replace for loop with list comprehension

B007 Loop control variable `hit` not used within loop body
   --> scripts/cache_analytics.py:704:28
    |
703 |         for accesses in self.key_access_history.values():
704 |             for timestamp, hit in accesses:
    |                            ^^^
705 |                 hourly_accesses[timestamp.hour] += 1
706 |                 daily_accesses[timestamp.strftime("%A")] += 1
    |
help: Rename unused `hit` to `_hit`

PERF401 Use `list.extend` to create a transformed list
   --> scripts/cache_analytics.py:815:17
    |
813 |             next_steps.append("Address critical issues immediately:")
814 |             for rec in critical_recs[:3]:  # Top 3 critical
815 |                 next_steps.append(f"  - {rec.title}: {rec.description}")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
816 |
817 |         if high_recs:
    |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
   --> scripts/cache_analytics.py:820:17
    |
818 |             next_steps.append("Plan high-priority improvements:")
819 |             for rec in high_recs[:3]:  # Top 3 high-priority
820 |                 next_steps.append(f"  - {rec.title}: {rec.description}")
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
821 |
822 |         # Add general recommendations
    |
help: Replace for loop with list.extend

C901 `validate_performance_thresholds` is too complex (15 > 10)
  --> scripts/ci_performance_check.py:90:9
   |
88 |             raise
89 |
90 |     def validate_performance_thresholds(self, results: dict[str, Any]) -> bool:
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
91 |         """Validate performance results against CI thresholds"""
92 |         logger.info("Validating performance against CI thresholds...")
   |

C901 `main` is too complex (11 > 10)
   --> scripts/ci_performance_check.py:294:5
    |
294 | def main():
    |     ^^^^
295 |     """Main entry point for CI performance validation"""
296 |     import argparse
    |

S607 Starting a process with a partial executable path
   --> scripts/ci_performance_optimizer.py:173:49
    |
171 |         try:
172 |             # Get CPU information
173 |             cpu_count = subprocess.check_output(["nproc"], text=True).strip()
    |                                                 ^^^^^^^^^
174 |
175 |             # Get memory information
    |

S607 Starting a process with a partial executable path
   --> scripts/ci_performance_optimizer.py:176:51
    |
175 |             # Get memory information
176 |             memory_info = subprocess.check_output(["free", "-m"], text=True)
    |                                                   ^^^^^^^^^^^^^^
177 |             memory_lines = memory_info.strip().split("\n")
178 |             memory_data = memory_lines[1].split()
    |

S607 Starting a process with a partial executable path
   --> scripts/ci_performance_optimizer.py:182:49
    |
181 |             # Get disk information
182 |             disk_info = subprocess.check_output(["df", "-h", "."], text=True)
    |                                                 ^^^^^^^^^^^^^^^^^
183 |             disk_lines = disk_info.strip().split("\n")
184 |             disk_data = disk_lines[1].split()
    |

C901 `_execute_check` is too complex (17 > 10)
   --> scripts/compliance_validator.py:370:9
    |
368 |         )
369 |
370 |     def _execute_check(self, check_type: str) -> dict[str, Any]:
    |         ^^^^^^^^^^^^^^
371 |         """Execute a specific compliance check"""
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/compliance_validator.py:548:21
    |
546 |                           if found_patterns:
547 |                               auth_implementations.extend(found_patterns)
548 | /                     except Exception:
549 | |                         continue
    | |________________________________^
550 |
551 |           unique_implementations = list(set(auth_implementations))
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/compliance_validator.py:587:21
    |
585 |                           if file_patterns:
586 |                               found_patterns.extend(file_patterns)
587 | /                     except Exception:
588 | |                         continue
    | |________________________________^
589 |
590 |           unique_patterns = list(set(found_patterns))
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/compliance_validator.py:617:21
    |
615 |                           if file_mfa:
616 |                               found_mfa.extend(file_mfa)
617 | /                     except Exception:
618 | |                         continue
    | |________________________________^
619 |
620 |           if found_mfa:
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/compliance_validator.py:654:21
    |
652 |                           if file_crypto:
653 |                               found_crypto.extend(file_crypto)
654 | /                     except Exception:
655 | |                         continue
    | |________________________________^
656 |
657 |           if found_crypto or encryption_files:
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/compliance_validator.py:704:17
    |
702 |                       if "import logging" in content or "logger." in content:
703 |                           logging_usage += 1
704 | /                 except Exception:
705 | |                     continue
    | |____________________________^
706 |
707 |           evidence.append(f"Files using logging: {logging_usage}")
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/compliance_validator.py:729:21
    |
727 |                           if any(term in content for term in backup_docs):
728 |                               found_backup_docs.append(str(doc_file.name))
729 | /                     except Exception:
730 | |                         continue
    | |________________________________^
731 |
732 |           if found_backup_docs:
    |

PERF401 Use a list comprehension to create a transformed list
   --> scripts/compliance_validator.py:782:21
    |
780 |                     for term in ["deploy", "release", "quality", "security"]
781 |                 ):
782 |                     change_mgmt_workflows.append(workflow_file.name)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
783 |
784 |             if change_mgmt_workflows:
    |
help: Replace for loop with list comprehension

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/compliance_validator.py:838:13
    |
836 |                   ):
837 |                       security_tools_in_reqs.append(req_file.name)
838 | /             except Exception:
839 | |                 continue
    | |________________________^
840 |
841 |           if security_tools_in_reqs:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/compliance_validator.py:838:13
    |
836 |                   ):
837 |                       security_tools_in_reqs.append(req_file.name)
838 | /             except Exception:
839 | |                 continue
    | |________________________^
840 |
841 |           if security_tools_in_reqs:
    |

PERF401 Use a list comprehension to create a transformed list
   --> scripts/compliance_validator.py:883:17
    |
881 |                 for term in ["security", "scan", "audit"]
882 |             ):
883 |                 security_workflows.append(workflow_file.name)
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
884 |
885 |         if security_workflows:
    |
help: Replace for loop with list comprehension

E722 Do not use bare `except`
  --> scripts/comprehensive_performance_suite.py:86:17
   |
84 |                     response = await client.get(f"{base_url}/health", timeout=5.0)
85 |                     server_available = response.status_code < 500
86 |                 except:
   |                 ^^^^^^
87 |                     server_available = False
   |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/comprehensive_performance_suite.py:105:22
    |
103 |                 "--save",
104 |             ]
105 |             result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path.cwd())
    |                      ^^^^^^^^^^^^^^
106 |
107 |             if result.returncode != 0:
    |

B007 Loop control variable `run` not used within loop body
   --> scripts/comprehensive_performance_suite.py:157:21
    |
155 |                 processing_times = []
156 |
157 |                 for run in range(10):
    |                     ^^^
158 |                     start_time = time.perf_counter()
    |
help: Rename unused `run` to `_run`

PERF401 Use a list comprehension to create a transformed list
   --> scripts/comprehensive_performance_suite.py:206:17
    |
204 |         for item in results[category]:
205 |             if metric in item:
206 |                 values.append(item[metric])
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
207 |
208 |         if values:
    |
help: Replace for loop with list comprehension

C901 `print_comprehensive_summary` is too complex (22 > 10)
   --> scripts/comprehensive_performance_suite.py:303:9
    |
301 |             return {"error": str(e)}
302 |
303 |     def print_comprehensive_summary(self):
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
304 |         """Print comprehensive performance summary"""
305 |         print("\n" + "=" * 100)
    |

B007 Loop control variable `version` not used within loop body
   --> scripts/convert_remaining_migrations.py:809:9
    |
807 |     ]
808 |
809 |     for version, filename, creator_func in migrations:
    |         ^^^^^^^
810 |         file_path = versions_dir / filename
    |
help: Rename unused `version` to `_version`

E722 Do not use bare `except`
   --> scripts/cost_optimizer.py:184:13
    |
182 |                     else 50
183 |                 )
184 |             except:
    |             ^^^^^^
185 |                 memory_utilization = 50  # Default estimate
    |

E722 Do not use bare `except`
   --> scripts/cost_optimizer.py:239:13
    |
237 |                     + sum([m["Sum"] for m in disk_write["Datapoints"]])
238 |                 ) / (1024 * 1024 * 1024)  # Convert to GB
239 |             except:
    |             ^^^^^^
240 |                 disk_io = 0
    |

C901 `main` is too complex (12 > 10)
   --> scripts/cost_optimizer.py:793:11
    |
792 | # CLI interface
793 | async def main():
    |           ^^^^
794 |     """Main entry point for cost optimizer"""
795 |     import argparse
    |

C401 Unnecessary generator (rewrite as a set comprehension)
   --> scripts/data_consistency_validator.py:182:33
    |
180 |                     raise ValueError("Unsupported database type")
181 |
182 |                 actual_tables = set(row[0] for row in result.fetchall())
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
183 |                 expected_tables_set = set(expected_tables)
    |
help: Rewrite as a set comprehension

S608 Possible SQL injection vector through string-based query construction
   --> scripts/data_consistency_validator.py:317:52
    |
315 |                     try:
316 |                         # Safe: table names are from admin configuration, not user input
317 |                         result = conn.execute(text(f"SELECT COUNT(*) FROM {table}"))
    |                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
318 |                         actual_count = result.scalar()
319 |                         actual_counts[table] = actual_count
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/data_consistency_validator.py:325:21
    |
323 |                                   f"Table {table}: expected >= {expected_count}, got {actual_count}"
324 |                               )
325 | /                     except Exception as e:
326 | |                         count_issues.append(
327 | |                             f"Table {table}: count check failed - {str(e)}"
328 | |                         )
    | |_________________________^
329 |
330 |                   check_result.details["actual_counts"] = actual_counts
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/data_consistency_validator.py:381:17
    |
379 |                       else:
380 |                           inaccessible_paths.append(f"{path} (does not exist)")
381 | /                 except PermissionError:
382 | |                     inaccessible_paths.append(f"{path} (permission denied)")
    | |____________________________________________________________________________^
383 |                   except Exception as e:
384 |                       inaccessible_paths.append(f"{path} ({str(e)})")
    |

C901 `validate_file_integrity` is too complex (14 > 10)
   --> scripts/data_consistency_validator.py:410:15
    |
408 |         return check_result
409 |
410 |     async def validate_file_integrity(
    |               ^^^^^^^^^^^^^^^^^^^^^^^
411 |         self, checksum_file: str | None = None, sample_size: int = 100
412 |     ) -> CheckResult:
    |

PERF401 Use a list comprehension to create a transformed list
   --> scripts/data_consistency_validator.py:597:21
    |
595 |             for key in required_keys:
596 |                 if key not in self.config:
597 |                     config_issues.append(f"Missing required config key: {key}")
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
598 |
599 |             # Check configuration file accessibility
    |
help: Replace for loop with list comprehension

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/data_consistency_validator.py:655:21
    |
653 |                                       f"{endpoint} (status: {response.status})"
654 |                                   )
655 | /                     except Exception as e:
656 | |                         unhealthy_services.append(f"{endpoint} (error: {str(e)})")
    | |__________________________________________________________________________________^
657 |
658 |               check_result.details["healthy_services"] = healthy_services
    |

C901 `run_validation` is too complex (14 > 10)
   --> scripts/data_consistency_validator.py:727:15
    |
725 |         logger.info(f"Custom validation check added: {check.name}")
726 |
727 |     async def run_validation(
    |               ^^^^^^^^^^^^^^
728 |         self,
729 |         consistency_level: ConsistencyLevel = ConsistencyLevel.STRUCTURAL,
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/data_consistency_validator.py:887:21
    |
885 |                           result = await task
886 |                           report.check_results.append(result)
887 | /                     except Exception as e:
888 | |                         error_result = CheckResult(
889 | |                             check_id=task_name,
890 | |                             result=ValidationResult.ERROR,
891 | |                             start_time=datetime.utcnow(),
892 | |                             end_time=datetime.utcnow(),
893 | |                             message=f"Task execution error: {str(e)}",
894 | |                             errors=[str(e)],
895 | |                         )
896 | |                         report.check_results.append(error_result)
    | |_________________________________________________________________^
897 |
898 |               # Process results and generate report
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/test"
    --> scripts/data_consistency_validator.py:1047:47
     |
1045 |     # Register validators
1046 |     validator.register_database_validation("sqlite:///test.db")
1047 |     validator.register_filesystem_validation(["/tmp/test", "/app/data"])
     |                                               ^^^^^^^^^^^
1048 |     validator.register_application_validation(
1049 |         {
     |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/database_load_balancer.py:241:13
    |
239 |                   )
240 |
241 | /             except Exception as e:
242 | |                 logger.error(f"Failed to initialize server {server.server_id}: {e}")
243 | |                 server.metrics.state = ServerState.FAILED
    | |_________________________________________________________^
244 |
245 |       def _initialize_consistent_hashing(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/database_load_balancer.py:310:13
    |
308 |                   self._update_circuit_breakers()
309 |                   self._adjust_server_weights()
310 | /             except Exception as e:
311 | |                 logger.error(f"Health monitor error: {e}")
    | |__________________________________________________________^
312 |
313 |       def _metrics_collector_worker(self) -> None:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/database_load_balancer.py:319:13
    |
317 |                   self._collect_server_metrics()
318 |                   self._cleanup_old_metrics()
319 | /             except Exception as e:
320 | |                 logger.error(f"Metrics collector error: {e}")
    | |_____________________________________________________________^
321 |
322 |       def _perform_health_checks(self) -> None:
    |

F841 Local variable `result` is assigned to but never used
   --> scripts/database_load_balancer.py:338:21
    |
336 |                 try:
337 |                     cursor = managed_conn.connection.execute("SELECT 1 as health_check")
338 |                     result = cursor.fetchone()
    |                     ^^^^^^
339 |                     health_check_time = (time.time() - start_time) * 1000
    |
help: Remove assignment to unused variable `result`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/database_load_balancer.py:395:13
    |
393 |                       logger.info(f"Circuit breaker for {server_id} moved to CLOSED")
394 |
395 | /             elif cb_state["state"] == "CLOSED":
396 | |                 # Check if we should open due to failures
397 | |                 if (
398 | |                     server.metrics.state == ServerState.FAILED
399 | |                     and cb_state["failure_count"] >= cb_state["failure_threshold"]
400 | |                 ):
    | |__________________^
401 |                       cb_state["state"] = "OPEN"
402 |                       cb_state["next_attempt_time"] = (
    |
help: Combine `if` statements using `and`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/database_load_balancer.py:429:17
    |
427 |                               )
428 |
429 | /                 except Exception as e:
430 | |                     logger.debug(
431 | |                         f"Failed to collect metrics for {server.server_id}: {e}"
432 | |                     )
    | |_____________________^
433 |
434 |       def _adjust_server_weights(self) -> None:
    |

C901 `select_server` is too complex (12 > 10)
   --> scripts/database_load_balancer.py:488:9
    |
486 |                     self._error_rates[server_id] = deque(recent_errors, maxlen=100)
487 |
488 |     def select_server(self, request: LoadBalancingRequest) -> RoutingDecision:
    |         ^^^^^^^^^^^^^
489 |         """
490 |         Select the best server for a request based on the current strategy.
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> scripts/database_load_balancer.py:624:25
    |
623 |         # Generate weighted random selection
624 |         random_weight = random.randint(1, total_weight)
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
625 |
626 |         cumulative_weight = 0
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
    --> scripts/database_load_balancer.py:1060:30
     |
1058 |                     client_id=f"client_{i % 3}",
1059 |                     session_id=f"session_{i % 5}",
1060 |                     priority=random.randint(1, 10),
     |                              ^^^^^^^^^^^^^^^^^^^^^
1061 |                 )
     |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
    --> scripts/database_load_balancer.py:1072:37
     |
1071 |                     # Simulate request completion
1072 |                     response_time = random.uniform(10, 200)
     |                                     ^^^^^^^^^^^^^^^^^^^^^^^
1073 |                     success = random.random() > 0.1  # 90% success rate
     |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
    --> scripts/database_load_balancer.py:1073:31
     |
1071 |                     # Simulate request completion
1072 |                     response_time = random.uniform(10, 200)
1073 |                     success = random.random() > 0.1  # 90% success rate
     |                               ^^^^^^^^^^^^^^^
1074 |
1075 |                     load_balancer.record_request_result(
     |

SIM115 Use a context manager for opening files
  --> scripts/database_performance_benchmark.py:62:30
   |
60 |             self.cleanup_db = False
61 |         else:
62 |             self.temp_file = tempfile.NamedTemporaryFile(suffix=".db", delete=False)
   |                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^
63 |             self.db_path = self.temp_file.name
64 |             self.cleanup_db = True
   |

E722 Do not use bare `except`
   --> scripts/database_performance_benchmark.py:424:9
    |
422 |             )
423 |             baseline_dict = {b["metric_name"]: b["baseline_value"] for b in baselines}
424 |         except:
    |         ^^^^^^
425 |             logger.warning("No performance baselines found. This may be the first run.")
426 |             baseline_dict = {}
    |

S608 Possible SQL injection vector through string-based query construction
   --> scripts/database_performance_benchmark.py:436:21
    |
434 |             for table in ["documents", "vector_indexes", "citations"]:
435 |                 count_result = self.db.fetch_one(
436 |                     f"SELECT COUNT(*) as count FROM {table}"
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
437 |                 )
438 |                 current_measurements[f"table_row_count_{table}"] = (
    |

C901 `generate_optimization_recommendations` is too complex (14 > 10)
   --> scripts/database_performance_benchmark.py:505:9
    |
503 |         return regression_results
504 |
505 |     def generate_optimization_recommendations(self) -> list[str]:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
506 |         """Generate comprehensive optimization recommendations."""
507 |         logger.info("Generating optimization recommendations...")
    |

PERF401 Use `list.extend` to create a transformed list
   --> scripts/database_performance_benchmark.py:525:25
    |
523 |                       )
524 |                       for query in slow_queries[:3]:  # Show top 3 slowest
525 | /                         recommendations.append(
526 | |                             f"  - {query['query_name']}: {query['average_time_ms']:.2f}ms"
527 | |                         )
    | |_________________________^
528 |
529 |           # Analyze index effectiveness
    |
help: Replace for loop with list.extend

F841 Local variable `doc_repo` is assigned to but never used
  --> scripts/demo_citation_network_analysis.py:43:5
   |
42 |     # Create repositories
43 |     doc_repo = DocumentRepository(db_connection)
   |     ^^^^^^^^
44 |     citation_repo = CitationRepository(db_connection)
45 |     relation_repo = CitationRelationRepository(db_connection)
   |
help: Remove assignment to unused variable `doc_repo`

C901 `demonstrate_network_analysis` is too complex (14 > 10)
   --> scripts/demo_citation_network_analysis.py:264:5
    |
264 | def demonstrate_network_analysis(
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
265 |     citation_service: CitationService, doc_ids: dict[str, int]
266 | ):
    |

C901 `main` is too complex (15 > 10)
   --> scripts/deployment_orchestrator.py:485:11
    |
485 | async def main():
    |           ^^^^
486 |     """Main CLI interface"""
487 |     parser = argparse.ArgumentParser(
    |

F841 Local variable `status_parser` is assigned to but never used
   --> scripts/deployment_orchestrator.py:584:5
    |
583 |     # Status command
584 |     status_parser = subparsers.add_parser("status", help="Show orchestrator status")
    |     ^^^^^^^^^^^^^
585 |
586 |     args = parser.parse_args()
    |
help: Remove assignment to unused variable `status_parser`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/disaster_recovery_orchestrator.py:237:13
    |
235 |                   failover_results["services"][service] = result
236 |
237 | /             except Exception as e:
238 | |                 logger.error(f"Error failing over {service}: {e}")
239 | |                 failover_results["services"][service] = {
240 | |                     "status": "failed",
241 | |                     "error": str(e),
242 | |                 }
    | |_________________^
243 |
244 |           failover_results["completed_at"] = datetime.utcnow().isoformat()
    |

F841 Local variable `target_ec2` is assigned to but never used
   --> scripts/disaster_recovery_orchestrator.py:314:13
    |
312 |         try:
313 |             source_ec2 = self.aws_session.client("ec2", region_name=source_region)
314 |             target_ec2 = self.aws_session.client("ec2", region_name=target_region)
    |             ^^^^^^^^^^
315 |
316 |             # Get running instances
    |
help: Remove assignment to unused variable `target_ec2`

E722 Do not use bare `except`
   --> scripts/disaster_recovery_orchestrator.py:384:9
    |
382 |         try:
383 |             config.load_incluster_config()
384 |         except:
    |         ^^^^^^
385 |             config.load_kube_config()
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/disaster_recovery_orchestrator.py:498:13
    |
496 |                   deployment_results["resources"][resource_type] = result
497 |
498 | /             except Exception as e:
499 | |                 logger.error(f"Error deploying {resource_type}: {e}")
500 | |                 deployment_results["resources"][resource_type] = {
501 | |                     "status": "failed",
502 | |                     "error": str(e),
503 | |                 }
    | |_________________^
504 |
505 |           deployment_results["completed_at"] = datetime.utcnow().isoformat()
    |

F841 Local variable `timeout` is assigned to but never used
   --> scripts/disaster_recovery_orchestrator.py:831:9
    |
829 |         """Execute a single recovery step."""
830 |         step_type = step_config["type"]
831 |         timeout = step_config.get("timeout", 600)  # Default 10 minutes
    |         ^^^^^^^
832 |
833 |         try:
    |
help: Remove assignment to unused variable `timeout`

PERF203 `try`-`except` within a loop incurs performance overhead
    --> scripts/disaster_recovery_orchestrator.py:1062:13
     |
1060 |                   elif channel == "sms":
1061 |                       await self._send_sms_notification(subject, message)
1062 | /             except Exception as e:
1063 | |                 logger.error(f"Failed to send {channel} notification: {e}")
     | |___________________________________________________________________________^
1064 |
1065 |       async def _send_slack_notification(self, subject: str, message: str):
     |

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
    --> scripts/disaster_recovery_orchestrator.py:1089:9
     |
1087 |           }
1088 |
1089 | /         async with aiohttp.ClientSession() as session:
1090 | |             async with session.post(webhook_url, json=payload) as response:
     | |___________________________________________________________________________^
1091 |                   if response.status == 200:
1092 |                       logger.info("Slack notification sent successfully")
     |
help: Combine `with` statements

S607 Starting a process with a partial executable path
  --> scripts/docs_generator.py:90:21
   |
88 |             try:
89 |                 result = subprocess.run(
90 |                     ["git", "describe", "--tags", "--abbrev=0"],
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
91 |                     capture_output=True,
92 |                     text=True,
   |

E722 Do not use bare `except`
  --> scripts/docs_generator.py:97:13
   |
95 |                 if result.returncode == 0:
96 |                     return result.stdout.strip()
97 |             except:
   |             ^^^^^^
98 |                 pass
   |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/docs_generator.py:97:13
    |
 95 |                   if result.returncode == 0:
 96 |                       return result.stdout.strip()
 97 | /             except:
 98 | |                 pass
    | |____________________^
 99 |
100 |               return "2.1.0"  # Default version
    |

C901 `_parse_sqlalchemy_model` is too complex (11 > 10)
   --> scripts/docs_generator.py:304:9
    |
302 |                             self.database_models.append(model_info)
303 |
304 |     def _parse_sqlalchemy_model(
    |         ^^^^^^^^^^^^^^^^^^^^^^^
305 |         self, class_node: ast.ClassDef, content: str, file_path: Path
306 |     ) -> dict[str, Any] | None:
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/docs_generator.py:409:13
    |
407 |           # Get relationship attributes
408 |           for keyword in call_node.keywords:
409 | /             if keyword.arg == "back_populates":
410 | |                 if isinstance(keyword.value, (ast.Str, ast.Constant)):
    | |______________________________________________________________________^
411 |                       rel_info["back_populates"] = (
412 |                           keyword.value.s
    |
help: Combine `if` statements using `and`

E722 Do not use bare `except`
   --> scripts/docs_generator.py:702:13
    |
700 |                 parsed = yaml.safe_load(content)
701 |                 config_info["options"] = self._flatten_config_dict(parsed)
702 |             except:
    |             ^^^^^^
703 |                 pass
704 |         elif file_name == ".env.example":
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/docs_generator.py:702:13
    |
700 |                   parsed = yaml.safe_load(content)
701 |                   config_info["options"] = self._flatten_config_dict(parsed)
702 | /             except:
703 | |                 pass
    | |____________________^
704 |           elif file_name == ".env.example":
705 |               # Parse environment variables
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/docs_generator.py:733:13
    |
731 |           for line in content.split("\n"):
732 |               line = line.strip()
733 | /             if line and not line.startswith("#"):
734 | |                 if "=" in line:
    | |_______________________________^
735 |                       key, value = line.split("=", 1)
736 |                       options.append(
    |
help: Combine `if` statements using `and`

E722 Do not use bare `except`
   --> scripts/docs_generator.py:803:13
    |
801 |                     elif isinstance(node, ast.ClassDef):
802 |                         total_classes += 1
803 |             except:
    |             ^^^^^^
804 |                 continue
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/docs_generator.py:803:13
    |
801 |                       elif isinstance(node, ast.ClassDef):
802 |                           total_classes += 1
803 | /             except:
804 | |                 continue
    | |________________________^
805 |
806 |           self.metadata.update(
    |

S607 Starting a process with a partial executable path
   --> scripts/docs_generator.py:828:17
    |
826 |             # Try to run coverage report
827 |             result = subprocess.run(
828 |                 ["python", "-m", "coverage", "json", "--quiet"],
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
829 |                 capture_output=True,
830 |                 text=True,
    |

E722 Do not use bare `except`
   --> scripts/docs_generator.py:855:13
    |
853 |                     data = json.load(f)
854 |                     performance_data.append({"file": perf_file.name, "data": data})
855 |             except:
    |             ^^^^^^
856 |                 continue
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/docs_generator.py:855:13
    |
853 |                       data = json.load(f)
854 |                       performance_data.append({"file": perf_file.name, "data": data})
855 | /             except:
856 | |                 continue
    | |________________________^
857 |
858 |           self.metadata["performance_metrics"] = performance_data
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/docs_generator.py:855:13
    |
853 |                       data = json.load(f)
854 |                       performance_data.append({"file": perf_file.name, "data": data})
855 | /             except:
856 | |                 continue
    | |________________________^
857 |
858 |           self.metadata["performance_metrics"] = performance_data
    |

S607 Starting a process with a partial executable path
    --> scripts/docs_generator.py:1114:21
     |
1112 |             try:
1113 |                 result = subprocess.run(
1114 |                     ["git", "log", "--oneline", "-50"],
     |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1115 |                     capture_output=True,
1116 |                     text=True,
     |

E722 Do not use bare `except`
    --> scripts/docs_generator.py:1125:13
     |
1123 |                         + "\n".join(f"- {commit}" for commit in commits)
1124 |                     ]
1125 |             except:
     |             ^^^^^^
1126 |                 changelog_content = ["## Changelog\n\nNo changelog available."]
     |

PERF401 Use a list comprehension to create a transformed list
    --> scripts/docs_generator.py:1266:13
     |
1264 |           # Index API endpoints
1265 |           for endpoint in self.api_endpoints:
1266 | /             search_data.append(
1267 | |                 {
1268 | |                     "type": "api_endpoint",
1269 | |                     "title": f"{endpoint['method']} {endpoint['path']}",
1270 | |                     "content": endpoint.get("docstring", ""),
1271 | |                     "url": f"api_reference.html#{endpoint['function_name']}",
1272 | |                     "keywords": [
1273 | |                         endpoint["method"],
1274 | |                         endpoint["path"],
1275 | |                         endpoint["function_name"],
1276 | |                     ],
1277 | |                 }
1278 | |             )
     | |_____________^
1279 |
1280 |           # Index database models
     |
help: Replace for loop with list comprehension

PERF401 Use `list.extend` to create a transformed list
    --> scripts/docs_generator.py:1282:13
     |
1280 |           # Index database models
1281 |           for model in self.database_models:
1282 | /             search_data.append(
1283 | |                 {
1284 | |                     "type": "database_model",
1285 | |                     "title": model["name"],
1286 | |                     "content": model.get("docstring", ""),
1287 | |                     "url": f"database_schema.html#{model['name']}",
1288 | |                     "keywords": [model["name"], "model", "database"],
1289 | |                 }
1290 | |             )
     | |_____________^
1291 |
1292 |           # Index services
     |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
    --> scripts/docs_generator.py:1294:13
     |
1292 |           # Index services
1293 |           for service in self.service_classes:
1294 | /             search_data.append(
1295 | |                 {
1296 | |                     "type": "service",
1297 | |                     "title": service["name"],
1298 | |                     "content": service.get("docstring", ""),
1299 | |                     "url": f"service_architecture.html#{service['name']}",
1300 | |                     "keywords": [service["name"], "service", "business logic"],
1301 | |                 }
1302 | |             )
     | |_____________^
1303 |
1304 |           # Index types
     |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
    --> scripts/docs_generator.py:1306:13
     |
1304 |           # Index types
1305 |           for type_def in self.type_definitions:
1306 | /             search_data.append(
1307 | |                 {
1308 | |                     "type": "type_definition",
1309 | |                     "title": type_def["name"],
1310 | |                     "content": type_def.get("docstring", ""),
1311 | |                     "url": f"type_definitions.html#{type_def['name']}",
1312 | |                     "keywords": [
1313 | |                         type_def["name"],
1314 | |                         "type",
1315 | |                         type_def.get("language", ""),
1316 | |                     ],
1317 | |                 }
1318 | |             )
     | |_____________^
1319 |
1320 |           search_index_file = self.output_dir / "search_index.json"
     |
help: Replace for loop with list.extend

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/docs_quality_checker.py:193:13
    |
191 |                   document_analyses.append(analysis)
192 |                   print(f"   ✅ Analyzed: {file_path.relative_to(self.project_root)}")
193 | /             except Exception as e:
194 | |                 print(f"   ❌ Error analyzing {file_path}: {e}")
    | |________________________________________________________________^
195 |
196 |           # Calculate overall metrics
    |

C901 `analyze_completeness` is too complex (11 > 10)
   --> scripts/docs_quality_checker.py:353:9
    |
351 |         return max(1, syllable_count)
352 |
353 |     def analyze_completeness(self, content: str, file_path: Path) -> float:
    |         ^^^^^^^^^^^^^^^^^^^^
354 |         """Analyze document completeness based on expected sections."""
355 |         file_name = file_path.name.lower()
    |

C901 `analyze_consistency` is too complex (19 > 10)
   --> scripts/docs_quality_checker.py:450:9
    |
448 |         return max(0, min(1, total_score))
449 |
450 |     def analyze_consistency(self, content: str) -> float:
    |         ^^^^^^^^^^^^^^^^^^^
451 |         """Analyze document consistency in formatting and terminology."""
452 |         issues = []
    |

B007 Loop control variable `level` not used within loop body
   --> scripts/docs_quality_checker.py:459:17
    |
457 |             # Check for consistent header formatting
458 |             header_styles = Counter()
459 |             for level, text in headers:
    |                 ^^^^^
460 |                 # Check title case consistency
461 |                 is_title_case = text.strip().istitle()
    |
help: Rename unused `level` to `_level`

C401 Unnecessary generator (rewrite as a set comprehension)
   --> scripts/docs_quality_checker.py:509:28
    |
507 |         bullet_lists = re.findall(r"^[\s]*[-*+]\s", content, re.MULTILINE)
508 |         if bullet_lists:
509 |             bullet_types = set(match.strip()[-1] for match in bullet_lists)
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
510 |             if len(bullet_types) > 1:
511 |                 issues.append("Inconsistent bullet point formatting")
    |
help: Rewrite as a set comprehension

C901 `analyze_structure` is too complex (12 > 10)
   --> scripts/docs_quality_checker.py:536:9
    |
534 |         return max(0, min(1, consistency_score))
535 |
536 |     def analyze_structure(self, content: str) -> float:
    |         ^^^^^^^^^^^^^^^^^
537 |         """Analyze document structure and organization."""
538 |         lines = content.split("\n")
    |

C401 Unnecessary generator (rewrite as a set comprehension)
   --> scripts/docs_quality_checker.py:576:33
    |
575 |             # Bonus for having multiple levels
576 |             unique_levels = len(set(level for level, _ in headers))
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
577 |             if unique_levels >= 2:
578 |                 structure_score += 0.15
    |
help: Rewrite as a set comprehension

B007 Loop control variable `text` not used within loop body
   --> scripts/docs_quality_checker.py:612:13
    |
610 |         total_links = len(links)
611 |
612 |         for text, url in links:
    |             ^^^^
613 |             if self.is_valid_link(url, file_path):
614 |                 valid_links += 1
    |
help: Rename unused `text` to `_text`

E722 Do not use bare `except`
   --> scripts/docs_quality_checker.py:636:9
    |
634 |         try:
635 |             return target_path.exists()
636 |         except:
    |         ^^^^^^
637 |             return False
    |

E722 Do not use bare `except`
   --> scripts/docs_quality_checker.py:658:13
    |
656 |                         if line.startswith("title:"):
657 |                             return line.split(":", 1)[1].strip().strip("\"'")
658 |             except:
    |             ^^^^^^
659 |                 pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/docs_quality_checker.py:658:13
    |
656 |                           if line.startswith("title:"):
657 |                               return line.split(":", 1)[1].strip().strip("\"'")
658 | /             except:
659 | |                 pass
    | |____________________^
660 |
661 |           return "Untitled Document"
    |

C901 `generate_recommendations` is too complex (15 > 10)
   --> scripts/docs_quality_checker.py:806:9
    |
804 |         return distribution
805 |
806 |     def generate_recommendations(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^
807 |         self, documents: list[DocumentAnalysis], metrics: dict[str, QualityMetric]
808 |     ) -> list[str]:
    |

B007 Loop control variable `name` not used within loop body
    --> scripts/docs_quality_checker.py:1096:13
     |
1094 |         """Generate HTML for metric cards."""
1095 |         cards = []
1096 |         for name, metric in metrics.items():
     |             ^^^^
1097 |             score_percent = metric.percentage
1098 |             cards.append(
     |
help: Rename unused `name` to `_name`

PERF102 When using only the values of a dict use the `values()` method
    --> scripts/docs_quality_checker.py:1096:29
     |
1094 |         """Generate HTML for metric cards."""
1095 |         cards = []
1096 |         for name, metric in metrics.items():
     |                             ^^^^^^^^^^^^^
1097 |             score_percent = metric.percentage
1098 |             cards.append(
     |
help: Replace `.items()` with `.values()`

B007 Loop control variable `name` not used within loop body
    --> scripts/docs_quality_checker.py:1143:13
     |
1141 |         ]
1142 |
1143 |         for name, metric in report.metrics.items():
     |             ^^^^
1144 |             lines.append(f"{metric.name}: {metric.percentage:.1f}%")
     |
help: Rename unused `name` to `_name`

PERF102 When using only the values of a dict use the `values()` method
    --> scripts/docs_quality_checker.py:1143:29
     |
1141 |         ]
1142 |
1143 |         for name, metric in report.metrics.items():
     |                             ^^^^^^^^^^^^^^^^^^^^
1144 |             lines.append(f"{metric.name}: {metric.percentage:.1f}%")
     |
help: Replace `.items()` with `.values()`

PERF401 Use `list.extend` to create a transformed list
    --> scripts/docs_quality_checker.py:1163:13
     |
1162 |         for rec in report.recommendations:
1163 |             lines.append(f"• {rec}")
     |             ^^^^^^^^^^^^^^^^^^^^^^^^
1164 |
1165 |         lines.extend(["", "DOCUMENT ANALYSIS", "-" * 20])
     |
help: Replace for loop with list.extend

F841 Local variable `metadata` is assigned to but never used
   --> scripts/document_load_tester.py:152:13
    |
151 |             # 4. Metadata extraction simulation
152 |             metadata = {
    |             ^^^^^^^^
153 |                 "word_count": word_count,
154 |                 "char_count": char_count,
    |
help: Remove assignment to unused variable `metadata`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/document_load_tester.py:254:17
    |
252 |                       user_results = future.result(timeout=30)
253 |                       all_results.extend(user_results)
254 | /                 except Exception as e:
255 | |                     logger.error(f"User thread failed: {e}")
    | |____________________________________________________________^
256 |
257 |           end_time = time.time()
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/document_load_tester.py:367:13
    |
365 |                   time.sleep(5)
366 |
367 | /             except Exception as e:
368 | |                 logger.error(f"Scenario {scenario.name} failed: {e}")
369 | |                 test_results[scenario.name] = {
370 | |                     "error": str(e),
371 | |                     "scenario_name": scenario.name,
372 | |                 }
    | |_________________^
373 |
374 |           overall_duration = time.time() - overall_start
    |

C901 `analyze_load_test_results` is too complex (18 > 10)
   --> scripts/document_load_tester.py:397:9
    |
395 |         return comprehensive_results
396 |
397 |     def analyze_load_test_results(self, test_results: dict[str, Any]) -> dict[str, Any]:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^
398 |         """Analyze load test results and generate insights"""
    |

F841 Local variable `encryption_service` is assigned to but never used
   --> scripts/enable_encryption.py:274:13
    |
273 |             secrets_manager = SecretsManagerService()
274 |             encryption_service = EncryptionService(session, secrets_manager)
    |             ^^^^^^^^^^^^^^^^^^
275 |
276 |             encrypted_count = 0
    |
help: Remove assignment to unused variable `encryption_service`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/enable_encryption.py:345:21
    |
343 |                           encrypted_count += 1
344 |
345 | /                     except Exception as e:
346 | |                         logger.error(f"Failed to encrypt {file_path}: {e}")
    | |___________________________________________________________________________^
347 |
348 |                   logger.info(f"Encrypted {encrypted_count} files")
    |

C901 `main` is too complex (11 > 10)
   --> scripts/enable_encryption.py:525:5
    |
525 | def main():
    |     ^^^^
526 |     """Main function to setup encryption."""
527 |     parser = argparse.ArgumentParser(description="Setup encryption for AI PDF Scholar")
    |

F841 Local variable `citation_repo` is assigned to but never used
   --> scripts/establish_performance_baseline.py:100:13
    |
 98 |             # Initialize repositories
 99 |             doc_repo = DocumentRepository(self.db)
100 |             citation_repo = CitationRepository(self.db)
    |             ^^^^^^^^^^^^^
101 |
102 |             # Test SELECT operations
    |
help: Remove assignment to unused variable `citation_repo`

F841 Local variable `docs` is assigned to but never used
   --> scripts/establish_performance_baseline.py:106:17
    |
104 |             for _ in range(50):  # 50 iterations for statistical significance
105 |                 start = time.perf_counter()
106 |                 docs = doc_repo.get_all()
    |                 ^^^^
107 |                 end = time.perf_counter()
108 |                 select_times.append((end - start) * 1000)  # Convert to ms
    |
help: Remove assignment to unused variable `docs`

F841 Local variable `results` is assigned to but never used
   --> scripts/establish_performance_baseline.py:188:21
    |
186 |                     """
187 |                     )
188 |                     results = cursor.fetchall()
    |                     ^^^^^^^
189 |                 end = time.perf_counter()
190 |                 complex_times.append((end - start) * 1000)
    |
help: Remove assignment to unused variable `results`

C901 `_benchmark_api_endpoints` is too complex (12 > 10)
   --> scripts/establish_performance_baseline.py:217:9
    |
215 |         return db_metrics
216 |
217 |     def _benchmark_api_endpoints(self) -> dict[str, Any]:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^
218 |         """Benchmark API endpoint response times."""
219 |         print("📊 API Response Times:")
    |

S607 Starting a process with a partial executable path
   --> scripts/establish_performance_baseline.py:229:17
    |
227 |               print("   🚀 Starting API server for testing...")
228 |               api_process = subprocess.Popen(
229 | /                 [
230 | |                     "python",
231 | |                     "-m",
232 | |                     "uvicorn",
233 | |                     "backend.api.main:app",
234 | |                     "--host",
235 | |                     "127.0.0.1",
236 | |                     "--port",
237 | |                     "8001",  # Use different port for testing
238 | |                     "--log-level",
239 | |                     "error",
240 | |                 ],
    | |_________________^
241 |                   cwd=self.project_root,
242 |                   stdout=subprocess.DEVNULL,
    |

F841 Local variable `processed` is assigned to but never used
   --> scripts/establish_performance_baseline.py:331:17
    |
329 |                 # Simulate text processing
330 |                 words = test_text.split()
331 |                 processed = [word.lower().strip(".,!?") for word in words]
    |                 ^^^^^^^^^
332 |                 # Simulate vector embedding (mock operation)
333 |                 time.sleep(0.05)  # Simulate embedding time
    |
help: Remove assignment to unused variable `processed`

F841 Local variable `query` is assigned to but never used
   --> scripts/establish_performance_baseline.py:353:17
    |
351 |                 start = time.perf_counter()
352 |                 # Simulate query processing
353 |                 query = "What is the main topic discussed?"
    |                 ^^^^^
354 |                 # Simulate similarity search
355 |                 time.sleep(0.1)  # Mock similarity computation
    |
help: Remove assignment to unused variable `query`

E722 Do not use bare `except`
   --> scripts/establish_performance_baseline.py:399:17
    |
397 |                         cursor.execute("SELECT COUNT(*) FROM documents")
398 |                         cursor.fetchone()
399 |                 except:
    |                 ^^^^^^
400 |                     pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/establish_performance_baseline.py:399:17
    |
397 |                           cursor.execute("SELECT COUNT(*) FROM documents")
398 |                           cursor.fetchone()
399 | /                 except:
400 | |                     pass
    | |________________________^
401 |
402 |               # Simulate text processing
    |

F841 Local variable `processed` is assigned to but never used
   --> scripts/establish_performance_baseline.py:404:13
    |
402 |             # Simulate text processing
403 |             test_data = "Sample text " * 1000 * (i + 1)  # Growing data
404 |             processed = test_data.upper().split()
    |             ^^^^^^^^^
405 |
406 |             # Record memory usage
    |
help: Remove assignment to unused variable `processed`

C901 `_generate_baseline_report` is too complex (20 > 10)
   --> scripts/establish_performance_baseline.py:489:9
    |
487 |         return psutil.Process().memory_info().rss / 1024 / 1024
488 |
489 |     def _generate_baseline_report(self) -> None:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^
490 |         """Generate comprehensive baseline report."""
491 |         print("\n" + "=" * 70)
    |

B007 Loop control variable `category` not used within loop body
   --> scripts/establish_performance_baseline.py:592:13
    |
591 |         # Count performance tests
592 |         for category, metrics in self.baselines.items():
    |             ^^^^^^^^
593 |             if isinstance(metrics, dict) and "error" not in metrics:
594 |                 for test_name, test_data in metrics.items():
    |
help: Rename unused `category` to `_category`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/establish_performance_baseline.py:592:34
    |
591 |         # Count performance tests
592 |         for category, metrics in self.baselines.items():
    |                                  ^^^^^^^^^^^^^^^^^^^^
593 |             if isinstance(metrics, dict) and "error" not in metrics:
594 |                 for test_name, test_data in metrics.items():
    |
help: Replace `.items()` with `.values()`

B007 Loop control variable `test_name` not used within loop body
   --> scripts/establish_performance_baseline.py:594:21
    |
592 |         for category, metrics in self.baselines.items():
593 |             if isinstance(metrics, dict) and "error" not in metrics:
594 |                 for test_name, test_data in metrics.items():
    |                     ^^^^^^^^^
595 |                     if isinstance(test_data, dict) and "meets_target" in test_data:
596 |                         total_tests += 1
    |
help: Rename unused `test_name` to `_test_name`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/establish_performance_baseline.py:594:45
    |
592 |         for category, metrics in self.baselines.items():
593 |             if isinstance(metrics, dict) and "error" not in metrics:
594 |                 for test_name, test_data in metrics.items():
    |                                             ^^^^^^^^^^^^^
595 |                     if isinstance(test_data, dict) and "meets_target" in test_data:
596 |                         total_tests += 1
    |
help: Replace `.items()` with `.values()`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/feature_flag_deployer.py:480:9
    |
479 |           # Environment-specific validations
480 | /         if environment == Environment.PRODUCTION:
481 | |             if new_status == FeatureFlagStatus.PRODUCTION and new_percentage > 50:
    | |__________________________________________________________________________________^
482 |                   # Require manual approval for high-impact production deployments
483 |                   logger.warning(
    |
help: Combine `if` statements using `and`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/feature_flag_deployer.py:719:13
    |
717 |                   self.flags[flag_key] = flag
718 |                   imported_count += 1
719 | /             except Exception as e:
720 | |                 logger.error(f"Failed to import flag '{flag_key}': {e}")
    | |________________________________________________________________________^
721 |
722 |           self.save_state()
    |

C901 `main` is too complex (21 > 10)
   --> scripts/feature_flag_deployer.py:726:11
    |
726 | async def main():
    |           ^^^^
727 |     """Main CLI interface"""
728 |     parser = argparse.ArgumentParser(
    |

UP035 `typing.List` is deprecated, use `list` instead
 --> scripts/fix_b904_syntax_errors.py:8:1
  |
6 | import re
7 | from pathlib import Path
8 | from typing import List, Tuple
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
 --> scripts/fix_b904_syntax_errors.py:8:1
  |
6 | import re
7 | from pathlib import Path
8 | from typing import List, Tuple
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |

S112 `try`-`except`-`continue` detected, consider logging the exception
  --> scripts/fix_b904_syntax_errors.py:46:9
   |
44 |                       break
45 |
46 | /         except Exception:
47 | |             continue
   | |____________________^
48 |
49 |       return errors
   |

UP035 `typing.List` is deprecated, use `list` instead
  --> scripts/fix_b904_violations.py:10:1
   |
 8 | import sys
 9 | from pathlib import Path
10 | from typing import List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

UP035 `typing.Tuple` is deprecated, use `tuple` instead
  --> scripts/fix_b904_violations.py:10:1
   |
 8 | import sys
 9 | from pathlib import Path
10 | from typing import List, Tuple
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
   |

S607 Starting a process with a partial executable path
  --> scripts/fix_b904_violations.py:17:13
   |
15 |     try:
16 |         result = subprocess.run(
17 |             ["ruff", "check", "--select", "B904"], capture_output=True, text=True
   |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
18 |         )
   |

C901 `fix_violation` is too complex (17 > 10)
  --> scripts/fix_b904_violations.py:35:5
   |
35 | def fix_violation(filepath: str, line_num: int) -> bool:
   |     ^^^^^^^^^^^^^
36 |     """Fix a single B904 violation."""
37 |     try:
   |

SIM108 Use ternary operator `suffix = f" from {exception_var}" if exception_var else " from None"` instead of `if`-`else`-block
   --> scripts/fix_b904_violations.py:106:9
    |
105 |           # Add 'from e' or 'from None' to the last line of the raise statement
106 | /         if exception_var:
107 | |             suffix = f" from {exception_var}"
108 | |         else:
109 | |             # If no exception variable, use 'from None' to explicitly break the chain
110 | |             suffix = " from None"
    | |_________________________________^
111 |
112 |           # Modify the last line of the statement
    |
help: Replace `if`-`else`-block with `suffix = f" from {exception_var}" if exception_var else " from None"`

B007 Loop control variable `full_line` not used within loop body
   --> scripts/fix_b904_violations.py:147:29
    |
145 |     # Group violations by file
146 |     files_to_fix = {}
147 |     for filepath, line_num, full_line in violations:
    |                             ^^^^^^^^^
148 |         if filepath not in files_to_fix:
149 |             files_to_fix[filepath] = []
    |
help: Rename unused `full_line` to `_full_line`

SIM102 Use a single `if` statement instead of nested `if` statements
  --> scripts/fix_from_e_indent.py:22:13
   |
21 |               # Check if this line has incorrect indentation for 'from e)'
22 | /             if re.match(r"^\s+from\s+\w+\)?\s*$", line):
23 | |                 # This is a 'from e)' on its own line with wrong indentation
24 | |                 # It should be appended to the previous line
25 | |                 if new_lines and i > 0:
   | |_______________________________________^
26 |                       # Get the previous line
27 |                       prev_line = new_lines[-1]
   |
help: Combine `if` statements using `and`

C901 `extract_scores_from_results` is too complex (16 > 10)
   --> scripts/generate_production_certification.py:161:9
    |
159 |         return len(self.test_results) > 0
160 |
161 |     def extract_scores_from_results(self) -> dict[str, float]:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
162 |         """Extract scores from test results for each certification criterion."""
163 |         scores = {}
    |

SIM108 Use ternary operator `overall_score = total_weighted_score / total_weight if total_weight > 0 else 0.0` instead of `if`-`else`-block
   --> scripts/generate_production_certification.py:265:9
    |
263 |                   )
264 |
265 | /         if total_weight > 0:
266 | |             overall_score = total_weighted_score / total_weight
267 | |         else:
268 | |             overall_score = 0.0
    | |_______________________________^
269 |
270 |           return overall_score
    |
help: Replace `if`-`else`-block with `overall_score = total_weighted_score / total_weight if total_weight > 0 else 0.0`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/generate_production_certification.py:280:13
    |
278 |           critical_criteria_passed = True
279 |           for criterion in self.certification_criteria:
280 | /             if criterion.critical and criterion.name in scores:
281 | |                 if scores[criterion.name] < criterion.required_score:
    | |_____________________________________________________________________^
282 |                       critical_criteria_passed = False
283 |                       break
    |
help: Combine `if` statements using `and`

F841 Local variable `risk_level` is assigned to but never used
   --> scripts/generate_production_certification.py:516:17
    |
514 |                 high_risks.append(f"{criterion.description} below critical threshold")
515 |             elif score < criterion.required_score:
516 |                 risk_level = "MEDIUM"
    |                 ^^^^^^^^^^
517 |                 medium_risks.append(
518 |                     f"{criterion.description} below recommended threshold"
    |
help: Remove assignment to unused variable `risk_level`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/generate_production_certification.py:521:13
    |
519 |                   )
520 |
521 | /             if score < 60.0:  # Very low scores are always high risk
522 | |                 if f"{criterion.description}" not in [
523 | |                     r.split(" below")[0] for r in high_risks
524 | |                 ]:
    | |__________________^
525 |                       high_risks.append(
526 |                           f"{criterion.description} critically low performance"
    |
help: Combine `if` statements using `and`

S603 `subprocess` call: check for execution of untrusted input
  --> scripts/generate_test_coverage.py:63:22
   |
62 |         try:
63 |             result = subprocess.run(
   |                      ^^^^^^^^^^^^^^
64 |                 cmd,
65 |                 cwd=self.project_root,
   |

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> scripts/generate_test_coverage.py:177:28
    |
176 |         # Module-specific recommendations
177 |         src_files = [f for f in file_analysis.keys() if f.startswith("src/")]
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^
178 |         backend_files = [f for f in file_analysis.keys() if f.startswith("backend/")]
    |
help: Remove `.keys()`

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> scripts/generate_test_coverage.py:178:32
    |
176 |         # Module-specific recommendations
177 |         src_files = [f for f in file_analysis.keys() if f.startswith("src/")]
178 |         backend_files = [f for f in file_analysis.keys() if f.startswith("backend/")]
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^
179 |
180 |         if src_files:
    |
help: Remove `.keys()`

C901 `generate_summary_report` is too complex (14 > 10)
   --> scripts/generate_test_coverage.py:198:9
    |
196 |         return recommendations
197 |
198 |     def generate_summary_report(
    |         ^^^^^^^^^^^^^^^^^^^^^^^
199 |         self, analysis: dict[str, Any], test_results: dict[str, Any]
200 |     ) -> str:
    |

S608 Possible SQL injection vector through string-based query construction
   --> scripts/index_optimization_advisor.py:142:17
    |
140 |             # Get table statistics
141 |             count_result = self.db.fetch_one(
142 |                 f"SELECT COUNT(*) as count FROM {table_name}"
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
143 |             )
144 |             row_count = count_result["count"] if count_result else 0
    |

SIM108 Use ternary operator `data_size_kb = row_count * 50 / 1024 if pragma_result else 0` instead of `if`-`else`-block
   --> scripts/index_optimization_advisor.py:149:17
    |
147 |               try:
148 |                   pragma_result = self.db.fetch_one(f"PRAGMA table_info({table_name})")
149 | /                 if pragma_result:
150 | |                     # Rough estimate: 50 bytes per row on average
151 | |                     data_size_kb = (row_count * 50) / 1024
152 | |                 else:
153 | |                     data_size_kb = 0
    | |____________________________________^
154 |               except:
155 |                   data_size_kb = 0
    |
help: Replace `if`-`else`-block with `data_size_kb = row_count * 50 / 1024 if pragma_result else 0`

E722 Do not use bare `except`
   --> scripts/index_optimization_advisor.py:154:13
    |
152 |                 else:
153 |                     data_size_kb = 0
154 |             except:
    |             ^^^^^^
155 |                 data_size_kb = 0
    |

E722 Do not use bare `except`
   --> scripts/index_optimization_advisor.py:171:13
    |
169 |                         }
170 |                     )
171 |             except:
    |             ^^^^^^
172 |                 pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/index_optimization_advisor.py:171:13
    |
169 |                           }
170 |                       )
171 | /             except:
172 | |                 pass
    | |____________________^
173 |
174 |               # Create table analysis
    |

F841 Local variable `schema` is assigned to but never used
   --> scripts/index_optimization_advisor.py:234:17
    |
232 |             for table_name in self._table_analyses:
233 |                 # Get table schema
234 |                 schema = self.db.fetch_all(f"PRAGMA table_info({table_name})")
    |                 ^^^^^^
235 |
236 |                 # Look for foreign key patterns
    |
help: Remove assignment to unused variable `schema`

B007 Loop control variable `table_name` not used within loop body
   --> scripts/index_optimization_advisor.py:364:13
    |
362 |         recommendations = []
363 |
364 |         for table_name, analysis in self._table_analyses.items():
    |             ^^^^^^^^^^
365 |             # Skip small tables
366 |             if analysis.row_count < self.MIN_TABLE_SIZE:
    |
help: Rename unused `table_name` to `_table_name`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/index_optimization_advisor.py:364:37
    |
362 |         recommendations = []
363 |
364 |         for table_name, analysis in self._table_analyses.items():
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^
365 |             # Skip small tables
366 |             if analysis.row_count < self.MIN_TABLE_SIZE:
    |
help: Replace `.items()` with `.values()`

F841 Local variable `column_pairs` is assigned to but never used
   --> scripts/index_optimization_advisor.py:445:9
    |
444 |         # Find column combinations that are frequently used together
445 |         column_pairs = defaultdict(int)
    |         ^^^^^^^^^^^^
446 |
447 |         # This is simplified - in practice, you'd analyze actual query patterns
    |
help: Remove assignment to unused variable `column_pairs`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/index_optimization_advisor.py:558:17
    |
556 |           for i, index1 in enumerate(analysis.existing_indexes):
557 |               for j, index2 in enumerate(analysis.existing_indexes):
558 | /                 if i != j and len(index1["columns"]) < len(index2["columns"]):
559 | |                     # Check if index1 is a prefix of index2
560 | |                     if index2["columns"][: len(index1["columns"])] == index1["columns"]:
    | |________________________________________________________________________________________^
561 |                           # index1 is redundant
562 |                           recommendation = IndexRecommendation(
    |
help: Combine `if` statements using `and`

C901 `main` is too complex (13 > 10)
   --> scripts/index_optimization_advisor.py:747:5
    |
747 | def main():
    |     ^^^^
748 |     """CLI interface for the Index Optimization Advisor."""
749 |     import argparse
    |

E722 Do not use bare `except`
   --> scripts/index_optimization_advisor.py:781:9
    |
779 |         try:
780 |             query_analyzer = QueryPerformanceAnalyzer(db)
781 |         except:
    |         ^^^^^^
782 |             logger.warning("Query analyzer not available - using basic analysis")
    |

S607 Starting a process with a partial executable path
   --> scripts/lightweight_load_test.py:128:17
    |
126 |               # Use a different port for load testing
127 |               self.api_process = subprocess.Popen(
128 | /                 [
129 | |                     "python",
130 | |                     "-m",
131 | |                     "uvicorn",
132 | |                     "backend.api.main:app",
133 | |                     "--host",
134 | |                     "127.0.0.1",
135 | |                     "--port",
136 | |                     "8002",  # Different port for load testing
137 | |                     "--log-level",
138 | |                     "error",
139 | |                 ],
    | |_________________^
140 |                   cwd=self.project_root,
141 |                   stdout=subprocess.DEVNULL,
    |

B007 Loop control variable `attempt` not used within loop body
   --> scripts/lightweight_load_test.py:149:17
    |
148 |             # Wait for server to start and verify it's responding
149 |             for attempt in range(15):  # 15 seconds timeout
    |                 ^^^^^^^
150 |                 time.sleep(1)
151 |                 try:
    |
help: Rename unused `attempt` to `_attempt`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/lightweight_load_test.py:249:17
    |
247 |                       user_results = future.result(timeout=duration + 10)
248 |                       results.extend(user_results)
249 | /                 except Exception as e:
250 | |                     print(f"   ⚠️  User simulation error: {e}")
    | |______________________________________________________________^
251 |
252 |           total_time = time.time() - start_time
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> scripts/lightweight_load_test.py:283:24
    |
281 |               }
282 |
283 |               endpoint = random.choices(
    |  ________________________^
284 | |                 list(endpoint_weights.keys()), weights=list(endpoint_weights.values())
285 | |             )[0]
    | |_____________^
286 |
287 |               # Make request
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> scripts/lightweight_load_test.py:294:58
    |
293 |             # Wait before next request (simulate user think time)
294 |             think_time = max(0, request_interval - 0.1 + random.uniform(-0.05, 0.05))
    |                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
295 |             time.sleep(think_time)
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/log_analyzer.py:481:13
    |
479 |               try:
480 |                   return datetime.strptime(timestamp_str, fmt)
481 | /             except ValueError:
482 | |                 continue
    | |________________________^
483 |
484 |           # Fallback to current time
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/log_analysis_cache"
   --> scripts/log_analyzer.py:500:44
    |
498 |         self.parser = LogParser()
499 |         self.pattern_library = LogPatternLibrary()
500 |         self.cache_dir = cache_dir or Path("/tmp/log_analysis_cache")
    |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^
501 |         self.cache_dir.mkdir(exist_ok=True)
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/log_analyzer.py:645:17
    |
644 |               for entry in self.log_entries:
645 | /                 if entry.level in [LogLevel.ERROR, LogLevel.CRITICAL, LogLevel.WARNING]:
646 | |                     if regex.search(entry.message) or (
647 | |                         entry.raw_line and regex.search(entry.raw_line)
648 | |                     ):
    | |______________________^
649 |                           matches.append(entry)
    |
help: Combine `if` statements using `and`

C901 `_analyze_performance_bottlenecks` is too complex (17 > 10)
   --> scripts/log_analyzer.py:676:9
    |
674 |         return pattern_matches
675 |
676 |     def _analyze_performance_bottlenecks(self) -> list[PerformanceBottleneck]:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
677 |         """Analyze performance bottlenecks from log data."""
678 |         logger.info("Analyzing performance bottlenecks...")
    |

C901 `_analyze_security_events` is too complex (15 > 10)
   --> scripts/log_analyzer.py:770:9
    |
768 |         return bottlenecks
769 |
770 |     def _analyze_security_events(self) -> list[SecurityEvent]:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^
771 |         """Analyze security events and potential threats."""
772 |         logger.info("Analyzing security events...")
    |

C401 Unnecessary generator (rewrite as a set comprehension)
   --> scripts/log_analyzer.py:847:43
    |
845 |                 # Determine attack pattern
846 |                 attack_pattern = None
847 |                 if frequency > 20 and len(set(e["endpoint"] for e in events)) > 5:
    |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
848 |                     attack_pattern = "reconnaissance_scan"
849 |                 elif frequency > 50:
    |
help: Rewrite as a set comprehension

C401 Unnecessary generator (rewrite as a set comprehension)
   --> scripts/log_analyzer.py:858:25
    |
856 |                     source_ip=ip,
857 |                     target_endpoint=max(
858 |                         set(e["endpoint"] for e in events),
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
859 |                         key=lambda x: sum(1 for e in events if e["endpoint"] == x),
860 |                     ),
    |
help: Rewrite as a set comprehension

C901 `_detect_anomalies` is too complex (14 > 10)
   --> scripts/log_analyzer.py:939:9
    |
937 |         return metrics
938 |
939 |     def _detect_anomalies(self) -> list[Anomaly]:
    |         ^^^^^^^^^^^^^^^^^
940 |         """Detect anomalies in log patterns and system behavior."""
941 |         logger.info("Detecting anomalies...")
    |

C901 `_generate_predictions` is too complex (20 > 10)
    --> scripts/log_analyzer.py:1067:9
     |
1065 |         return anomalies
1066 |
1067 |     def _generate_predictions(self) -> list[PredictiveInsight]:
     |         ^^^^^^^^^^^^^^^^^^^^^
1068 |         """Generate predictive insights based on log analysis."""
1069 |         logger.info("Generating predictive insights...")
     |

PERF401 Use a list comprehension to create a transformed list
    --> scripts/log_analyzer.py:1118:17
     |
1116 |         for entry in self.log_entries:
1117 |             if entry.response_time and entry.response_time > 0:
1118 |                 response_times.append((entry.timestamp, entry.response_time))
     |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1119 |
1120 |         if len(response_times) > 50:
     |
help: Replace for loop with list comprehension

C901 `_format_markdown` is too complex (25 > 10)
    --> scripts/log_analyzer.py:1254:9
     |
1253 |     @staticmethod
1254 |     def _format_markdown(results: dict[str, Any]) -> str:
     |         ^^^^^^^^^^^^^^^^
1255 |         """Format as Markdown report."""
1256 |         md_content = []
     |

PERF401 Use `list.extend` to create a transformed list
    --> scripts/log_analyzer.py:1315:29
     |
1313 |                         md_content.append("- **Recommendations:**")
1314 |                         for rec in bottleneck["recommendations"]:
1315 |                             md_content.append(f"  - {rec}")
     |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1316 |                     md_content.append("")
1317 |             else:
     |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
    --> scripts/log_analyzer.py:1338:29
     |
1336 |                         md_content.append("- **Recommended Countermeasures:**")
1337 |                         for measure in event["countermeasures"]:
1338 |                             md_content.append(f"  - {measure}")
     |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1339 |                     md_content.append("")
1340 |             else:
     |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
    --> scripts/log_analyzer.py:1352:21
     |
1350 |               if business_metrics:
1351 |                   for metric in business_metrics:
1352 | /                     md_content.append(
1353 | |                         f"- **{metric['metric_name']}:** {metric['metric_value']} ({metric['metric_type']})"
1354 | |                     )
     | |_____________________^
1355 |                   md_content.append("")
1356 |               else:
     |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
    --> scripts/log_analyzer.py:1397:29
     |
1395 |                         md_content.append("- **Recommended Actions:**")
1396 |                         for action in prediction["recommended_actions"]:
1397 |                             md_content.append(f"  - {action}")
     |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1398 |                     md_content.append("")
1399 |             else:
     |
help: Replace for loop with list.extend

PERF203 `try`-`except` within a loop incurs performance overhead
    --> scripts/log_analyzer.py:1595:13
     |
1593 |               try:
1594 |                   analysis_types.append(AnalysisType(type_name))
1595 | /             except ValueError:
1596 | |                 logger.error(f"Unknown analysis type: {type_name}")
1597 | |                 return 1
     | |________________________^
1598 |
1599 |       # Initialize analysis engine
     |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/memory_leak_detector.py:201:13
    |
199 |                   time.sleep(0.1)
200 |
201 | /             except Exception as e:
202 | |                 print(f"   ⚠️  Operation error: {e}")
203 | |                 continue
    | |________________________^
204 |
205 |           print(f"✅ Completed {operation_count} sustained operations")
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/memory_test_"
   --> scripts/memory_leak_detector.py:215:31
    |
213 |                 # Create test data
214 |                 test_title = f"Memory Test Document {operation_id}"
215 |                 test_path = f"/tmp/memory_test_{operation_id}.pdf"
    |                               ^^^^^^^^^^^^^^^^^
216 |                 test_hash = f"hash_{operation_id:06d}"
    |

F841 Local variable `count` is assigned to but never used
   --> scripts/memory_leak_detector.py:229:17
    |
227 |                 # Query operation
228 |                 cursor.execute("SELECT COUNT(*) FROM documents")
229 |                 count = cursor.fetchone()[0]
    |                 ^^^^^
230 |
231 |                 # Cleanup older test data to prevent database growth
    |
help: Remove assignment to unused variable `count`

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/memory_leak_detector.py:243:9
    |
241 |                   conn.commit()
242 |
243 | /         except Exception:
244 | |             # Silently handle database errors during stress testing
245 | |             pass
    | |________________^
246 |
247 |       def _perform_text_processing_operations(self, operation_id: int) -> None:
    |

B007 Loop control variable `i` not used within loop body
   --> scripts/memory_leak_detector.py:275:13
    |
274 |         # Allocate memory in chunks
275 |         for i in range(50):
    |             ^
276 |             chunk = [operation_id + j for j in range(100)]  # 100 integers
277 |             test_data.append(chunk)
    |
help: Rename unused `i` to `_i`

F841 Local variable `total` is assigned to but never used
   --> scripts/memory_leak_detector.py:280:9
    |
279 |         # Process the data
280 |         total = sum(sum(chunk) for chunk in test_data)
    |         ^^^^^
281 |
282 |         # Explicit cleanup
    |
help: Remove assignment to unused variable `total`

F841 Local variable `timestamps` is assigned to but never used
   --> scripts/memory_leak_detector.py:296:9
    |
294 |         # Extract memory values
295 |         memory_values = [sample["process_memory_mb"] for sample in self.memory_samples]
296 |         timestamps = [
    |         ^^^^^^^^^^
297 |             datetime.fromisoformat(sample["timestamp"].replace("Z", "+00:00"))
298 |             for sample in self.memory_samples
    |
help: Remove assignment to unused variable `timestamps`

SIM108 Use ternary operator `slope = 0 if denominator == 0 else (n * sum_xy - sum_x * sum_y) / denominator` instead of `if`-`else`-block
   --> scripts/memory_leak_detector.py:369:9
    |
367 |           # Slope (trend)
368 |           denominator = n * sum_xx - sum_x * sum_x
369 | /         if denominator == 0:
370 | |             slope = 0
371 | |         else:
372 | |             slope = (n * sum_xy - sum_x * sum_y) / denominator
    | |______________________________________________________________^
373 |
374 |           # Correlation coefficient
    |
help: Replace `if`-`else`-block with `slope = 0 if denominator == 0 else (n * sum_xy - sum_x * sum_y) / denominator`

PERF203 `try`-`except` within a loop incurs performance overhead
  --> scripts/migrate_test_fixtures.py:51:13
   |
49 |                       files_to_migrate.append(file_path)
50 |
51 | /             except Exception as e:
52 | |                 print(f"Warning: Could not scan {file_path}: {e}")
   | |__________________________________________________________________^
53 |
54 |           return files_to_migrate
   |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> scripts/optimize_tests.py:53:13
   |
51 |                       }
52 |                   )
53 | /             except Exception as e:
54 | |                 print(f"Warning: Could not analyze {conftest}: {e}")
   | |____________________________________________________________________^
55 |
56 |           structure = {
   |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/optimize_tests.py:128:22
    |
126 |                 "--disable-warnings",
127 |             ] + test_args
128 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
129 |                 cmd,
130 |                 cwd=self.project_root,
    |

S112 `try`-`except`-`continue` detected, consider logging the exception
   --> scripts/optimize_tests.py:196:17
    |
194 |                                   elif "skipped" in status:
195 |                                       results["skipped"] = count
196 | /                 except Exception:
197 | |                     continue
    | |____________________________^
198 |
199 |           results["total"] = results["passed"] + results["failed"] + results["skipped"]
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/optimize_tests.py:249:13
    |
247 |                           )
248 |
249 | /             except Exception as e:
250 | |                 print(f"Warning: Could not analyze imports in {test_file}: {e}")
    | |________________________________________________________________________________^
251 |
252 |           # Get top 10 most common imports
    |

PERF401 Use `list.extend` to create a transformed list
   --> scripts/optimize_tests.py:275:21
    |
273 |               for conftest in structure.get("conftest_analysis", []):
274 |                   if conftest["complexity"] == "high":
275 | /                     recommendations.append(
276 | |                         {
277 | |                             "type": "fixture_optimization",
278 | |                             "priority": "high",
279 | |                             "title": "Simplify complex conftest.py",
280 | |                             "description": f"{conftest['file']} has {conftest['lines']} lines and {conftest['fixtures']} fixtures. Co…
281 | |                             "action": "Split large conftest.py files and optimize fixture scopes",
282 | |                         }
283 | |                     )
    | |_____________________^
284 |
285 |               # Check test organization
    |
help: Replace for loop with list.extend

S603 `subprocess` call: check for execution of untrusted input
  --> scripts/optimized_security_scan.py:34:22
   |
32 |         """Run command with timeout and error handling."""
33 |         try:
34 |             result = subprocess.run(
   |                      ^^^^^^^^^^^^^^
35 |                 cmd,
36 |                 timeout=timeout,
   |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/optimized_security_scan.py:287:22
    |
285 |     for tool in required_tools:
286 |         try:
287 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
288 |                 [sys.executable, "-m", tool, "--version"],
289 |                 capture_output=True,
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/optimized_security_scan.py:297:9
    |
295 |               else:
296 |                   raise subprocess.CalledProcessError(result.returncode, tool)
297 | /         except (
298 | |             subprocess.CalledProcessError,
299 | |             FileNotFoundError,
300 | |             subprocess.TimeoutExpired,
301 | |         ):
302 | |             print(f"⚠️ Installing tool '{tool}'...")
303 | |             try:
304 | |                 subprocess.run(
305 | |                     [sys.executable, "-m", "pip", "install", tool],
306 | |                     check=True,
307 | |                     timeout=60,
308 | |                 )
309 | |                 print(f"✅ Tool '{tool}' installed successfully")
310 | |             except subprocess.TimeoutExpired:
311 | |                 print(f"❌ Failed to install '{tool}' - timeout")
312 | |                 sys.exit(1)
313 | |             except Exception as e:
314 | |                 print(f"❌ Failed to install '{tool}': {e}")
315 | |                 sys.exit(1)
    | |___________________________^
316 |
317 |       # Run scans
    |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/optimized_security_scan.py:304:17
    |
302 |             print(f"⚠️ Installing tool '{tool}'...")
303 |             try:
304 |                 subprocess.run(
    |                 ^^^^^^^^^^^^^^
305 |                     [sys.executable, "-m", "pip", "install", tool],
306 |                     check=True,
    |

C901 `_extract_metrics_from_results` is too complex (11 > 10)
   --> scripts/performance_regression_detector.py:108:9
    |
106 |         self.save_baselines()
107 |
108 |     def _extract_metrics_from_results(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
109 |         self, results: dict[str, Any]
110 |     ) -> dict[str, float]:
    |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/production_performance_validator.py:427:22
    |
426 |             # Run a minimal load test for validation
427 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
428 |                 ["python", str(load_script), "--scenario", "basic"],
429 |                 cwd=self.project_root,
    |

S607 Starting a process with a partial executable path
   --> scripts/production_performance_validator.py:428:17
    |
426 |             # Run a minimal load test for validation
427 |             result = subprocess.run(
428 |                 ["python", str(load_script), "--scenario", "basic"],
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
429 |                 cwd=self.project_root,
430 |                 capture_output=True,
    |

B007 Loop control variable `operation` not used within loop body
   --> scripts/production_performance_validator.py:573:17
    |
571 |         if db_details:
572 |             db_values = []
573 |             for operation, data in db_details.items():
    |                 ^^^^^^^^^
574 |                 if isinstance(data, dict) and "value" in data:
575 |                     db_values.append(data["value"])
    |
help: Rename unused `operation` to `_operation`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/production_performance_validator.py:573:36
    |
571 |         if db_details:
572 |             db_values = []
573 |             for operation, data in db_details.items():
    |                                    ^^^^^^^^^^^^^^^^
574 |                 if isinstance(data, dict) and "value" in data:
575 |                     db_values.append(data["value"])
    |
help: Replace `.items()` with `.values()`

B007 Loop control variable `endpoint` not used within loop body
   --> scripts/production_performance_validator.py:588:17
    |
586 |         if api_details:
587 |             api_values = []
588 |             for endpoint, data in api_details.items():
    |                 ^^^^^^^^
589 |                 if isinstance(data, dict) and "value" in data:
590 |                     api_values.append(data["value"])
    |
help: Rename unused `endpoint` to `_endpoint`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/production_performance_validator.py:588:35
    |
586 |         if api_details:
587 |             api_values = []
588 |             for endpoint, data in api_details.items():
    |                                   ^^^^^^^^^^^^^^^^^
589 |                 if isinstance(data, dict) and "value" in data:
590 |                     api_values.append(data["value"])
    |
help: Replace `.items()` with `.values()`

S608 Possible SQL injection vector through string-based query construction
   --> scripts/query_performance_analyzer.py:300:21
    |
299 |               # Get slow queries from database
300 |               query = f"""
    |  _____________________^
301 | |                 SELECT query_id, query_text,
302 | |                        AVG(execution_time_ms) as avg_time,
303 | |                        MAX(execution_time_ms) as max_time,
304 | |                        MIN(execution_time_ms) as min_time,
305 | |                        COUNT(*) as execution_count,
306 | |                        SUM(execution_time_ms) as total_time
307 | |                 FROM query_performance_log
308 | |                 WHERE execution_time_ms >= ? {time_filter}
309 | |                 GROUP BY query_id, query_text
310 | |                 HAVING avg_time >= ?
311 | |                 ORDER BY avg_time DESC, execution_count DESC
312 | |                 LIMIT ?
313 | |             """
    | |_______________^
314 |
315 |               params = [threshold_ms] + params + [threshold_ms, limit]
    |

F841 Local variable `query_text_lower` is assigned to but never used
   --> scripts/query_performance_analyzer.py:424:9
    |
422 |     def _generate_recommendations(self, analysis: QueryAnalysisResult) -> None:
423 |         """Generate optimization recommendations for the query."""
424 |         query_text_lower = analysis.query_text.lower()
    |         ^^^^^^^^^^^^^^^^
425 |
426 |         # Recommendations based on bottlenecks
    |
help: Remove assignment to unused variable `query_text_lower`

PERF401 Use `list.extend` to create a transformed list
   --> scripts/query_performance_analyzer.py:696:21
    |
694 |               if where_columns:
695 |                   for column in where_columns:
696 | /                     optimizations_applied.append(
697 | |                         f"Suggestion: Consider index on column '{column}'"
698 | |                     )
    | |_____________________^
699 |
700 |               # Optimization 4: Rewrite LIKE with leading wildcard
    |
help: Replace for loop with list.extend

F841 Local variable `result` is assigned to but never used
   --> scripts/query_performance_analyzer.py:774:13
    |
772 |             cutoff_date = datetime.now() - timedelta(days=days_to_keep)
773 |
774 |             result = self.db.execute(
    |             ^^^^^^
775 |                 """
776 |                 DELETE FROM query_performance_log
    |
help: Remove assignment to unused variable `result`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/rag_performance_scaler.py:149:13
    |
147 |                       logger.debug(f"No data for RAG metric {metric_name}")
148 |
149 | /             except Exception as e:
150 | |                 logger.warning(f"Error collecting RAG metric {metric_name}: {e}")
151 | |                 metrics[metric_name] = 0.0
    | |__________________________________________^
152 |
153 |           return metrics
    |

F841 Local variable `query_rate` is assigned to but never used
   --> scripts/rag_performance_scaler.py:195:9
    |
194 |         # Calculate memory per query (approximate)
195 |         query_rate = max(
    |         ^^^^^^^^^^
196 |             0.01, metrics.get("rag_query_rate", 0.01)
197 |         )  # Avoid division by zero
    |
help: Remove assignment to unused variable `query_rate`

C901 `make_scaling_decision` is too complex (11 > 10)
   --> scripts/rag_performance_scaler.py:463:15
    |
461 |         return total_cost_change
462 |
463 |     async def make_scaling_decision(self, current_replicas: int) -> RAGScalingDecision:
    |               ^^^^^^^^^^^^^^^^^^^^^
464 |         """Make RAG-aware scaling decision"""
    |

E722 Do not use bare `except`
   --> scripts/rag_performance_scaler.py:622:13
    |
620 |             try:
621 |                 config.load_incluster_config()
622 |             except:
    |             ^^^^^^
623 |                 try:
624 |                     config.load_kube_config()
    |

E722 Do not use bare `except`
   --> scripts/rag_performance_scaler.py:625:17
    |
623 |                 try:
624 |                     config.load_kube_config()
625 |                 except:
    |                 ^^^^^^
626 |                     self.k8s_available = False
    |

E722 Do not use bare `except`
   --> scripts/rag_performance_scaler.py:641:13
    |
639 |                 if result and len(result) > 0:
640 |                     return int(float(result[0]["value"][1]))
641 |             except:
    |             ^^^^^^
642 |                 pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/rag_performance_scaler.py:641:13
    |
639 |                   if result and len(result) > 0:
640 |                       return int(float(result[0]["value"][1]))
641 | /             except:
642 | |                 pass
    | |____________________^
643 |
644 |               return 2  # Default fallback
    |

E722 Do not use bare `except`
   --> scripts/rag_performance_scaler.py:651:9
    |
649 |             )
650 |             return deployment.spec.replicas
651 |         except:
    |         ^^^^^^
652 |             return 2
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/rag_performance_scaler.py:698:13
    |
696 |                   await asyncio.sleep(interval_seconds)
697 |
698 | /             except KeyboardInterrupt:
699 | |                 logger.info("RAG scaling orchestrator stopped by user")
700 | |                 break
    | |_____________________^
701 |               except Exception as e:
702 |                   logger.error(f"Error in RAG scaling cycle: {e}")
    |

F841 Local variable `current_replicas` is assigned to but never used
   --> scripts/rag_performance_scaler.py:734:9
    |
732 |     if args.mode == "analyze":
733 |         logger.info("Analyzing RAG workload...")
734 |         current_replicas = await orchestrator.get_current_replicas()
    |         ^^^^^^^^^^^^^^^^
735 |         metrics = await orchestrator.scaler.workload_analyzer.collect_rag_metrics()
736 |         profile = await orchestrator.scaler.workload_analyzer.create_workload_profile(
    |
help: Remove assignment to unused variable `current_replicas`

E722 Do not use bare `except`
   --> scripts/redis_performance_tuner.py:219:13
    |
217 |                         [item[1] for item in latency_history]
218 |                     )[int(len(latency_history) * 0.99)]
219 |             except:
    |             ^^^^^^
220 |                 pass  # Latency history might not be available
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/redis_performance_tuner.py:219:13
    |
217 |                           [item[1] for item in latency_history]
218 |                       )[int(len(latency_history) * 0.99)]
219 | /             except:
220 | |                 pass  # Latency history might not be available
    | |____________________^
221 |
222 |               # Get slow log
    |

E722 Do not use bare `except`
   --> scripts/redis_performance_tuner.py:226:13
    |
224 |                 slow_log = await asyncio.to_thread(client.slowlog_get, 10)
225 |                 metrics.slow_queries_count = len(slow_log)
226 |             except:
    |             ^^^^^^
227 |                 pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/redis_performance_tuner.py:226:13
    |
224 |                   slow_log = await asyncio.to_thread(client.slowlog_get, 10)
225 |                   metrics.slow_queries_count = len(slow_log)
226 | /             except:
227 | |                 pass
    | |____________________^
228 |
229 |               # Calculate derived metrics
    |

SIM210 Remove unnecessary `True if ... else False`
   --> scripts/redis_performance_tuner.py:583:29
    |
581 |                         operation="health_check",
582 |                         cache_type="redis",
583 |                         hit=True if metrics.hit_rate_percent > 80 else False,
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
584 |                     )
585 |                     self.metrics_service.update_cache_size(
    |
help: Remove unnecessary `True if ... else False`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/redis_performance_tuner.py:592:13
    |
590 |                   await asyncio.sleep(interval_minutes * 60)
591 |
592 | /             except asyncio.CancelledError:
593 | |                 break
    | |_____________________^
594 |               except Exception as e:
595 |                   logger.error(f"Error in continuous tuning: {e}")
    |

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   --> scripts/rollback_automation.py:308:17
    |
306 |           for backup_url in config.backup_urls:
307 |               try:
308 | /                 async with aiohttp.ClientSession(timeout=self.http_timeout) as session:
309 | |                     async with session.get(f"{backup_url}/health") as response:
    | |_______________________________________________________________________________^
310 |                           if response.status == 200:
311 |                               result.logs.append(
    |
help: Combine `with` statements

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/rollback_automation.py:319:13
    |
317 |                                   f"Rollback target unhealthy: {backup_url} (status: {response.status})"
318 |                               )
319 | /             except Exception as e:
320 | |                 result.logs.append(f"Rollback target check failed: {backup_url} - {e}")
    | |_______________________________________________________________________________________^
321 |
322 |           # If no backup URLs worked, we'll proceed anyway but log the concern
    |

F841 Local variable `config` is assigned to but never used
   --> scripts/rollback_automation.py:341:9
    |
339 |         result.logs.append("Starting fast rollback - immediate traffic switch")
340 |
341 |         config = result.config
    |         ^^^^^^
342 |
343 |         # Step 1: Immediate traffic redirection
    |
help: Remove assignment to unused variable `config`

F841 Local variable `config` is assigned to but never used
   --> scripts/rollback_automation.py:395:9
    |
393 |     ) -> None:
394 |         """Redirect traffic to rollback target"""
395 |         config = result.config
    |         ^^^^^^
396 |
397 |         if immediate or percentage == 100:
    |
help: Remove assignment to unused variable `config`

C901 `main` is too complex (17 > 10)
   --> scripts/rollback_automation.py:690:11
    |
690 | async def main():
    |           ^^^^
691 |     """Main CLI interface"""
692 |     parser = argparse.ArgumentParser(
    |

C901 `_determine_test_success` is too complex (11 > 10)
   --> scripts/run_production_validation.py:267:9
    |
265 |             }
266 |
267 |     def _determine_test_success(self, result, test_name):
    |         ^^^^^^^^^^^^^^^^^^^^^^^
268 |         """Determine if test was successful based on result structure."""
269 |         if isinstance(result, bool):
    |

B007 Loop control variable `key` not used within loop body
   --> scripts/run_production_validation.py:292:17
    |
291 |             # Look for nested success indicators
292 |             for key, value in result.items():
    |                 ^^^
293 |                 if isinstance(value, dict):
294 |                     if "overall_success" in value:
    |
help: Rename unused `key` to `_key`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/run_production_validation.py:292:31
    |
291 |             # Look for nested success indicators
292 |             for key, value in result.items():
    |                               ^^^^^^^^^^^^
293 |                 if isinstance(value, dict):
294 |                     if "overall_success" in value:
    |
help: Replace `.items()` with `.values()`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> scripts/run_production_validation.py:319:13
    |
318 |               # If critical test fails, consider stopping
319 | /             if test_config["critical"] and not test_result["success"]:
320 | |                 if not test_result.get("skipped", False):
    | |_________________________________________________________^
321 |                       logger.error(
322 |                           f"💀 Critical test {test_config['name']} failed - continuing with remaining tests"
    |
help: Combine `if` statements using `and`

C403 Unnecessary list comprehension (rewrite as a set comprehension)
   --> scripts/run_security_tests.py:385:29
    |
383 |                           "business_impact": self._get_business_impact(severity),
384 |                           "affected_components": list(
385 | /                             set(
386 | |                                 [
387 | |                                     vuln.get(
388 | |                                         "endpoint", vuln.get("component", "Unknown")
389 | |                                     )
390 | |                                     for vuln in vulns
391 | |                                 ]
392 | |                             )
    | |_____________________________^
393 |                           ),
394 |                       }
    |
help: Rewrite as a set comprehension

S603 `subprocess` call: check for execution of untrusted input
  --> scripts/run_tests.py:90:18
   |
89 |         start_time = time.time()
90 |         result = subprocess.run(
   |                  ^^^^^^^^^^^^^^
91 |             cmd, capture_output=True, text=True, cwd=self.project_root
92 |         )
   |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/run_tests.py:125:18
    |
123 |         ]
124 |
125 |         result = subprocess.run(
    |                  ^^^^^^^^^^^^^^
126 |             cmd, capture_output=True, text=True, cwd=self.project_root
127 |         )
    |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/run_tests.py:143:9
    |
142 |         # Generate JSON coverage for programmatic access
143 |         subprocess.run(
    |         ^^^^^^^^^^^^^^
144 |             [sys.executable, "-m", "coverage", "json", "-o", "coverage.json"],
145 |             cwd=self.project_root,
    |

F841 Local variable `test_selection` is assigned to but never used
   --> scripts/run_tests.py:229:13
    |
227 |         k_index = sys.argv.index("-k")
228 |         if k_index + 1 < len(sys.argv):
229 |             test_selection = sys.argv[k_index + 1]
    |             ^^^^^^^^^^^^^^
230 |
231 |     # Run tests
    |
help: Remove assignment to unused variable `test_selection`

B028 No explicit `stacklevel` keyword argument found
  --> scripts/scaling_predictor.py:41:5
   |
39 | except ImportError:
40 |     KUBERNETES_AVAILABLE = False
41 |     warnings.warn(
   |     ^^^^^^^^^^^^^
42 |         "Kubernetes client not available. Install with: pip install kubernetes"
43 |     )
   |
help: Set `stacklevel=2`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/scaling_predictor.py:131:13
    |
129 |                       logger.warning(f"No data for metric {metric_name}")
130 |
131 | /             except Exception as e:
132 | |                 logger.error(f"Error collecting metric {metric_name}: {e}")
133 | |                 metrics[metric_name] = 0.0
    | |__________________________________________^
134 |
135 |           return metrics
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/scaling_predictor.py:161:17
    |
159 |                       else:
160 |                           metrics[metric_name] = 0.0
161 | /                 except Exception as e:
162 | |                     logger.warning(f"Error collecting historical {metric_name}: {e}")
163 | |                     metrics[metric_name] = 0.0
    | |______________________________________________^
164 |
165 |               all_data.append(metrics)
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/scaling_models"
   --> scripts/scaling_predictor.py:174:42
    |
172 |     """ML-based scaling predictor"""
173 |
174 |     def __init__(self, model_path: str = "/tmp/scaling_models"):
    |                                          ^^^^^^^^^^^^^^^^^^^^^
175 |         self.model_path = Path(model_path)
176 |         self.model_path.mkdir(exist_ok=True, parents=True)
    |

F841 Local variable `anomaly_score` is assigned to but never used
   --> scripts/scaling_predictor.py:338:9
    |
337 |         # Detect anomalies
338 |         anomaly_score = self.anomaly_detector.decision_function(X_scaled)[0]
    |         ^^^^^^^^^^^^^
339 |         is_anomaly = self.anomaly_detector.predict(X_scaled)[0] == -1
    |
help: Remove assignment to unused variable `anomaly_score`

E722 Do not use bare `except`
   --> scripts/scaling_predictor.py:434:13
    |
432 |             try:
433 |                 config.load_incluster_config()  # Try in-cluster config first
434 |             except:
    |             ^^^^^^
435 |                 try:
436 |                     config.load_kube_config()  # Fallback to local config
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/scaling_predictor.py:684:13
    |
682 |                   await asyncio.sleep(self.prediction_interval)
683 |
684 | /             except KeyboardInterrupt:
685 | |                 logger.info("Scaling manager stopped by user")
686 | |                 break
    | |_____________________^
687 |               except Exception as e:
688 |                   logger.error(f"Error in continuous loop: {e}")
    |

C901 `validate_phase_requirements` is too complex (11 > 10)
   --> scripts/security_headers_migration.py:129:9
    |
127 |         return configs[phase]
128 |
129 |     def validate_phase_requirements(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
130 |         self, phase: MigrationPhase
131 |     ) -> tuple[bool, list[str]]:
    |

S103 `os.chmod` setting a permissive mask `0o755` on file or directory
   --> scripts/security_headers_migration.py:388:37
    |
386 |         # Make executable on Unix-like systems
387 |         if os.name != "nt":
388 |             os.chmod(rollback_file, 0o755)
    |                                     ^^^^^
389 |
390 |         logger.info(f"Generated rollback script: {rollback_file}")
    |

C901 `main` is too complex (11 > 10)
   --> scripts/security_headers_migration.py:393:5
    |
393 | def main():
    |     ^^^^
394 |     """Main entry point for migration script."""
395 |     parser = argparse.ArgumentParser(description="Security Headers Migration Tool")
    |

S306 Use of insecure and deprecated function (`mktemp`)
  --> scripts/simple_benchmark.py:33:24
   |
32 |     def __init__(self):
33 |         self.db_path = tempfile.mktemp(suffix=".db")
   |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
34 |         self.db = None
35 |         self.results = {}
   |

B007 Loop control variable `run` not used within loop body
  --> scripts/simple_benchmark.py:69:17
   |
67 |             query_times = []
68 |
69 |             for run in range(runs):
   |                 ^^^
70 |                 start_time = time.perf_counter()
71 |                 try:
   |
help: Rename unused `run` to `_run`

F841 Local variable `result_count` is assigned to but never used
  --> scripts/simple_benchmark.py:73:21
   |
71 |                 try:
72 |                     result = self.db.fetch_all(query_sql)
73 |                     result_count = len(result) if result else 0
   |                     ^^^^^^^^^^^^
74 |                 except Exception as e:
75 |                     logger.warning(f"Query {query_name} failed: {e}")
   |
help: Remove assignment to unused variable `result_count`

B007 Loop control variable `run` not used within loop body
   --> scripts/simple_benchmark.py:130:17
    |
128 |             read_times = []
129 |
130 |             for run in range(runs):
    |                 ^^^
131 |                 start_time = time.perf_counter()
132 |                 try:
    |
help: Rename unused `run` to `_run`

F841 Local variable `content_length` is assigned to but never used
   --> scripts/simple_benchmark.py:134:21
    |
132 |                 try:
133 |                     content = file_path.read_text()
134 |                     content_length = len(content)
    |                     ^^^^^^^^^^^^^^
135 |                 except Exception as e:
136 |                     logger.warning(f"File read {file_type} failed: {e}")
    |
help: Remove assignment to unused variable `content_length`

B007 Loop control variable `run` not used within loop body
   --> scripts/simple_benchmark.py:191:17
    |
189 |             processing_times = []
190 |
191 |             for run in range(runs):
    |                 ^^^
192 |                 start_time = time.perf_counter()
    |
help: Rename unused `run` to `_run`

F841 Local variable `word_count` is assigned to but never used
   --> scripts/simple_benchmark.py:196:17
    |
194 |                 # Simulate text processing operations
195 |                 words = text_content.split()
196 |                 word_count = len(words)
    |                 ^^^^^^^^^^
197 |                 char_count = len(text_content)
198 |                 sentences = text_content.split(". ")
    |
help: Remove assignment to unused variable `word_count`

F841 Local variable `char_count` is assigned to but never used
   --> scripts/simple_benchmark.py:197:17
    |
195 |                 words = text_content.split()
196 |                 word_count = len(words)
197 |                 char_count = len(text_content)
    |                 ^^^^^^^^^^
198 |                 sentences = text_content.split(". ")
199 |                 sentence_count = len(sentences)
    |
help: Remove assignment to unused variable `char_count`

F841 Local variable `sentence_count` is assigned to but never used
   --> scripts/simple_benchmark.py:199:17
    |
197 |                 char_count = len(text_content)
198 |                 sentences = text_content.split(". ")
199 |                 sentence_count = len(sentences)
    |                 ^^^^^^^^^^^^^^
200 |
201 |                 # Basic text cleaning
    |
help: Remove assignment to unused variable `sentence_count`

F841 Local variable `cleaned_text` is assigned to but never used
   --> scripts/simple_benchmark.py:202:17
    |
201 |                 # Basic text cleaning
202 |                 cleaned_text = text_content.strip().lower()
    |                 ^^^^^^^^^^^^
203 |
204 |                 end_time = time.perf_counter()
    |
help: Remove assignment to unused variable `cleaned_text`

C901 `print_summary` is too complex (15 > 10)
   --> scripts/simple_benchmark.py:269:9
    |
267 |         return self.results
268 |
269 |     def print_summary(self):
    |         ^^^^^^^^^^^^^
270 |         """Print benchmark summary"""
271 |         print("\n" + "=" * 80)
    |

C901 `optimize_image` is too complex (15 > 10)
   --> scripts/static_asset_optimizer.py:214:15
    |
212 |         }
213 |
214 |     async def optimize_image(self, input_path: Path, output_dir: Path) -> AssetInfo:
    |               ^^^^^^^^^^^^^^
215 |         """Optimize a single image."""
216 |         start_time = time.time()
    |

SIM108 Use ternary operator `suffix = input_path.suffix if format_name == "original" else f".{format_name}"` instead of `if`-`else`-block
   --> scripts/static_asset_optimizer.py:347:9
    |
345 |       ) -> Path:
346 |           """Get output path for optimized image."""
347 | /         if format_name == "original":
348 | |             suffix = input_path.suffix
349 | |         else:
350 | |             suffix = f".{format_name}"
    | |______________________________________^
351 |
352 |           filename = f"{input_path.stem}{suffix}"
    |
help: Replace `if`-`else`-block with `suffix = input_path.suffix if format_name == "original" else f".{format_name}"`

PERF401 Use a list comprehension to create a transformed list
   --> scripts/static_asset_optimizer.py:650:17
    |
648 |         for file_path in input_dir.rglob("*"):
649 |             if file_path.is_file() and file_path.suffix.lower() in all_extensions:
650 |                 assets.append(file_path)
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^
651 |
652 |         return assets
    |
help: Replace for loop with list comprehension

B007 Loop control variable `format_name` not used within loop body
   --> scripts/static_asset_optimizer.py:828:21
    |
826 |             # Upload all optimized assets
827 |             for asset_info in self.optimized_assets.values():
828 |                 for format_name, asset_path in asset_info.versions.items():
    |                     ^^^^^^^^^^^
829 |                     success = await self._upload_single_asset(asset_path, output_dir)
830 |                     if success:
    |
help: Rename unused `format_name` to `_format_name`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/static_asset_optimizer.py:828:48
    |
826 |             # Upload all optimized assets
827 |             for asset_info in self.optimized_assets.values():
828 |                 for format_name, asset_path in asset_info.versions.items():
    |                                                ^^^^^^^^^^^^^^^^^^^^^^^^^
829 |                     success = await self._upload_single_asset(asset_path, output_dir)
830 |                     if success:
    |
help: Replace `.items()` with `.values()`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/system_maintenance.py:156:13
    |
154 |                       self.tasks_completed.append(result)
155 |
156 | /             except Exception as e:
157 | |                 logger.error(f"Maintenance task {task_name} failed: {e}")
158 | |                 self.tasks_completed.append(
159 | |                     MaintenanceTask(
160 | |                         task_name=task_name,
161 | |                         status="failed",
162 | |                         message=f"Task failed with error: {str(e)}",
163 | |                         execution_time=0.0,
164 | |                     )
165 | |                 )
    | |_________________^
166 |
167 |           # Generate maintenance report
    |

S608 Possible SQL injection vector through string-based query construction
   --> scripts/system_maintenance.py:345:40
    |
343 |                     for table in tables:
344 |                         table_name = table[0]
345 |                         cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
    |                                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
346 |                         row_count = cursor.fetchone()[0]
347 |                         table_stats[table_name] = row_count
    |

PERF401 Use a list comprehension to create a transformed list
   --> scripts/system_maintenance.py:525:21
    |
523 |             for backup_file in backup_dir.glob("ai_pdf_scholar_backup_*.db"):
524 |                 if backup_file.stat().st_mtime < cutoff_date.timestamp():
525 |                     old_backups.append(backup_file)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
526 |
527 |             if old_backups:
    |
help: Replace for loop with list comprehension

S607 Starting a process with a partial executable path
   --> scripts/system_maintenance.py:592:25
    |
590 |                 try:
591 |                     result = subprocess.run(
592 |                         ["logrotate", "/etc/logrotate.d/ai-pdf-scholar"],
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
593 |                         capture_output=True,
594 |                         text=True,
    |

C901 `_log_compression` is too complex (11 > 10)
   --> scripts/system_maintenance.py:643:9
    |
641 |             )
642 |
643 |     def _log_compression(self) -> MaintenanceTask:
    |         ^^^^^^^^^^^^^^^^
644 |         """Compress old log files."""
645 |         start_time = time.time()
    |

F841 Local variable `result` is assigned to but never used
   --> scripts/system_maintenance.py:672:33
    |
671 | …                     try:
672 | …                         result = subprocess.run(
    |                           ^^^^^^
673 | …                             ["gzip", str(log_file)], check=True, timeout=300
674 | …                         )
    |
help: Remove assignment to unused variable `result`

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/system_maintenance.py:672:42
    |
671 | …                     try:
672 | …                         result = subprocess.run(
    |                                    ^^^^^^^^^^^^^^
673 | …                             ["gzip", str(log_file)], check=True, timeout=300
674 | …                         )
    |

S607 Starting a process with a partial executable path
   --> scripts/system_maintenance.py:673:37
    |
671 | …                     try:
672 | …                         result = subprocess.run(
673 | …                             ["gzip", str(log_file)], check=True, timeout=300
    |                               ^^^^^^^^^^^^^^^^^^^^^^^
674 | …                         )
    |

C901 `_redis_cache_optimization` is too complex (11 > 10)
   --> scripts/system_maintenance.py:795:9
    |
793 |         return tasks
794 |
795 |     def _redis_cache_optimization(self) -> MaintenanceTask:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^
796 |         """Optimize Redis cache."""
797 |         start_time = time.time()
    |

S108 Probable insecure usage of temporary file or directory: "/tmp"
   --> scripts/system_maintenance.py:891:22
    |
889 |                 self.config.DATA_DIR / "cache",
890 |                 self.config.DATA_DIR / "temp",
891 |                 Path("/tmp") / "ai_pdf_scholar_cache",
    |                      ^^^^^^
892 |             ]
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/system_maintenance.py:978:29
    |
976 |                                   cursor.fetchall()
977 |                                   warmed_items += 1
978 | /                             except sqlite3.Error:
979 | |                                 continue
    | |________________________________________^
980 |               except Exception:
981 |                   pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/system_maintenance.py:980:13
    |
978 |                               except sqlite3.Error:
979 |                                   continue
980 | /             except Exception:
981 | |                 pass
    | |____________________^
982 |
983 |               # Warm up Redis cache with popular data
    |

C901 `_disk_cleanup` is too complex (14 > 10)
    --> scripts/system_maintenance.py:1034:9
     |
1032 |         return tasks
1033 |
1034 |     def _disk_cleanup(self) -> MaintenanceTask:
     |         ^^^^^^^^^^^^^
1035 |         """Perform disk cleanup operations."""
1036 |         start_time = time.time()
     |

S108 Probable insecure usage of temporary file or directory: "/tmp"
    --> scripts/system_maintenance.py:1059:30
     |
1057 |             if not self.config.DRY_RUN:
1058 |                 # Clean temporary files
1059 |                 temp_dirs = ["/tmp", "/var/tmp", str(self.config.DATA_DIR / "temp")]
     |                              ^^^^^^
1060 |
1061 |                 for temp_dir in temp_dirs:
     |

S108 Probable insecure usage of temporary file or directory: "/var/tmp"
    --> scripts/system_maintenance.py:1059:38
     |
1057 |             if not self.config.DRY_RUN:
1058 |                 # Clean temporary files
1059 |                 temp_dirs = ["/tmp", "/var/tmp", str(self.config.DATA_DIR / "temp")]
     |                                      ^^^^^^^^^^
1060 |
1061 |                 for temp_dir in temp_dirs:
     |

S112 `try`-`except`-`continue` detected, consider logging the exception
    --> scripts/system_maintenance.py:1073:33
     |
1071 |                                           temp_file.unlink()
1072 |                                           total_freed += file_size
1073 | /                                 except Exception:
1074 | |                                     continue
     | |____________________________________________^
1075 |
1076 |                   cleanup_actions.append("Cleaned temporary files")
     |

S607 Starting a process with a partial executable path
    --> scripts/system_maintenance.py:1081:25
     |
1079 |                 try:
1080 |                     result = subprocess.run(
1081 |                         ["apt-get", "autoremove", "-y"],
     |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1082 |                         capture_output=True,
1083 |                         timeout=300,
     |

S607 Starting a process with a partial executable path
    --> scripts/system_maintenance.py:1092:25
     |
1090 |                 try:
1091 |                     result = subprocess.run(
1092 |                         ["apt-get", "autoclean"], capture_output=True, timeout=120
     |                         ^^^^^^^^^^^^^^^^^^^^^^^^
1093 |                     )
1094 |                     if result.returncode == 0:
     |

C901 `_directory_organization` is too complex (13 > 10)
    --> scripts/system_maintenance.py:1122:9
     |
1120 |             )
1121 |
1122 |     def _directory_organization(self) -> MaintenanceTask:
     |         ^^^^^^^^^^^^^^^^^^^^^^^
1123 |         """Organize and clean up directory structure."""
1124 |         start_time = time.time()
     |

PERF401 Use a list comprehension to create a transformed list
    --> scripts/system_maintenance.py:1450:21
     |
1448 |                 if env_var in os.environ:
1449 |                     # Basic check - in production, you'd check actual rotation dates
1450 |                     rotation_needed.append(f"{env_var}: Consider rotation")
     |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1451 |
1452 |             if rotation_needed:
     |
help: Replace for loop with list comprehension

C901 `_generate_recommendations` is too complex (11 > 10)
    --> scripts/system_maintenance.py:1620:9
     |
1618 |     # ============================================================================
1619 |
1620 |     def _generate_recommendations(self) -> list[str]:
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^
1621 |         """Generate maintenance recommendations based on task results."""
1622 |         recommendations = []
     |

SIM102 Use a single `if` statement instead of nested `if` statements
    --> scripts/system_maintenance.py:1660:13
     |
1658 |                       )
1659 |
1660 | /             elif task.task_name == "log_cleanup" and task.status == "success":
1661 | |                 if task.metrics and task.metrics.get("files_deleted", 0) > 100:
     | |_______________________________________________________________________________^
1662 |                       recommendations.append(
1663 |                           "Large number of old log files - consider adjusting log retention policies"
     |
help: Combine `if` statements using `and`

E722 Do not use bare `except`
   --> scripts/system_performance_monitor.py:220:9
    |
218 |                 else 0
219 |             )
220 |         except:
    |         ^^^^^^
221 |             db_size = 0
    |

F841 Local variable `results` is assigned to but never used
   --> scripts/system_performance_monitor.py:233:21
    |
231 |                     start_time = time.time()
232 |                     cursor = conn.execute(query)
233 |                     results = cursor.fetchall()
    |                     ^^^^^^^
234 |                     end_time = time.time()
    |
help: Remove assignment to unused variable `results`

F841 Local variable `word_count` is assigned to but never used
   --> scripts/system_performance_monitor.py:309:21
    |
307 |                     text = "Sample text for processing " * 1000
308 |                     processed = text.upper().lower().split()
309 |                     word_count = len(processed)
    |                     ^^^^^^^^^^
310 |
311 |                 # Monitor memory every 100 operations
    |
help: Remove assignment to unused variable `word_count`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/system_performance_monitor.py:316:13
    |
314 |                       peak_memory = max(peak_memory, current_memory)
315 |
316 | /             except Exception as e:
317 | |                 logger.warning(f"Operation {i} failed: {e}")
    | |____________________________________________________________^
318 |
319 |           end_time = time.time()
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/system_performance_monitor.py:406:17
    |
404 |                       results.extend(user_results)
405 |                       errors.extend(user_errors)
406 | /                 except Exception as e:
407 | |                     logger.error(f"Concurrent test thread failed: {e}")
408 | |                     errors.append(str(e))
    | |_________________________________________^
409 |
410 |           total_time = time.time() - start_time
    |

B007 Loop control variable `i` not used within loop body
   --> scripts/system_performance_monitor.py:462:13
    |
460 |         errors = []
461 |
462 |         for i in range(iterations):
    |             ^
463 |             try:
464 |                 start_time = time.time()
    |
help: Rename unused `i` to `_i`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/system_performance_monitor.py:474:13
    |
472 |                   successful += 1
473 |
474 | /             except Exception as e:
475 | |                 failed += 1
476 | |                 errors.append(str(e))
    | |_____________________________________^
477 |
478 |           reliability_tests.append(
    |

B007 Loop control variable `i` not used within loop body
   --> scripts/system_performance_monitor.py:501:13
    |
499 |         errors = []
500 |
501 |         for i in range(iterations):
    |             ^
502 |             try:
503 |                 start_time = time.time()
    |
help: Rename unused `i` to `_i`

B007 Loop control variable `j` not used within loop body
   --> scripts/system_performance_monitor.py:508:25
    |
506 |                 connections = []
507 |                 try:
508 |                     for j in range(10):  # Create 10 connections
    |                         ^
509 |                         conn = sqlite3.connect(self.db_path, timeout=1)
510 |                         connections.append(conn)
    |
help: Rename unused `j` to `_j`

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
   --> scripts/system_performance_monitor.py:524:25
    |
522 |                       # Cleanup any remaining connections
523 |                       for conn in connections:
524 | /                         try:
525 | |                             conn.close()
526 | |                         except:
527 | |                             pass
    | |________________________________^
528 |                       raise conn_error
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
   --> scripts/system_performance_monitor.py:526:25
    |
524 |                         try:
525 |                             conn.close()
526 |                         except:
    |                         ^^^^^^
527 |                             pass
528 |                     raise conn_error
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/system_performance_monitor.py:526:25
    |
524 |                           try:
525 |                               conn.close()
526 | /                         except:
527 | |                             pass
    | |________________________________^
528 |                       raise conn_error
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/system_performance_monitor.py:526:25
    |
524 |                           try:
525 |                               conn.close()
526 | /                         except:
527 | |                             pass
    | |________________________________^
528 |                       raise conn_error
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/system_performance_monitor.py:530:13
    |
528 |                       raise conn_error
529 |
530 | /             except Exception as e:
531 | |                 failed += 1
532 | |                 errors.append(str(e))
    | |_____________________________________^
533 |
534 |           reliability_tests.append(
    |

C901 `generate_performance_summary` is too complex (11 > 10)
   --> scripts/system_performance_monitor.py:648:9
    |
646 |             }
647 |
648 |     def generate_performance_summary(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
649 |         self,
650 |         resource_metrics: dict,
    |

S603 `subprocess` call: check for execution of untrusted input
  --> scripts/test_ci_locally.py:35:22
   |
33 |         """Run a command and return result."""
34 |         try:
35 |             result = subprocess.run(
   |                      ^^^^^^^^^^^^^^
36 |                 cmd,
37 |                 cwd=self.project_root,
   |

S607 Starting a process with a partial executable path
   --> scripts/test_diagnostics.py:104:17
    |
102 |         try:
103 |             result = subprocess.run(
104 |                 ["python", "-m", "pytest", "--collect-only", "-q"],
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
105 |                 cwd=self.project_root,
106 |                 capture_output=True,
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/test_diagnostics.py:146:13
    |
144 |                   importlib.util.find_spec(package.replace("-", "_"))
145 |                   print(f"✅ {package} is available")
146 | /             except ImportError:
147 | |                 self.issues_found.append(f"Missing package: {package}")
148 | |                 self.recommendations.append(f"Install {package}: pip install {package}")
    | |________________________________________________________________________________________^
149 |
150 |       def check_test_file_patterns(self):
    |

F841 Local variable `valid_patterns` is assigned to but never used
   --> scripts/test_diagnostics.py:157:9
    |
155 |         test_files = [f for f in test_files if f.name != "__init__.py"]
156 |
157 |         valid_patterns = ["test_*.py", "*_test.py"]
    |         ^^^^^^^^^^^^^^
158 |         invalid_files = []
    |
help: Remove assignment to unused variable `valid_patterns`

S607 Starting a process with a partial executable path
   --> scripts/test_diagnostics.py:178:17
    |
176 |           try:
177 |               result = subprocess.run(
178 | /                 [
179 | |                     "python",
180 | |                     "-m",
181 | |                     "pytest",
182 | |                     "tests/test_database_connection.py",
183 | |                     "-v",
184 | |                     "--no-cov",
185 | |                     "--maxfail=1",
186 | |                 ],
    | |_________________^
187 |                   cwd=self.project_root,
188 |                   capture_output=True,
    |

UP036 Version block is outdated for minimum Python version
  --> scripts/test_environment_validator.py:85:16
   |
84 |             # Check minimum Python version (3.8+)
85 |             if sys.version_info < (3, 8):
   |                ^^^^^^^^^^^^^^^^^^^^^^^^^
86 |                 self.results["python_environment"]["status"] = "error"
87 |                 self.results["python_environment"]["details"] = {
   |
help: Remove outdated version block

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/test_environment_validator.py:146:13
    |
144 |                   print(f"✅ {package_name}: {version}")
145 |
146 | /             except ImportError:
147 | |                 missing_packages.append(package_name)
148 | |                 print(f"❌ {package_name}: Not installed")
    | |__________________________________________________________^
149 |
150 |           if missing_packages:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/test_environment_validator.py:182:13
    |
180 |                   import_status[module_name] = "ok"
181 |                   print(f"✅ {module_name}")
182 | /             except Exception as e:
183 | |                 import_status[module_name] = f"error: {e}"
184 | |                 failed_imports.append(module_name)
185 | |                 print(f"❌ {module_name}: {e}")
    | |_______________________________________________^
186 |
187 |           if failed_imports:
    |

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
   --> scripts/test_environment_validator.py:240:17
    |
238 |               finally:
239 |                   # Clean up temp file
240 | /                 try:
241 | |                     Path(temp_path).unlink(missing_ok=True)
242 | |                 except:
243 | |                     pass
    | |________________________^
244 |
245 |           except Exception as e:
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
   --> scripts/test_environment_validator.py:242:17
    |
240 |                 try:
241 |                     Path(temp_path).unlink(missing_ok=True)
242 |                 except:
    |                 ^^^^^^
243 |                     pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/test_environment_validator.py:242:17
    |
240 |                   try:
241 |                       Path(temp_path).unlink(missing_ok=True)
242 | /                 except:
243 | |                     pass
    | |________________________^
244 |
245 |           except Exception as e:
    |

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
   --> scripts/test_environment_validator.py:311:17
    |
310 |               finally:
311 | /                 try:
312 | |                     Path(temp_path).unlink(missing_ok=True)
313 | |                 except:
314 | |                     pass
    | |________________________^
315 |
316 |           except Exception as e:
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
   --> scripts/test_environment_validator.py:313:17
    |
311 |                 try:
312 |                     Path(temp_path).unlink(missing_ok=True)
313 |                 except:
    |                 ^^^^^^
314 |                     pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> scripts/test_environment_validator.py:313:17
    |
311 |                   try:
312 |                       Path(temp_path).unlink(missing_ok=True)
313 | /                 except:
314 | |                     pass
    | |________________________^
315 |
316 |           except Exception as e:
    |

S608 Possible SQL injection vector through string-based query construction
  --> scripts/test_performance_optimization.py:71:43
   |
69 |             for table in test_tables:
70 |                 try:
71 |                     result = db.fetch_one(f"SELECT COUNT(*) as count FROM {table}")
   |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
72 |                     logger.info(
73 |                         f"✅ Performance monitoring table '{table}' created (rows: {result['count'] if result else 0})"
   |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> scripts/test_performance_optimization.py:75:17
   |
73 |                           f"✅ Performance monitoring table '{table}' created (rows: {result['count'] if result else 0})"
74 |                       )
75 | /                 except Exception as e:
76 | |                     logger.error(
77 | |                         f"❌ Performance monitoring table '{table}' not found: {e}"
78 | |                     )
79 | |                     return False
   | |________________________________^
80 |
81 |               # Test advanced performance analysis functions
   |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/test_performance_optimization.py:172:13
    |
170 |                   )
171 |
172 | /             except Exception as e:
173 | |                 logger.error(f"❌ Query analysis failed for '{query_name}': {e}")
174 | |                 return False
    | |____________________________^
175 |
176 |           # Test benchmark functionality
    |

B007 Loop control variable `req_idx` not used within loop body
   --> scripts/test_rate_limiting.py:197:17
    |
195 |         for ip_idx in range(num_ips):
196 |             client_ip = f"192.168.{ip_idx // 256}.{ip_idx % 256}"
197 |             for req_idx in range(requests_per_ip):
    |                 ^^^^^^^
198 |                 task = self.make_request(endpoint, client_ip=client_ip)
199 |                 tasks.append(task)
    |
help: Rename unused `req_idx` to `_req_idx`

B007 Loop control variable `endpoint` not used within loop body
   --> scripts/test_rate_limiting.py:340:17
    |
338 |         if args.test in ["endpoints", "all"]:
339 |             results = await tester.test_endpoint_specific_limits()
340 |             for endpoint, result in results.items():
    |                 ^^^^^^^^
341 |                 print_results(result)
    |
help: Rename unused `endpoint` to `_endpoint`

PERF102 When using only the values of a dict use the `values()` method
   --> scripts/test_rate_limiting.py:340:37
    |
338 |         if args.test in ["endpoints", "all"]:
339 |             results = await tester.test_endpoint_specific_limits()
340 |             for endpoint, result in results.items():
    |                                     ^^^^^^^^^^^^^
341 |                 print_results(result)
    |
help: Replace `.items()` with `.values()`

S603 `subprocess` call: check for execution of untrusted input
  --> scripts/test_runner.py:21:18
   |
20 |     try:
21 |         result = subprocess.run(cmd, cwd=Path(__file__).parent.parent)
   |                  ^^^^^^^^^^^^^^
22 |         return result.returncode
23 |     except KeyboardInterrupt:
   |

S602 `subprocess` call with `shell=True` identified, security issue
  --> scripts/test_security.py:17:18
   |
15 |     """Run a command and return the result with timeout"""
16 |     try:
17 |         result = subprocess.run(
   |                  ^^^^^^^^^^^^^^
18 |             cmd, shell=True, capture_output=True, text=True, cwd=cwd, timeout=timeout
19 |         )
   |

F841 Local variable `files_to_check` is assigned to but never used
  --> scripts/test_security.py:91:5
   |
90 |     # Check common files
91 |     files_to_check = [
   |     ^^^^^^^^^^^^^^
92 |         "config.py",
93 |         "backend/api/main.py",
   |
help: Remove assignment to unused variable `files_to_check`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> scripts/test_security.py:128:9
    |
126 |               results.append((name, result))
127 |               print(f"{'✅' if result else '❌'} {name}: {'PASS' if result else 'FAIL'}")
128 | /         except Exception as e:
129 | |             print(f"❌ {name}: ERROR - {e}")
130 | |             results.append((name, False))
    | |_________________________________________^
131 |
132 |       print("\n📊 Security Test Summary:")
    |

C901 `run_test_category` is too complex (28 > 10)
  --> scripts/test_suite_health_checker.py:73:9
   |
71 |         }
72 |
73 |     def run_test_category(
   |         ^^^^^^^^^^^^^^^^^
74 |         self, category: str, test_patterns: list[str], timeout: int = 120
75 |     ) -> TestCategoryResult:
   |

S603 `subprocess` call: check for execution of untrusted input
   --> scripts/test_suite_health_checker.py:102:22
    |
101 |         try:
102 |             result = subprocess.run(
    |                      ^^^^^^^^^^^^^^
103 |                 cmd,
104 |                 cwd=self.project_root,
    |

SIM105 Use `contextlib.suppress(ValueError)` instead of `try`-`except`-`pass`
   --> scripts/test_suite_health_checker.py:127:29
    |
125 |                       for i, part in enumerate(parts):
126 |                           if part == "passed" and i > 0:
127 | /                             try:
128 | |                                 passed_tests = int(parts[i - 1])
129 | |                             except ValueError:
130 | |                                 pass
    | |____________________________________^
131 |                           elif part == "failed" and i > 0:
132 |                               try:
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(ValueError): ...`

SIM105 Use `contextlib.suppress(ValueError)` instead of `try`-`except`-`pass`
   --> scripts/test_suite_health_checker.py:132:29
    |
130 |                                   pass
131 |                           elif part == "failed" and i > 0:
132 | /                             try:
133 | |                                 failed_tests = int(parts[i - 1])
134 | |                             except ValueError:
135 | |                                 pass
    | |____________________________________^
136 |                           elif part == "skipped" and i > 0:
137 |                               try:
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(ValueError): ...`

SIM105 Use `contextlib.suppress(ValueError)` instead of `try`-`except`-`pass`
   --> scripts/test_suite_health_checker.py:137:29
    |
135 |                                   pass
136 |                           elif part == "skipped" and i > 0:
137 | /                             try:
138 | |                                 skipped_tests = int(parts[i - 1])
139 | |                             except ValueError:
140 | |                                 pass
    | |____________________________________^
141 |                   elif "passed" in line and "failed" not in line:
142 |                       # Parse line like "10 passed in 2.34s"
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(ValueError): ...`

SIM105 Use `contextlib.suppress(ValueError)` instead of `try`-`except`-`pass`
   --> scripts/test_suite_health_checker.py:146:29
    |
144 |                       for i, part in enumerate(parts):
145 |                           if part == "passed" and i > 0:
146 | /                             try:
147 | |                                 passed_tests = int(parts[i - 1])
148 | |                             except ValueError:
149 | |                                 pass
    | |____________________________________^
150 |                   elif "skipped" in line and "passed" not in line:
151 |                       # Parse line like "5 skipped"
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(ValueError): ...`

SIM105 Use `contextlib.suppress(ValueError)` instead of `try`-`except`-`pass`
   --> scripts/test_suite_health_checker.py:155:29
    |
153 |                       for i, part in enumerate(parts):
154 |                           if part == "skipped" and i > 0:
155 | /                             try:
156 | |                                 skipped_tests = int(parts[i - 1])
157 | |                             except ValueError:
158 | |                                 pass
    | |____________________________________^
159 |
160 |               total_tests = passed_tests + failed_tests + skipped_tests
    |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(ValueError): ...`

C901 `generate_recommendations` is too complex (12 > 10)
   --> scripts/test_suite_health_checker.py:247:9
    |
245 |         return weighted_score / total_weight if total_weight > 0 else 0.0
246 |
247 |     def generate_recommendations(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^
248 |         self, categories: list[TestCategoryResult], health_score: float
249 |     ) -> list[str]:
    |

PERF401 Use `list.extend` to create a transformed list
   --> scripts/test_suite_health_checker.py:282:17
    |
280 |               )
281 |               for cat in critical_categories:
282 | /                 recommendations.append(
283 | |                     f"   • {cat.category}: {cat.pass_rate:.1f}% pass rate"
284 | |                 )
    | |_________________^
285 |
286 |           if poor_categories:
    |
help: Replace for loop with list.extend

PERF401 Use `list.extend` to create a transformed list
   --> scripts/test_suite_health_checker.py:289:17
    |
287 |               recommendations.append("⚠️  HIGH PRIORITY: Improve these test categories:")
288 |               for cat in poor_categories:
289 | /                 recommendations.append(
290 | |                     f"   • {cat.category}: {cat.pass_rate:.1f}% pass rate"
291 | |                 )
    | |_________________^
292 |
293 |           # Specific improvement suggestions
    |
help: Replace for loop with list.extend

SIM102 Use a single `if` statement instead of nested `if` statements
  --> scripts/verify_s106_fix.py:34:21
   |
32 |                       var_name = target.id.lower()
33 |                       # Check if variable name contains password-related keywords
34 | /                     if any(
35 | |                         pwd in var_name
36 | |                         for pwd in ["password", "passwd", "pwd", "secret"]
37 | |                     ):
38 | |                         # Check if the value is a hardcoded string literal
39 | |                         if isinstance(node.value, ast.Constant) and isinstance(
40 | |                             node.value.value, str
41 | |                         ):
   | |__________________________^
42 |                               # Exclude empty strings and environment variable references
43 |                               value = node.value.value
   |
help: Combine `if` statements using `and`

C901 `main` is too complex (12 > 10)
  --> scripts/verify_s106_fix.py:64:5
   |
64 | def main():
   |     ^^^^
65 |     """Main function to check for S106 violations."""
66 |     print("🔍 Checking for S106 (hardcoded password) violations...\n")
   |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/connection.py:253:13
    |
251 |               try:
252 |                   callback(conn_info.connection_id or "unknown", reason)
253 | /             except Exception as e:
254 | |                 logger.error(f"Leak callback error: {e}")
    | |_________________________________________________________^
255 |
256 |       def log_connection_lifecycle(self, event: str, conn_info: ConnectionInfo) -> None:
    |

PERF401 Use a list comprehension to create a transformed list
   --> src/database/connection.py:764:17
    |
762 |               active_details = []
763 |               for conn_info in self._active_connections.values():
764 | /                 active_details.append(
765 | |                     {
766 | |                         "connection_id": conn_info.connection_id,
767 | |                         "thread_id": conn_info.thread_id,
768 | |                         "age": time.time() - conn_info.created_at,
769 | |                         "idle_time": time.time() - conn_info.last_activity,
770 | |                         "transaction_level": conn_info.transaction_level,
771 | |                         "access_count": conn_info.access_count,
772 | |                         "potentially_leaked": conn_info.is_potentially_leaked(),
773 | |                     }
774 | |                 )
    | |_________________^
775 |
776 |               return {
    |
help: Replace for loop with list comprehension

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/connection.py:809:17
    |
807 |                       )
808 |                       time.sleep(sleep_time)
809 | /                 except Exception as e:
810 | |                     logger.error(f"Error in cleanup worker: {e}")
811 | |                     time.sleep(30)  # Shorter retry interval
    | |__________________________________^
812 |
813 |           self._cleanup_timer = threading.Thread(target=cleanup_worker, daemon=True)
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/database/connection.py:829:29
    |
827 |                           for conn_info in list(self._active_connections.values()):
828 |                               # Only check connections that are actually in use
829 | /                             if conn_info.in_use and conn_info.is_potentially_leaked():
830 | |                                 # Avoid alerting if we're already handling this connection
831 | |                                 if not hasattr(conn_info, "_being_handled"):
    | |____________________________________________________________________________^
832 |                                       self._log_to_leak_detector(
833 |                                           "", conn_info, "periodic_check"
    |
help: Combine `if` statements using `and`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/connection.py:837:17
    |
836 |                       time.sleep(self.LEAK_DETECTION_INTERVAL)
837 | /                 except Exception as e:
838 | |                     logger.error(f"Error in leak detector: {e}")
839 | |                     time.sleep(30)
    | |__________________________________^
840 |
841 |           self._leak_detector_timer = threading.Thread(
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/connection.py:855:17
    |
853 |                       self._memory_monitor.log_memory_usage()
854 |                       time.sleep(self._memory_monitor.check_interval)
855 | /                 except Exception as e:
856 | |                     logger.error(f"Error in memory monitor: {e}")
857 | |                     time.sleep(60)
    | |__________________________________^
858 |
859 |           self._memory_monitor_timer = threading.Thread(
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/connection.py:893:17
    |
891 |                       conn_info = self._pool.get_nowait()
892 |                       self._close_connection(conn_info)
893 | /                 except Empty:
894 | |                     break
    | |_________________________^
895 |
896 |               self._connection_count = 0
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
    --> src/database/connection.py:1107:13
     |
1105 |                       )
1106 |                       current_thread._cleanup_callbacks.append(cleanup)
1107 | /             except Exception:
1108 | |                 pass  # Fallback to weakref only
     | |____________________^
1109 |
1110 |           # Verify connection is still valid and mark activity
     |

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/database/connection.py:1335:13
     |
1333 |                   return cursor
1334 |
1335 | /             except sqlite3.OperationalError as e:
1336 | |                 if self._handle_operational_error(e, attempt, max_retries):
1337 | |                     continue  # Retry
     | |____________________________^
1338 |                   # If not retrying, exception was already raised in handler
     |

N807 Function name should not start and end with `__`
  --> src/database/migrations.py:64:9
   |
62 |     CURRENT_VERSION = 7
63 |
64 |     def __init__(self, db_connection: DatabaseConnection) -> None:
   |         ^^^^^^^^
65 |         """
66 |         Initialize database migrator.
   |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/migrations.py:268:13
    |
266 |               try:
267 |                   self.db.execute(tag_insert_sql, (tag_name, tag_color))
268 | /             except Exception as e:
269 | |                 # Ignore duplicate tag errors
270 | |                 logger.debug(f"Could not insert default tag {tag_name}: {e}")
    | |_____________________________________________________________________________^
271 |           logger.info("Inserted default tags")
272 |           logger.info("Initial schema migration completed")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/migrations.py:504:13
    |
502 |                       f"Created index {i}/{len(all_indexes)}: {index_sql[:50]}..."
503 |                   )
504 | /             except Exception as e:
505 | |                 logger.warning(f"Index creation warning for index {i}: {e}")
    | |____________________________________________________________________________^
506 |                   # Continue with other indexes even if one fails
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/migrations.py:594:13
    |
592 |                       f"Created advanced index {i}/{len(all_advanced_indexes)}: {index_sql[:60]}..."
593 |                   )
594 | /             except Exception as e:
595 | |                 logger.warning(f"Advanced index creation warning for index {i}: {e}")
    | |_____________________________________________________________________________________^
596 |                   # Continue with other indexes even if one fails
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/migrations.py:624:17
    |
622 |                       self.db.execute(setting)
623 |                       logger.debug(f"Applied performance setting: {setting}")
624 | /                 except Exception as e:
625 | |                     logger.warning(f"Could not apply setting {setting}: {e}")
    | |_____________________________________________________________________________^
626 |
627 |               logger.info("Database performance settings optimized")
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/migrations.py:696:13
    |
694 |               try:
695 |                   self.db.execute(index_sql)
696 | /             except Exception as e:
697 | |                 logger.warning(f"Could not create monitoring index: {e}")
    | |_________________________________________________________________________^
698 |
699 |           logger.debug("Performance monitoring tables created successfully")
    |

C901 `_initialize_performance_baselines` is too complex (13 > 10)
   --> src/database/migrations.py:701:9
    |
699 |         logger.debug("Performance monitoring tables created successfully")
700 |
701 |     def _initialize_performance_baselines(self) -> None:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
702 |         """
703 |         Initialize performance baselines for future comparison.
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/database/migrations.py:722:25
    |
720 |                 try:
721 |                     count_result = self.db.fetch_one(
722 |                         f"SELECT COUNT(*) as count FROM {table}"
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
723 |                     )
724 |                     count = count_result["count"] if count_result else 0
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/migrations.py:733:17
    |
731 |                           )
732 |                       )
733 | /                 except Exception as e:
734 | |                     logger.warning(f"Could not get row count for table {table}: {e}")
    | |_____________________________________________________________________________________^
735 |
736 |               # Index counts and sizes
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/migrations.py:795:17
    |
793 |                           )
794 |                       )
795 | /                 except Exception as e:
796 | |                     logger.warning(
797 | |                         f"Could not measure baseline for query {query_name}: {e}"
798 | |                     )
    | |_____________________^
799 |
800 |               # Insert all baselines
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/database/migrations.py:809:21
    |
807 |                       try:
808 |                           self.db.execute(baseline_insert_sql, baseline)
809 | /                     except Exception as e:
810 | |                         logger.warning(f"Could not insert baseline {baseline[0]}: {e}")
    | |_______________________________________________________________________________________^
811 |
812 |                   logger.info(f"Initialized {len(baselines)} performance baselines")
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/database/migrations.py:850:21
    |
848 |                 # Get row count
849 |                 count_result = self.db.fetch_one(
850 |                     f"SELECT COUNT(*) as count FROM {table_name}"
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
851 |                 )
852 |                 row_count = count_result["count"] if count_result else 0
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/database/migrations.py:926:25
    |
924 |                     # Row count
925 |                     count_result = self.db.fetch_one(
926 |                         f"SELECT COUNT(*) as count FROM {table_name}"
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
927 |                     )
928 |                     row_count = count_result["count"] if count_result else 0
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/database/migrations.py:932:25
    |
930 |                     # Table size estimation
931 |                     dbstat_result = self.db.fetch_one(
932 |                         f"SELECT SUM(pgsize) as size FROM dbstat WHERE name = '{table_name}'"
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
933 |                     )
934 |                     table_size = (
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/database/migrations.py:979:29
    |
977 |                     try:
978 |                         size_result = self.db.fetch_one(
979 |                             f"SELECT COUNT(*) as pages, SUM(pgsize) as size FROM dbstat WHERE name = '{index_name}'"
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
980 |                         )
981 |                         pages = size_result["pages"] if size_result else 0
    |

B007 Loop control variable `ref_table` not used within loop body
    --> src/database/migrations.py:1028:32
     |
1026 |             ]
1027 |
1028 |             for table, column, ref_table in tables_with_fks:
     |                                ^^^^^^^^^
1029 |                 try:
1030 |                     # Check if index exists for this foreign key
     |
help: Rename unused `ref_table` to `_ref_table`

S608 Possible SQL injection vector through string-based query construction
    --> src/database/migrations.py:1032:25
     |
1030 |                     # Check if index exists for this foreign key
1031 |                     index_check = self.db.fetch_all(
1032 |                         f"SELECT name FROM sqlite_master WHERE type='index' AND tbl_name='{table}' AND sql LIKE '%{column}%'"
     |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1033 |                     )
     |

S110 `try`-`except`-`pass` detected, consider logging the exception
    --> src/database/migrations.py:1040:17
     |
1038 |                           )
1039 |
1040 | /                 except Exception:
1041 | |                     pass
     | |________________________^
1042 |
1043 |               # Analyze table sizes for potential partitioning
     |

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/database/migrations.py:1040:17
     |
1038 |                           )
1039 |
1040 | /                 except Exception:
1041 | |                     pass
     | |________________________^
1042 |
1043 |               # Analyze table sizes for potential partitioning
     |

S608 Possible SQL injection vector through string-based query construction
    --> src/database/migrations.py:1052:25
     |
1050 |                     table_name = table_row["name"]
1051 |                     count_result = self.db.fetch_one(
1052 |                         f"SELECT COUNT(*) as count FROM {table_name}"
     |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1053 |                     )
1054 |                     row_count = count_result["count"] if count_result else 0
     |

S110 `try`-`except`-`pass` detected, consider logging the exception
    --> src/database/migrations.py:1061:13
     |
1059 |                           )
1060 |
1061 | /             except Exception:
1062 | |                 pass
     | |____________________^
1063 |
1064 |               # Check for potential full table scans
     |

SIM102 Use a single `if` statement instead of nested `if` statements
    --> src/database/migrations.py:1465:9
     |
1464 |           # LIKE pattern optimization
1465 | /         if "like" in query_lower and "%" in query:
1466 | |             if query.count("%") >= 2:  # Leading and trailing wildcards
     | |_____________________________________^
1467 |                   recommendations.append(
1468 |                       "LIKE with leading wildcards can't use indexes efficiently. Consider FTS if full-text search is needed."
     |
help: Combine `if` statements using `and`

C901 `_analyze_query_cost` is too complex (11 > 10)
    --> src/database/migrations.py:1495:9
     |
1493 |         return recommendations
1494 |
1495 |     def _analyze_query_cost(
     |         ^^^^^^^^^^^^^^^^^^^
1496 |         self, query: str, execution_plan: list, rows_returned: int
1497 |     ) -> dict[str, Any]:
     |

C901 `analyze_index_effectiveness` is too complex (17 > 10)
    --> src/database/migrations.py:1637:9
     |
1635 |         return benchmark_results
1636 |
1637 |     def analyze_index_effectiveness(self) -> dict[str, Any]:
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^
1638 |         """
1639 |         Analyze the effectiveness of all indexes in the database.
     |

S608 Possible SQL injection vector through string-based query construction
    --> src/database/migrations.py:1678:29
     |
1676 |                     try:
1677 |                         size_result = self.db.fetch_one(
1678 |                             f"SELECT COUNT(*) as pages, SUM(pgsize) as size FROM dbstat WHERE name = '{index_name}'"
     |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
1679 |                         )
1680 |                         if size_result and size_result["size"]:
     |

S110 `try`-`except`-`pass` detected, consider logging the exception
    --> src/database/migrations.py:1682:21
     |
1680 |                           if size_result and size_result["size"]:
1681 |                               index_analysis["size_estimate"] = size_result["size"]
1682 | /                     except Exception:
1683 | |                         pass
     | |____________________________^
1684 |
1685 |                       # Estimate selectivity by checking if index is on unique or near-unique columns
     |

S110 `try`-`except`-`pass` detected, consider logging the exception
    --> src/database/migrations.py:1699:21
     |
1697 |                               )
1698 |                               index_analysis["effectiveness"] = "medium"
1699 | /                     except Exception:
1700 | |                         pass
     | |____________________________^
1701 |
1702 |                       # Analyze index usage patterns based on name
     |

PERF203 `try`-`except` within a loop incurs performance overhead
    --> src/database/migrations.py:1899:13
     |
1897 |               try:
1898 |                   self.db.execute(index_sql)
1899 | /             except Exception as e:
1900 | |                 logger.warning(f"Could not create auth index: {e}")
     | |___________________________________________________________________^
1901 |
1902 |           logger.info("Created authentication indexes")
     |

S608 Possible SQL injection vector through string-based query construction
   --> src/database/modular_migrator.py:168:25
    |
166 |                     # Get row count
167 |                     count_result = self.db.fetch_one(
168 |                         f"SELECT COUNT(*) as count FROM {table_name}"
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
169 |                     )
170 |                     row_count = count_result["count"] if count_result else 0
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/database/modular_migrator.py:284:25
    |
282 |                     # Row count
283 |                     count_result = self.db.fetch_one(
284 |                         f"SELECT COUNT(*) as count FROM {table_name}"
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
285 |                     )
286 |                     row_count = count_result["count"] if count_result else 0
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/base_repository.py:99:21
    |
 97 |             if not self._is_valid_table_name(table_name):
 98 |                 raise ValueError(f"Invalid table name: {table_name}")
 99 |             query = f"SELECT * FROM {table_name} WHERE id = ?"
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
100 |             row = self.db.fetch_one(query, (id,))
101 |             if row:
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/base_repository.py:124:25
    |
122 |             if limit is not None:
123 |                 # Use parameterized query for pagination
124 |                 query = f"SELECT * FROM {table_name} ORDER BY id LIMIT ? OFFSET ?"
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
125 |                 rows = self.db.fetch_all(query, (limit, offset))
126 |             else:
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/base_repository.py:127:25
    |
125 |                 rows = self.db.fetch_all(query, (limit, offset))
126 |             else:
127 |                 query = f"SELECT * FROM {table_name} ORDER BY id"
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
128 |                 rows = self.db.fetch_all(query)
129 |             return [self.to_model(dict(row)) for row in rows]
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/base_repository.py:144:21
    |
142 |             if not self._is_valid_table_name(table_name):
143 |                 raise ValueError(f"Invalid table name: {table_name}")
144 |             query = f"SELECT COUNT(*) as count FROM {table_name}"
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
145 |             result = self.db.fetch_one(query)
146 |             return result["count"] if result else 0
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/base_repository.py:174:25
    |
172 |             # Try using INSERT ... RETURNING first (SQLite 3.35+)
173 |             try:
174 |                 query = f"INSERT INTO {table_name} ({cols}) VALUES ({placeholders}) RETURNING id"
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
175 |                 cursor = self.db.execute(query, tuple(values))
176 |                 result = cursor.fetchone()
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/base_repository.py:184:25
    |
182 |             except Exception:
183 |                 # Fallback to traditional INSERT + last_insert_rowid()
184 |                 query = f"INSERT INTO {table_name} ({cols}) VALUES ({placeholders})"
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
185 |                 self.db.execute(query, tuple(values))
186 |                 new_id = self.db.get_last_insert_id()
    |

B904 Within an `except` clause, raise exceptions with `raise ... from err` or `raise ... from None` to distinguish them from errors in exception handling
   --> src/repositories/base_repository.py:188:21
    |
186 |                 new_id = self.db.get_last_insert_id()
187 |                 if new_id is None or new_id <= 0:
188 |                     raise RuntimeError(f"Failed to get insert ID for {table_name}")
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
189 |
190 |             # Retrieve the created model
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/base_repository.py:222:21
    |
220 |             if not self._is_valid_table_name(table_name):
221 |                 raise ValueError(f"Invalid table name: {table_name}")
222 |             query = f"UPDATE {table_name} SET {set_clause} WHERE id = ?"
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
223 |             result = self.db.execute(query, tuple(values))
224 |             if result.rowcount == 0:
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/base_repository.py:250:21
    |
248 |             if not self._is_valid_table_name(table_name):
249 |                 raise ValueError(f"Invalid table name: {table_name}")
250 |             query = f"DELETE FROM {table_name} WHERE id = ?"
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
251 |             result = self.db.execute(query, (id,))
252 |             return result.rowcount > 0
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/base_repository.py:269:21
    |
267 |             if not self._is_valid_table_name(table_name):
268 |                 raise ValueError(f"Invalid table name: {table_name}")
269 |             query = f"SELECT 1 FROM {table_name} WHERE id = ? LIMIT 1"
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
270 |             result = self.db.fetch_one(query, (id,))
271 |             return result is not None
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/base_repository.py:294:21
    |
292 |             if not re.match(r"^[a-zA-Z_][a-zA-Z0-9_]*$", field):
293 |                 raise ValueError(f"Invalid field name: {field}")
294 |             query = f"SELECT * FROM {table_name} WHERE {field} = ?"
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
295 |             rows = self.db.fetch_all(query, (value,))
296 |             return [self.to_model(dict(row)) for row in rows]
    |

S608 Possible SQL injection vector through string-based query construction
  --> src/repositories/citation_relation_repository.py:91:19
   |
89 |               values = [relation_dict[col] for col in columns]
90 |
91 |               sql = f"""
   |  ___________________^
92 | |                 INSERT INTO citation_relations ({", ".join(columns)})
93 | |                 VALUES ({", ".join(placeholders)})
94 | |             """
   | |_______________^
95 |
96 |               self.db.execute(sql, values)
   |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/citation_relation_repository.py:158:19
    |
156 |               values = list(relation_dict.values()) + [relation.id]
157 |
158 |               sql = f"""
    |  ___________________^
159 | |                 UPDATE citation_relations
160 | |                 SET {", ".join(set_clauses)}
161 | |                 WHERE id = ?
162 | |             """
    | |_______________^
163 |
164 |               self.db.execute(sql, values)
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/citation_relation_repository.py:223:19
    |
221 |               # Create placeholders for IN clause
222 |               placeholders = ",".join(["?" for _ in relation_ids])
223 |               sql = f"""
    |  ___________________^
224 | |                 SELECT * FROM citation_relations
225 | |                 WHERE id IN ({placeholders})
226 | |                 ORDER BY id
227 | |             """
    | |_______________^
228 |               results = self.db.fetch_all(sql, tuple(relation_ids))
    |

C901 `get_citation_network` is too complex (11 > 10)
   --> src/repositories/citation_relation_repository.py:348:9
    |
346 |             raise
347 |
348 |     def get_citation_network(self, document_id: int, depth: int = 1) -> dict[str, Any]:
    |         ^^^^^^^^^^^^^^^^^^^^
349 |         """
350 |         Get citation network for a document up to specified depth.
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/citation_relation_repository.py:426:28
    |
424 |               if nodes:
425 |                   placeholders = ",".join(["?" for _ in nodes])
426 |                   node_sql = f"""
    |  ____________________________^
427 | |                     SELECT id, title, created_at
428 | |                     FROM documents
429 | |                     WHERE id IN ({placeholders})
430 | |                 """
    | |___________________^
431 |                   node_results = self.db.fetch_all(node_sql, list(nodes))
    |

S608 Possible SQL injection vector through string-based query construction
  --> src/repositories/citation_repository.py:80:19
   |
78 |               values = [citation_dict[col] for col in columns]
79 |
80 |               sql = f"""
   |  ___________________^
81 | |                 INSERT INTO citations ({", ".join(columns)})
82 | |                 VALUES ({", ".join(placeholders)})
83 | |             """
   | |_______________^
84 |
85 |               self.db.execute(sql, values)
   |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/citation_repository.py:147:19
    |
145 |               values = list(citation_dict.values()) + [citation.id]
146 |
147 |               sql = f"""
    |  ___________________^
148 | |                 UPDATE citations
149 | |                 SET {", ".join(set_clauses)}
150 | |                 WHERE id = ?
151 | |             """
    | |_______________^
152 |
153 |               self.db.execute(sql, values)
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/citation_repository.py:381:19
    |
379 |               # Create placeholders for IN clause
380 |               placeholders = ",".join(["?" for _ in citation_ids])
381 |               sql = f"""
    |  ___________________^
382 | |                 SELECT * FROM citations
383 | |                 WHERE id IN ({placeholders})
384 | |                 ORDER BY id
385 | |             """
    | |_______________^
386 |               results = self.db.fetch_all(sql, tuple(citation_ids))
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/multi_document_repositories.py:117:21
    |
115 |                   placeholders = ",".join("?" * len(entity_ids))
116 |                   cursor.execute(
117 | /                     f"""
118 | |                     SELECT id, name, description, document_ids, document_count, created_at, updated_at
119 | |                     FROM multi_document_collections WHERE id IN ({placeholders})
120 | |                 """,
    | |___________________^
121 |                       entity_ids,
122 |                   )
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/multi_document_repositories.py:388:21
    |
386 |                   placeholders = ",".join("?" * len(entity_ids))
387 |                   cursor.execute(
388 | /                     f"""
389 | |                     SELECT id, collection_id, index_path, index_hash, embedding_model,
390 | |                            chunk_count, created_at, metadata
391 | |                     FROM multi_document_indexes WHERE id IN ({placeholders})
392 | |                 """,
    | |___________________^
393 |                       entity_ids,
394 |                   )
    |

S608 Possible SQL injection vector through string-based query construction
   --> src/repositories/multi_document_repositories.py:648:21
    |
646 |                   placeholders = ",".join("?" * len(entity_ids))
647 |                   cursor.execute(
648 | /                     f"""
649 | |                     SELECT id, collection_id, query_text, user_id, response_text, confidence_score,
650 | |                            sources, cross_references, status, error_message, processing_time_ms,
651 | |                            tokens_used, created_at, completed_at
652 | |                     FROM cross_document_queries WHERE id IN ({placeholders})
653 | |                 """,
    | |___________________^
654 |                       entity_ids,
655 |                   )
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/repositories/vector_repository.py:236:17
    |
234 |                           shutil.rmtree(index.index_path, ignore_errors=True)
235 |                           logger.debug(f"Removed index files: {index.index_path}")
236 | /                 except Exception as e:
237 | |                     logger.warning(
238 | |                         f"Failed to cleanup individual index {index.id}: {e}"
239 | |                     )
240 | |                     continue
    | |____________________________^
241 |               logger.info(f"Cleaned up {cleaned_count} invalid vector indexes")
242 |               return cleaned_count
    |

C901 `extract_authors` is too complex (11 > 10)
   --> src/services/citation_parsing_service.py:236:9
    |
234 |             return None
235 |
236 |     def extract_authors(self, citation_text: str) -> str | None:
    |         ^^^^^^^^^^^^^^^
237 |         """
238 |         Extract authors from citation text with enhanced accuracy.
    |

C901 `calculate_confidence_score` is too complex (12 > 10)
   --> src/services/citation_parsing_service.py:532:9
    |
530 |             return "unknown"
531 |
532 |     def calculate_confidence_score(self, citation_data: dict[str, Any]) -> float:
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^
533 |         """
534 |         Calculate confidence score for parsed citation.
    |

C901 `detect_citation_clusters` is too complex (12 > 10)
   --> src/services/citation_service.py:694:9
    |
692 |             return []
693 |
694 |     def detect_citation_clusters(
    |         ^^^^^^^^^^^^^^^^^^^^^^^^
695 |         self, min_cluster_size: int = 3
696 |     ) -> list[dict[str, Any]]:
    |

C901 `_analyze_index_corruption` is too complex (11 > 10)
    --> src/services/enhanced_rag_service.py:1033:9
     |
1031 |         return recovery_result
1032 |
1033 |     def _analyze_index_corruption(self, index: VectorIndexModel) -> dict[str, Any]:
     |         ^^^^^^^^^^^^^^^^^^^^^^^^^
1034 |         """Analyze index for various types of corruption."""
1035 |         analysis_result = {
     |

N818 Exception name `RetryExhaustedException` should be named with an Error suffix
  --> src/services/error_recovery.py:35:7
   |
35 | class RetryExhaustedException(RecoveryError):
   |       ^^^^^^^^^^^^^^^^^^^^^^^
36 |     """Raised when retry attempts are exhausted."""
   |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/services/error_recovery.py:133:13
    |
131 |                   return result
132 |
133 | /             except self.config.non_retryable_exceptions:
134 | |                 # Don't retry these exceptions
135 | |                 raise
    | |_____________________^
136 |
137 |               except Exception as e:
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/services/error_recovery.py:326:17
    |
324 |                       self._cleanup_path(path)
325 |                       self.metrics.cleanup_operations += 1
326 | /                 except Exception as e:
327 | |                     logger.error(f"Failed to cleanup path {path}: {e}")
328 | |                     self.metrics.failed_recoveries += 1
    | |_______________________________________________________^
329 |
330 |               # Execute cleanup handlers
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/services/error_recovery.py:335:17
    |
333 |                       handler()
334 |                       self.metrics.cleanup_operations += 1
335 | /                 except Exception as e:
336 | |                     logger.error(f"Cleanup handler failed: {e}")
337 | |                     self.metrics.failed_recoveries += 1
    | |_______________________________________________________^
338 |
339 |               # Clear all handlers
    |

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/services/error_recovery.py:406:13
    |
404 |                   if result:
405 |                       self.metrics.successful_recoveries += 1
406 | /             except Exception as e:
407 | |                 logger.error(f"Health check '{name}' failed: {e}")
408 | |                 results[name] = False
409 | |                 self.metrics.failed_recoveries += 1
410 | |                 error_type = type(e).__name__
411 | |                 self.metrics.error_types[error_type] = (
412 | |                     self.metrics.error_types.get(error_type, 0) + 1
413 | |                 )
    | |_________________^
414 |
415 |           return results
    |

SIM108 Use ternary operator `retry_mechanism = RetryMechanism(retry_config) if retry_config else self.retry` instead of `if`-`else`-block
   --> src/services/error_recovery.py:444:9
    |
443 |           # Setup custom configurations if provided
444 | /         if retry_config:
445 | |             retry_mechanism = RetryMechanism(retry_config)
446 | |         else:
447 | |             retry_mechanism = self.retry
    | |________________________________________^
448 |
449 |           if circuit_breaker_config:
    |
help: Replace `if`-`else`-block with `retry_mechanism = RetryMechanism(retry_config) if retry_config else self.retry`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/services/rag/chunking_strategies.py:184:13
    |
182 |                   if chunks:
183 |                       return chunks
184 | /             except Exception as exc:
185 | |                 logger.warning(
186 | |                     "Chunker %s failed, falling back to next strategy: %s",
187 | |                     strategy.__class__.__name__,
188 | |                     exc,
189 | |                 )
190 | |                 continue
    | |________________________^
191 |
192 |           # Fallback to simple splitting
    |

B007 Loop control variable `para_idx` not used within loop body
   --> src/services/rag/chunking_strategies.py:223:13
    |
221 |         current_size = 0
222 |
223 |         for para_idx, paragraph in enumerate(paragraphs):
    |             ^^^^^^^^
224 |             para_complexity = self._calculate_complexity(paragraph)
225 |             adaptive_size = self._get_adaptive_chunk_size(para_complexity)
    |
help: Rename unused `para_idx` to `_para_idx`

PERF401 Use `list.extend` to create a transformed list
   --> src/services/rag/chunking_strategies.py:401:17
    |
399 |             for match in re.finditer(pattern, text):
400 |                 # Add position after citation for potential break point
401 |                 positions.append(match.end())
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
402 |
403 |         return positions
    |
help: Replace for loop with list.extend

PERF401 Use a list comprehension to create a transformed list
   --> src/services/rag/chunking_strategies.py:411:13
    |
409 |         # Find paragraph boundaries
410 |         for match in re.finditer(r"\n\n+", text):
411 |             positions.append(match.end())
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
412 |
413 |         # Find potential headers (lines with few words, capitalized)
    |
help: Replace for loop with list comprehension

PERF401 Use `list.extend` to create a transformed list
   --> src/services/rag/chunking_strategies.py:415:13
    |
413 |         # Find potential headers (lines with few words, capitalized)
414 |         for match in re.finditer(r"\n([A-Z][A-Za-z\s]{5,50})\n", text):
415 |             positions.append(match.start())
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
416 |
417 |         return positions
    |
help: Replace for loop with list.extend

N818 Exception name `RAGBaseException` should be named with an Error suffix
  --> src/services/rag/exceptions.py:11:7
   |
11 | class RAGBaseException(Exception):
   |       ^^^^^^^^^^^^^^^^
12 |     """Base exception for all RAG-related errors."""
   |

C401 Unnecessary generator (rewrite as a set comprehension)
   --> src/services/rag/file_manager.py:271:31
    |
269 |                 return orphaned_dirs
270 |
271 |             valid_paths_set = set(Path(path) for path in valid_index_paths)
    |                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
272 |
273 |             for item in self.vector_storage_dir.iterdir():
    |
help: Rewrite as a set comprehension

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/services/rag/file_manager.py:274:17
    |
273 |               for item in self.vector_storage_dir.iterdir():
274 | /                 if item.is_dir() and item.name.startswith("doc_"):
275 | |                     if item not in valid_paths_set:
    | |___________________________________________________^
276 |                           orphaned_dirs.append(item)
277 |                           logger.debug(f"Found orphaned directory: {item}")
    |
help: Combine `if` statements using `and`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/services/rag/file_manager.py:302:13
    |
300 |                   cleaned_count += 1
301 |
302 | /             except Exception as e:
303 | |                 logger.warning(
304 | |                     f"Failed to remove orphaned directory {orphaned_dir}: {e}"
305 | |                 )
    | |_________________^
306 |
307 |           return cleaned_count
    |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/services/rag/index_builder.py:388:13
    |
387 |               # Check API availability (if not in test mode)
388 | /             if not self.test_mode:
389 | |                 if not self.api_key:
    | |____________________________________^
390 |                       validation_result["issues"].append(
391 |                           "Google API key is not configured"
    |
help: Combine `if` statements using `and`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/services/rag/large_document_processor.py:191:17
    |
189 |                       chunks = self.process_document(file_path)
190 |                       results[file_path] = chunks
191 | /                 except Exception as e:
192 | |                     logger.error(f"Failed to process {file_path}: {e}")
193 | |                     results[file_path] = []
    | |___________________________________________^
194 |
195 |               self.monitor.end_operation(op_id, success=True)
    |

B007 Loop control variable `op_type` not used within loop body
   --> src/services/rag/performance_monitor.py:222:13
    |
221 |         # Calculate averages
222 |         for op_type, stats in operation_stats.items():
    |             ^^^^^^^
223 |             stats["avg_duration"] = stats["total_duration"] / stats["count"]
224 |             stats["avg_memory_delta"] = stats["avg_memory_delta"] / stats["count"]
    |
help: Rename unused `op_type` to `_op_type`

SIM102 Use a single `if` statement instead of nested `if` statements
   --> src/services/rag/recovery_service.py:224:21
    |
223 |                       # Basic structure validation for vector store
224 | /                     if file_path.name == "default__vector_store.json":
225 | |                         if not isinstance(data, dict) or "embedding_dict" not in data:
    | |______________________________________________________________________________________^
226 |                               analysis_result["corrupted_files"].append(
227 |                                   f"{file_path.name}: Invalid structure"
    |
help: Combine `if` statements using `and`

PERF203 `try`-`except` within a loop incurs performance overhead
   --> src/services/rag/recovery_service.py:583:17
    |
581 |                           corrupted_indexes.append(corrupted_info)
582 |
583 | /                 except Exception as e:
584 | |                     logger.error(f"Failed to analyze index {vector_index.id}: {e}")
    | |___________________________________________________________________________________^
585 |
586 |           except Exception as e:
    |

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> src/services/service_factory.py:219:13
    |
218 |         # Try to resolve as a service dependency
219 |         for service_type in self._service_configs.keys():
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
220 |             if dependency_name == service_type.__name__.lower():
221 |                 return self.create_service(service_type)
    |
help: Remove `.keys()`

SIM118 Use `key in dict` instead of `key in dict.keys()`
   --> src/services/service_factory.py:248:43
    |
246 |             },
247 |             "active_singletons": [
248 |                 service_type.__name__ for service_type in self._services.keys()
    |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
249 |             ],
250 |             "factory_config": self.config,
    |
help: Remove `.keys()`

S104 Possible binding to all interfaces
  --> start_api_server.py:29:14
   |
27 |     config = uvicorn.Config(
28 |         "backend.api.main:app",
29 |         host="0.0.0.0",
   |              ^^^^^^^^^
30 |         port=8000,
31 |         reload=False,  # Disable reload for stability
   |

S104 Possible binding to all interfaces
  --> start_api_server_autorepair.py:29:14
   |
27 |     config = uvicorn.Config(
28 |         "backend.api.main:app",
29 |         host="0.0.0.0",
   |              ^^^^^^^^^
30 |         port=8000,
31 |         reload=False,  # Disable reload for stability
   |

S104 Possible binding to all interfaces
  --> start_api_server_simple.py:34:18
   |
32 |         uvicorn.run(
33 |             app,
34 |             host="0.0.0.0",
   |                  ^^^^^^^^^
35 |             port=8000,
36 |             log_level="info",
   |

S104 Possible binding to all interfaces
  --> start_bulletproof_server.py:15:14
   |
13 |     uvicorn.run(
14 |         "backend.api.main_bulletproof:app",
15 |         host="0.0.0.0",
   |              ^^^^^^^^^
16 |         port=8000,
17 |         reload=False,
   |

S607 Starting a process with a partial executable path
  --> start_frontend_dev.py:24:13
   |
22 |     try:
23 |         process = subprocess.Popen(
24 |             ["npm", "run", "dev"],
   |             ^^^^^^^^^^^^^^^^^^^^^
25 |             cwd=str(FRONTEND_DIR),
26 |             stdout=log_handle,
   |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> test_api_health.py:48:13
   |
46 |                           print(f"⚠️  {description}: Status {status}")
47 |                           results.append((description, False, f"Status {status}: {text[:100]}"))
48 | /             except Exception as e:
49 | |                 print(f"❌ {description}: {type(e).__name__}: {str(e)[:100]}")
50 | |                 results.append((description, False, str(e)))
   | |____________________________________________________________^
51 |
52 |       # Summary
   |

C901 `main` is too complex (11 > 10)
  --> test_api_health.py:66:11
   |
66 | async def main():
   |           ^^^^
67 |     """Main test function."""
68 |     # First check if server is already running
   |

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
  --> test_api_health.py:72:9
   |
71 |       try:
72 | /         async with aiohttp.ClientSession() as session:
73 | |             async with session.get("http://127.0.0.1:8000/ping", timeout=aiohttp.ClientTimeout(total=2)) as response:
   | |_____________________________________________________________________________________________________________________^
74 |                   if response.status == 200:
75 |                       print("✅ API server is already running")
   |
help: Combine `with` statements

E722 Do not use bare `except`
  --> test_api_health.py:79:5
   |
77 |                     success = await test_health_endpoints()
78 |                     return 0 if success else 1
79 |     except:
   |     ^^^^^^
80 |         print("API server is not running")
   |

S603 `subprocess` call: check for execution of untrusted input
  --> test_api_health.py:84:22
   |
82 |     # Try to start the server
83 |     print("\nStarting API server...")
84 |     server_process = subprocess.Popen(
   |                      ^^^^^^^^^^^^^^^^
85 |         [sys.executable, "start_api_server.py", "--uvicorn"],
86 |         cwd=project_root,
   |

SIM117 Use a single `with` statement with multiple contexts instead of nested `with` statements
   --> test_api_health.py:107:13
    |
105 |           # Try to connect
106 |           try:
107 | /             async with aiohttp.ClientSession() as session:
108 | |                 async with session.get("http://127.0.0.1:8000/ping", timeout=aiohttp.ClientTimeout(total=1)) as response:
    | |_________________________________________________________________________________________________________________________^
109 |                       if response.status == 200:
110 |                           print(f"✅ Server started successfully after {i+1} seconds")
    |
help: Combine `with` statements

E722 Do not use bare `except`
   --> test_api_health.py:112:9
    |
110 |                         print(f"✅ Server started successfully after {i+1} seconds")
111 |                         break
112 |         except:
    |         ^^^^^^
113 |             pass
    |

S110 `try`-`except`-`pass` detected, consider logging the exception
   --> test_api_health.py:112:9
    |
110 |                           print(f"✅ Server started successfully after {i+1} seconds")
111 |                           break
112 | /         except:
113 | |             pass
    | |________________^
114 |
115 |           if i % 5 == 0 and i > 0:
    |

S603 `subprocess` call: check for execution of untrusted input
  --> test_health_endpoint.py:20:12
   |
18 |     print("Starting API server...")
19 |     # Start the server
20 |     proc = subprocess.Popen(
   |            ^^^^^^^^^^^^^^^^
21 |         [sys.executable, 'start_api_server.py', '--uvicorn'],
22 |         stdout=subprocess.PIPE,
   |

S603 `subprocess` call: check for execution of untrusted input
  --> test_server.py:15:15
   |
13 |     # Start the server
14 |     print("Starting server using start_api_server_simple.py...")
15 |     process = subprocess.Popen(
   |               ^^^^^^^^^^^^^^^^
16 |         [sys.executable, "start_api_server_simple.py"],
17 |         stdout=subprocess.PIPE,
   |

S113 Probable use of `requests` call without timeout
  --> test_server.py:28:20
   |
26 |         # Test root endpoint
27 |         print("\nTesting root endpoint...")
28 |         response = requests.get("http://127.0.0.1:8000/")
   |                    ^^^^^^^^^^^^
29 |         print(f"Status: {response.status_code}")
30 |         print(f"Response: {response.json()}")
   |

S113 Probable use of `requests` call without timeout
  --> test_server.py:34:20
   |
32 |         # Test health endpoint
33 |         print("\nTesting basic health endpoint...")
34 |         response = requests.get("http://127.0.0.1:8000/health")
   |                    ^^^^^^^^^^^^
35 |         print(f"Status: {response.status_code}")
36 |         print(f"Response: {response.json()}")
   |

S113 Probable use of `requests` call without timeout
  --> test_server.py:40:20
   |
38 |         # Test API health endpoint
39 |         print("\nTesting API health endpoint...")
40 |         response = requests.get("http://127.0.0.1:8000/api/system/health")
   |                    ^^^^^^^^^^^^
41 |         print(f"Status: {response.status_code}")
42 |         print(f"Response: {response.json()}")
   |

S113 Probable use of `requests` call without timeout
  --> test_server.py:46:20
   |
44 |         # Test API docs
45 |         print("\nTesting API docs endpoint...")
46 |         response = requests.get("http://127.0.0.1:8000/api/docs")
   |                    ^^^^^^^^^^^^
47 |         print(f"Status: {response.status_code}")
48 |         print(f"Docs available: {response.status_code == 200}")
   |

S603 `subprocess` call: check for execution of untrusted input
  --> test_simple_server.py:23:22
   |
22 |     # Start server process
23 |     server_process = subprocess.Popen(
   |                      ^^^^^^^^^^^^^^^^
24 |         [sys.executable, "start_api_server_simple.py"],
25 |         cwd=project_root,
   |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> test_simple_server.py:60:9
   |
58 |               else:
59 |                   print(f"⚠️  {name}: Status {response.status_code}")
60 | /         except Exception as e:
61 | |             print(f"❌ {name}: {e}")
   | |____________________________________^
62 |
63 |       # Stop server
   |

SIM115 Use a context manager for opening files
  --> tests/backend/test_documents_upload_route.py:56:16
   |
54 |     content_type: str = "application/pdf",
55 | ) -> UploadFile:
56 |     file_obj = SpooledTemporaryFile()
   |                ^^^^^^^^^^^^^^^^^^^^
57 |     file_obj.write(content)
58 |     file_obj.seek(0)
   |

F841 Local variable `RateLimitMonitor` is assigned to but never used
  --> tests/backend/test_rate_limit_monitor_extended.py:90:5
   |
88 | def test_global_monitor_helpers(monkeypatch):
89 |     rlm = _load_module()
90 |     RateLimitMonitor = rlm.RateLimitMonitor
   |     ^^^^^^^^^^^^^^^^
91 |     RateLimitEvent = rlm.RateLimitEvent
92 |     get_monitor = rlm.get_monitor
   |
help: Remove assignment to unused variable `RateLimitMonitor`

F841 Local variable `RateLimitEvent` is assigned to but never used
  --> tests/backend/test_rate_limit_monitor_extended.py:91:5
   |
89 |     rlm = _load_module()
90 |     RateLimitMonitor = rlm.RateLimitMonitor
91 |     RateLimitEvent = rlm.RateLimitEvent
   |     ^^^^^^^^^^^^^^
92 |     get_monitor = rlm.get_monitor
93 |     record_rate_limit_event = rlm.record_rate_limit_event
   |
help: Remove assignment to unused variable `RateLimitEvent`

S108 Probable insecure usage of temporary file or directory: "/tmp/doc.pdf"
  --> tests/database/test_document_model.py:50:22
   |
48 |         "id": 1,
49 |         "title": "FromDB",
50 |         "file_path": "/tmp/doc.pdf",
   |                      ^^^^^^^^^^^^^^
51 |         "file_hash": "hash789",
52 |         "file_size": 10,
   |

S108 Probable insecure usage of temporary file or directory: "/tmp/index"
  --> tests/database/test_vector_index_model.py:40:23
   |
38 |         "id": 5,
39 |         "document_id": 9,
40 |         "index_path": "/tmp/index",
   |                       ^^^^^^^^^^^^
41 |         "index_hash": "hash",
42 |         "chunk_count": 42,
   |

N805 First argument of a method should be named `self`
  --> tests/services/test_document_service.py:25:26
   |
23 |             rowcount = 0
24 |
25 |             def fetchone(self_inner):
   |                          ^^^^^^^^^^
26 |                 return None
   |
help: Rename `self_inner` to `self`

S108 Probable insecure usage of temporary file or directory: "/tmp/doc.pdf"
   --> tests/services/test_document_service.py:148:27
    |
146 |                 id=doc_id,
147 |                 title="Loaded",
148 |                 file_path="/tmp/doc.pdf",
    |                           ^^^^^^^^^^^^^^
149 |                 file_hash="hash",
150 |                 file_size=1,
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/doc1.pdf"
   --> tests/services/test_document_service.py:171:31
    |
169 |                     id=1,
170 |                     title="Doc1",
171 |                     file_path="/tmp/doc1.pdf",
    |                               ^^^^^^^^^^^^^^^
172 |                     file_hash="hash1",
173 |                     file_size=1,
    |

N805 First argument of a method should be named `self`
  --> tests/services/test_enhanced_rag_service.py:25:26
   |
23 |             rowcount = 0
24 |
25 |             def fetchone(self_inner):
   |                          ^^^^^^^^^^
26 |                 return None
   |
help: Rename `self_inner` to `self`

S108 Probable insecure usage of temporary file or directory: "/tmp/index"
   --> tests/services/test_enhanced_rag_service.py:235:20
    |
233 |         id=1,
234 |         document_id=1,
235 |         index_path="/tmp/index",
    |                    ^^^^^^^^^^^^
236 |         index_hash="hash",
237 |         chunk_count=1,
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/test_idx"
   --> tests/services/test_enhanced_rag_service.py:263:21
    |
261 |     doc_repo = DummyDocumentRepo()
262 |     vector_repo = DummyVectorRepo()
263 |     idx_path = Path("/tmp/test_idx")
    |                     ^^^^^^^^^^^^^^^
264 |     idx_path.mkdir(parents=True, exist_ok=True)
265 |     vector_repo.records[1] = VectorIndexModel(
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/index"
   --> tests/services/test_enhanced_rag_service.py:300:20
    |
298 |         id=1,
299 |         document_id=1,
300 |         index_path="/tmp/index",
    |                    ^^^^^^^^^^^^
301 |         index_hash="hash",
302 |         chunk_count=1,
    |

B017 Do not assert blind exception: `Exception`
  --> tests/services/test_error_recovery.py:39:10
   |
37 |         raise ValueError("nope")
38 |
39 |     with pytest.raises(Exception):
   |          ^^^^^^^^^^^^^^^^^^^^^^^^
40 |         always_fail()
41 |     assert mechanism.metrics.failed_recoveries == 1
   |

N805 First argument of a method should be named `self`
  --> tests/services/test_integrated_cache_manager.py:19:21
   |
18 |         class _Recorder:
19 |             def inc(self_inner, value: int = 1):
   |                     ^^^^^^^^^^
20 |                 parent.calls.append(("inc", labels, value))
   |
help: Rename `self_inner` to `self`

N805 First argument of a method should be named `self`
  --> tests/services/test_integrated_cache_manager.py:22:25
   |
20 |                 parent.calls.append(("inc", labels, value))
21 |
22 |             def observe(self_inner, value: float):
   |                         ^^^^^^^^^^
23 |                 parent.calls.append(("observe", labels, value))
   |
help: Rename `self_inner` to `self`

S108 Probable insecure usage of temporary file or directory: "/tmp/index_"
   --> tests/services/test_multi_document_rag_service.py:120:18
    |
118 |     def create_index(self, documents, collection_id):
119 |         self.created += 1
120 |         path = f"/tmp/index_{collection_id}"
    |                  ^^^^^^^^^^^
121 |         Path(path).mkdir(parents=True, exist_ok=True)
122 |         self.index_exists_flag = True
    |

S108 Probable insecure usage of temporary file or directory: "/tmp/docs"
  --> tests/services/test_service_factory.py:31:72
   |
29 | def test_default_factory_singleton_and_dependencies(monkeypatch):
30 |     dummy_db = _DummyDB()
31 |     factory = DefaultServiceFactory(dummy_db, config={"documents_dir": "/tmp/docs"})
   |                                                                        ^^^^^^^^^^^
32 |
33 |     # Register a simple service with dependencies and singleton behavior
   |

S108 Probable insecure usage of temporary file or directory: "/tmp/docs"
  --> tests/services/test_service_factory.py:56:69
   |
54 | def test_test_factory_mocks_and_overrides():
55 |     dummy_db = _DummyDB()
56 |     factory = TestServiceFactory(dummy_db, config={"documents_dir": "/tmp/docs"})
   |                                                                     ^^^^^^^^^^^
57 |     factory.register_service_config(
58 |         _DummyService, dependencies=["db_connection"], singleton=True, extra="cfg"
   |

S108 Probable insecure usage of temporary file or directory: "/tmp"
  --> tests/services/test_service_factory.py:85:67
   |
83 |     )
84 |
85 |     initialize_service_factory(dummy_db, config={"documents_dir": "/tmp"})
   |                                                                   ^^^^^^
86 |     factory = get_service_factory()
87 |     assert isinstance(factory, ServiceFactory)
   |

S603 `subprocess` call: check for execution of untrusted input
  --> tests_e2e/conftest.py:32:28
   |
30 |         try:
31 |             # Start server in background
32 |             self.process = subprocess.Popen(
   |                            ^^^^^^^^^^^^^^^^
33 |                 [sys.executable, "web_main.py", "--host", "localhost", "--port", "8000"],
34 |                 stdout=subprocess.PIPE,
   |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> tests_e2e/conftest.py:49:17
   |
47 |                           print(f"✅ Web server started on {BASE_URL}")
48 |                           return True
49 | /                 except Exception:
50 | |                     time.sleep(0.5)
51 | |                     continue
   | |____________________________^
52 |
53 |               print("❌ Web server failed to start within timeout")
   |

F405 `browser_context` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:14:5
   |
12 | __all__ = [
13 |     # Browser fixtures
14 |     'browser_context',
   |     ^^^^^^^^^^^^^^^^^
15 |     'page',
16 |     'mobile_browser',
   |

F405 `page` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:15:5
   |
13 |     # Browser fixtures
14 |     'browser_context',
15 |     'page',
   |     ^^^^^^
16 |     'mobile_browser',
17 |     'multi_browser',
   |

F405 `mobile_browser` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:16:5
   |
14 |     'browser_context',
15 |     'page',
16 |     'mobile_browser',
   |     ^^^^^^^^^^^^^^^^
17 |     'multi_browser',
   |

F405 `multi_browser` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:17:5
   |
15 |     'page',
16 |     'mobile_browser',
17 |     'multi_browser',
   |     ^^^^^^^^^^^^^^^
18 |
19 |     # Data fixtures
   |

F405 `test_pdf_file` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:20:5
   |
19 |     # Data fixtures
20 |     'test_pdf_file',
   |     ^^^^^^^^^^^^^^^
21 |     'test_user',
22 |     'test_documents',
   |

F405 `test_user` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:21:5
   |
19 |     # Data fixtures
20 |     'test_pdf_file',
21 |     'test_user',
   |     ^^^^^^^^^^^
22 |     'test_documents',
   |

F405 `test_documents` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:22:5
   |
20 |     'test_pdf_file',
21 |     'test_user',
22 |     'test_documents',
   |     ^^^^^^^^^^^^^^^^
23 |
24 |     # API fixtures
   |

F405 `api_client` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:25:5
   |
24 |     # API fixtures
25 |     'api_client',
   |     ^^^^^^^^^^^^
26 |     'authenticated_api',
   |

F405 `authenticated_api` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:26:5
   |
24 |     # API fixtures
25 |     'api_client',
26 |     'authenticated_api',
   |     ^^^^^^^^^^^^^^^^^^^
27 |
28 |     # Database fixtures
   |

F405 `clean_database` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:29:5
   |
28 |     # Database fixtures
29 |     'clean_database',
   |     ^^^^^^^^^^^^^^^^
30 |     'seeded_database',
31 | ]
   |

F405 `seeded_database` may be undefined, or defined from star imports
  --> tests_e2e/fixtures/__init__.py:30:5
   |
28 |     # Database fixtures
29 |     'clean_database',
30 |     'seeded_database',
   |     ^^^^^^^^^^^^^^^^^
31 | ]
   |

SIM102 Use a single `if` statement instead of nested `if` statements
   --> tests_e2e/fixtures/api_fixtures.py:210:13
    |
208 |           while time.time() - start_time < timeout:
209 |               response = self.get(endpoint)
210 | /             if response.success and response.data:
211 | |                 if response.data.get('status') == expected_status:
    | |__________________________________________________________________^
212 |                       return True
213 |               time.sleep(poll_interval)
    |
help: Combine `if` statements using `and`

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
  --> tests_e2e/fixtures/data_fixtures.py:23:24
   |
21 |     def random_string(length: int = 10) -> str:
22 |         """Generate a random string."""
23 |         return ''.join(random.choices(string.ascii_letters + string.digits, k=length))
   |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
24 |
25 |     @staticmethod
   |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
  --> tests_e2e/fixtures/data_fixtures.py:33:21
   |
31 |     def random_phone() -> str:
32 |         """Generate a random phone number."""
33 |         return f"+1{random.randint(2000000000, 9999999999)}"
   |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
34 |
35 |     @staticmethod
   |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/data_fixtures.py:225:52
    |
224 |     for i in range(10):
225 |         doc_date = datetime.now() - timedelta(days=random.randint(0, 365))
    |                                                    ^^^^^^^^^^^^^^^^^^^^^^
226 |         documents.append({
227 |             "id": i + 1,
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/data_fixtures.py:231:25
    |
229 |             "filename": f"test_doc_{i + 1}.pdf",
230 |             "description": f"This is test document number {i + 1}",
231 |             "category": random.choice(categories),
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^
232 |             "tags": [f"tag{j}" for j in range(random.randint(1, 5))],
233 |             "status": random.choice(statuses),
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/data_fixtures.py:232:47
    |
230 |             "description": f"This is test document number {i + 1}",
231 |             "category": random.choice(categories),
232 |             "tags": [f"tag{j}" for j in range(random.randint(1, 5))],
    |                                               ^^^^^^^^^^^^^^^^^^^^
233 |             "status": random.choice(statuses),
234 |             "upload_date": doc_date.isoformat(),
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/data_fixtures.py:233:23
    |
231 |             "category": random.choice(categories),
232 |             "tags": [f"tag{j}" for j in range(random.randint(1, 5))],
233 |             "status": random.choice(statuses),
    |                       ^^^^^^^^^^^^^^^^^^^^^^^
234 |             "upload_date": doc_date.isoformat(),
235 |             "file_size": random.randint(100000, 10000000),
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/data_fixtures.py:235:26
    |
233 |             "status": random.choice(statuses),
234 |             "upload_date": doc_date.isoformat(),
235 |             "file_size": random.randint(100000, 10000000),
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
236 |             "page_count": random.randint(1, 100),
237 |             "author": f"Author {random.randint(1, 5)}",
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/data_fixtures.py:236:27
    |
234 |             "upload_date": doc_date.isoformat(),
235 |             "file_size": random.randint(100000, 10000000),
236 |             "page_count": random.randint(1, 100),
    |                           ^^^^^^^^^^^^^^^^^^^^^^
237 |             "author": f"Author {random.randint(1, 5)}",
238 |             "citations_count": random.randint(0, 50),
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/data_fixtures.py:237:33
    |
235 |             "file_size": random.randint(100000, 10000000),
236 |             "page_count": random.randint(1, 100),
237 |             "author": f"Author {random.randint(1, 5)}",
    |                                 ^^^^^^^^^^^^^^^^^^^^
238 |             "citations_count": random.randint(0, 50),
239 |             "metadata": {
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/data_fixtures.py:238:32
    |
236 |             "page_count": random.randint(1, 100),
237 |             "author": f"Author {random.randint(1, 5)}",
238 |             "citations_count": random.randint(0, 50),
    |                                ^^^^^^^^^^^^^^^^^^^^^
239 |             "metadata": {
240 |                 "version": "1.0",
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/data_fixtures.py:242:59
    |
240 |                 "version": "1.0",
241 |                 "language": "en",
242 |                 "keywords": [f"keyword{j}" for j in range(random.randint(3, 8))]
    |                                                           ^^^^^^^^^^^^^^^^^^^^
243 |             }
244 |         })
    |

F841 Local variable `malicious_name` is assigned to but never used
   --> tests_e2e/fixtures/data_fixtures.py:323:5
    |
322 |     # File with malicious name
323 |     malicious_name = test_dir / "../../etc/passwd.pdf"
    |     ^^^^^^^^^^^^^^
324 |     safe_malicious = test_dir / "malicious_name.pdf"
325 |     safe_malicious.write_bytes(b"%PDF-1.4\nTest")
    |
help: Remove assignment to unused variable `malicious_name`

S608 Possible SQL injection vector through string-based query construction
   --> tests_e2e/fixtures/database_fixtures.py:191:26
    |
189 |         for table in tables:
190 |             # Safe: table names are hardcoded test fixture names, not user input
191 |             self.execute(f"DELETE FROM {table}")
    |                          ^^^^^^^^^^^^^^^^^^^^^^
192 |         self.commit()
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:223:23
    |
222 |         for i in range(count):
223 |             user_id = random.choice(user_ids)
    |                       ^^^^^^^^^^^^^^^^^^^^^^^
224 |             status = random.choice(statuses)
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:224:22
    |
222 |         for i in range(count):
223 |             user_id = random.choice(user_ids)
224 |             status = random.choice(statuses)
    |                      ^^^^^^^^^^^^^^^^^^^^^^^
225 |
226 |             cursor = self.execute(
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:240:21
    |
238 |                     f"document_{i}.pdf",
239 |                     f"/storage/documents/document_{i}.pdf",
240 |                     random.randint(100000, 10000000),
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
241 |                     random.randint(1, 500),
242 |                     status,
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:241:21
    |
239 |                     f"/storage/documents/document_{i}.pdf",
240 |                     random.randint(100000, 10000000),
241 |                     random.randint(1, 500),
    |                     ^^^^^^^^^^^^^^^^^^^^^^
242 |                     status,
243 |                     datetime.now() - timedelta(hours=random.randint(0, 72))
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:243:54
    |
241 |                     random.randint(1, 500),
242 |                     status,
243 |                     datetime.now() - timedelta(hours=random.randint(0, 72))
    |                                                      ^^^^^^^^^^^^^^^^^^^^^
244 |                     if status == 'completed' else None,
245 |                     json.dumps({
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:248:59
    |
246 |                         "author": f"Author {i % 10}",
247 |                         "category": ["Research", "Tutorial", "Reference"][i % 3],
248 |                         "tags": [f"tag{j}" for j in range(random.randint(1, 5))]
    |                                                           ^^^^^^^^^^^^^^^^^^^^
249 |                     })
250 |                 )
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:262:30
    |
261 |         for doc_id in random.sample(document_ids, min(30, len(document_ids))):
262 |             citation_count = random.randint(1, 10)
    |                              ^^^^^^^^^^^^^^^^^^^^^
263 |
264 |             for i in range(citation_count):
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:278:32
    |
276 |                         f"[{i+1}] Citation text for reference",
277 |                         f"Author{i}, Co-Author{i}",
278 |                         2020 + random.randint(0, 4),
    |                                ^^^^^^^^^^^^^^^^^^^^
279 |                         f"Research Paper Title {i}",
280 |                         ["Journal", "Conference", "Book"][random.randint(0, 2)],
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:280:59
    |
278 |                         2020 + random.randint(0, 4),
279 |                         f"Research Paper Title {i}",
280 |                         ["Journal", "Conference", "Book"][random.randint(0, 2)],
    |                                                           ^^^^^^^^^^^^^^^^^^^^
281 |                         random.randint(1, 300),
282 |                         random.uniform(0.7, 1.0)
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:281:25
    |
279 |                         f"Research Paper Title {i}",
280 |                         ["Journal", "Conference", "Book"][random.randint(0, 2)],
281 |                         random.randint(1, 300),
    |                         ^^^^^^^^^^^^^^^^^^^^^^
282 |                         random.uniform(0.7, 1.0)
283 |                     )
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:282:25
    |
280 |                         ["Journal", "Conference", "Book"][random.randint(0, 2)],
281 |                         random.randint(1, 300),
282 |                         random.uniform(0.7, 1.0)
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^
283 |                     )
284 |                 )
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:307:23
    |
306 |         for _ in range(30):
307 |             user_id = random.choice(user_ids)
    |                       ^^^^^^^^^^^^^^^^^^^^^^^
308 |             query_text = random.choice(sample_queries)
309 |             selected_docs = random.sample(
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:308:26
    |
306 |         for _ in range(30):
307 |             user_id = random.choice(user_ids)
308 |             query_text = random.choice(sample_queries)
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
309 |             selected_docs = random.sample(
310 |                 document_ids,
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:311:21
    |
309 |             selected_docs = random.sample(
310 |                 document_ids,
311 |                 min(random.randint(1, 5), len(document_ids))
    |                     ^^^^^^^^^^^^^^^^^^^^
312 |             )
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:328:21
    |
326 |                     f"Response to: {query_text}. This is a detailed answer...",
327 |                     json.dumps(selected_docs),
328 |                     random.uniform(0.5, 1.0),
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^
329 |                     random.uniform(0.5, 5.0)
330 |                 )
    |

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/fixtures/database_fixtures.py:329:21
    |
327 |                     json.dumps(selected_docs),
328 |                     random.uniform(0.5, 1.0),
329 |                     random.uniform(0.5, 5.0)
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^
330 |                 )
331 |             )
    |

S608 Possible SQL injection vector through string-based query construction
   --> tests_e2e/fixtures/database_fixtures.py:345:35
    |
343 |         for table in tables:
344 |             # Safe: table names are hardcoded test fixture names, not user input
345 |             cursor = self.execute(f"SELECT COUNT(*) as count FROM {table}")
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
346 |             stats[f"{table}_count"] = cursor.fetchone()['count']
    |

SIM102 Use a single `if` statement instead of nested `if` statements
  --> tests_e2e/run_e2e_tests.py:67:9
   |
65 |           }
66 |
67 | /         if test_suite in suite_markers:
68 | |             if suite_markers[test_suite]:
   | |_________________________________________^
69 |                   cmd.extend(suite_markers[test_suite].split())
   |
help: Combine `if` statements using `and`

S603 `subprocess` call: check for execution of untrusted input
   --> tests_e2e/run_e2e_tests.py:106:18
    |
104 |         # Run tests
105 |         start_time = time.time()
106 |         result = subprocess.run(cmd, cwd=self.root_dir.parent)
    |                  ^^^^^^^^^^^^^^
107 |         duration = time.time() - start_time
    |

F403 `from fixtures import *` used; unable to detect undefined names
  --> tests_e2e/test_complete_document_workflow.py:11:1
   |
10 | import pytest
11 | from fixtures import *
   | ^^^^^^^^^^^^^^^^^^^^^^
12 | from playwright.sync_api import Page, expect
   |

F841 Local variable `upload_response` is assigned to but never used
   --> tests_e2e/test_complete_document_workflow.py:350:13
    |
348 |         # Wait for upload completion
349 |         with page.expect_response("**/api/documents/upload") as response_info:
350 |             upload_response = response_info.value
    |             ^^^^^^^^^^^^^^^
351 |
352 |         upload_time = time.time() - start_time
    |
help: Remove assignment to unused variable `upload_response`

F403 `from fixtures import *` used; unable to detect undefined names
  --> tests_e2e/test_library_management.py:10:1
   |
 9 | import pytest
10 | from fixtures import *
   | ^^^^^^^^^^^^^^^^^^^^^^
11 | from playwright.sync_api import Page, expect
   |

F841 Local variable `initial_order` is assigned to but never used
   --> tests_e2e/test_library_management.py:188:9
    |
186 |             return titles
187 |
188 |         initial_order = get_document_titles()
    |         ^^^^^^^^^^^^^
189 |
190 |         # Sort by title (A-Z)
    |
help: Remove assignment to unused variable `initial_order`

F841 Local variable `prev_button` is assigned to but never used
   --> tests_e2e/test_library_management.py:443:9
    |
441 |         # Test pagination navigation
442 |         next_button = pagination.locator('[data-testid="next-page"]')
443 |         prev_button = pagination.locator('[data-testid="prev-page"]')
    |         ^^^^^^^^^^^
444 |         page_number = pagination.locator('[data-testid="current-page"]')
    |
help: Remove assignment to unused variable `prev_button`

F841 Local variable `last_page_count` is assigned to but never used
   --> tests_e2e/test_library_management.py:463:9
    |
461 |         # Verify different documents shown
462 |         last_page_cards = page.locator('[data-testid="document-card"]')
463 |         last_page_count = last_page_cards.count()
    |         ^^^^^^^^^^^^^^^
464 |
465 |         # Go back to first page
    |
help: Remove assignment to unused variable `last_page_count`

F841 Local variable `first_page_count` is assigned to but never used
   --> tests_e2e/test_library_management.py:470:9
    |
469 |         first_page_cards = page.locator('[data-testid="document-card"]')
470 |         first_page_count = first_page_cards.count()
    |         ^^^^^^^^^^^^^^^^
471 |
472 |         # Test items per page selector
    |
help: Remove assignment to unused variable `first_page_count`

F403 `from fixtures import *` used; unable to detect undefined names
  --> tests_e2e/test_performance_and_load.py:14:1
   |
12 | import aiohttp
13 | import pytest
14 | from fixtures import *
   | ^^^^^^^^^^^^^^^^^^^^^^
15 | from playwright.sync_api import Browser, Page
   |

C901 `test_concurrent_user_simulation` is too complex (14 > 10)
  --> tests_e2e/test_performance_and_load.py:87:9
   |
85 |     @pytest.mark.performance
86 |     @pytest.mark.load
87 |     def test_concurrent_user_simulation(
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
88 |         self,
89 |         browser: Browser,
   |

B007 Loop control variable `i` not used within loop body
   --> tests_e2e/test_performance_and_load.py:104:17
    |
103 |             # Create multiple browser contexts (users)
104 |             for i in range(user_count):
    |                 ^
105 |                 context = browser.new_context()
106 |                 page = context.new_page()
    |
help: Rename unused `i` to `_i`

E722 Do not use bare `except`
   --> tests_e2e/test_performance_and_load.py:185:13
    |
183 |                     await response.text()
184 |                     return time.time() - start
185 |             except:
    |             ^^^^^^
186 |                 return None
    |

F405 `Path` may be undefined, or defined from star imports
   --> tests_e2e/test_performance_and_load.py:258:25
    |
256 |         for size_config in file_sizes:
257 |             # Create test file of specific size
258 |             test_file = Path(f"test_{size_config['name']}.pdf")
    |                         ^^^^
259 |
260 |             # Generate PDF content
    |

F841 Local variable `response` is assigned to but never used
   --> tests_e2e/test_performance_and_load.py:340:17
    |
338 |             for _ in range(5):
339 |                 start_time = time.time()
340 |                 response = api_client.post(
    |                 ^^^^^^^^
341 |                     '/api/rag/query',
342 |                     json={
    |
help: Remove assignment to unused variable `response`

S311 Standard pseudo-random generators are not suitable for cryptographic purposes
   --> tests_e2e/test_performance_and_load.py:405:22
    |
403 |             ]
404 |
405 |             action = random.choice(actions)
    |                      ^^^^^^^^^^^^^^^^^^^^^^
406 |             req_start = time.time()
    |

F403 `from fixtures import *` used; unable to detect undefined names
  --> tests_e2e/test_rag_query_workflow.py:10:1
   |
 9 | import pytest
10 | from fixtures import *
   | ^^^^^^^^^^^^^^^^^^^^^^
11 | from playwright.sync_api import Page, expect
   |

F841 Local variable `response_info` is assigned to but never used
   --> tests_e2e/test_rag_query_workflow.py:277:62
    |
276 |             submit_button = page.locator('[data-testid="submit-query"]')
277 |             with page.expect_response("**/api/rag/query") as response_info:
    |                                                              ^^^^^^^^^^^^^
278 |                 submit_button.click()
    |
help: Remove assignment to unused variable `response_info`

E722 Do not use bare `except`
   --> tests_e2e/test_rag_query_workflow.py:389:9
    |
387 |             submit_button.click()
388 |             page.wait_for_selector('[data-testid="rag-response"]', timeout=1000)
389 |         except:
    |         ^^^^^^
390 |             # Expected timeout
391 |             timeout_error = page.locator('[data-testid="timeout-error"]')
    |

F403 `from fixtures import *` used; unable to detect undefined names
  --> tests_e2e/test_security_workflows.py:12:1
   |
11 | import pytest
12 | from fixtures import *
   | ^^^^^^^^^^^^^^^^^^^^^^
13 | from playwright.sync_api import Page
   |

E722 Do not use bare `except`
  --> tests_e2e/test_security_workflows.py:46:13
   |
44 |                 page.wait_for_event("dialog", timeout=1000)
45 |                 alert_present = True
46 |             except:
   |             ^^^^^^
47 |                 alert_present = False
   |

E722 Do not use bare `except`
  --> tests_e2e/test_security_workflows.py:80:13
   |
78 |                 page.wait_for_event("dialog", timeout=1000)
79 |                 alert_present = True
80 |             except:
   |             ^^^^^^
81 |                 alert_present = False
   |

F405 `APIClient` may be undefined, or defined from star imports
   --> tests_e2e/test_security_workflows.py:293:26
    |
291 |         """Test authorization and access control."""
292 |         # Create different user sessions
293 |         regular_client = APIClient(web_server)
    |                          ^^^^^^^^^
294 |         admin_client = APIClient(web_server)
295 |         guest_client = APIClient(web_server)
    |

F405 `APIClient` may be undefined, or defined from star imports
   --> tests_e2e/test_security_workflows.py:294:24
    |
292 |         # Create different user sessions
293 |         regular_client = APIClient(web_server)
294 |         admin_client = APIClient(web_server)
    |                        ^^^^^^^^^
295 |         guest_client = APIClient(web_server)
    |

F405 `APIClient` may be undefined, or defined from star imports
   --> tests_e2e/test_security_workflows.py:295:24
    |
293 |         regular_client = APIClient(web_server)
294 |         admin_client = APIClient(web_server)
295 |         guest_client = APIClient(web_server)
    |                        ^^^^^^^^^
296 |
297 |         # Authenticate users
    |

B007 Loop control variable `i` not used within loop body
   --> tests_e2e/test_security_workflows.py:354:13
    |
352 |         # Test 3: Rate limiting per user role
353 |         # Admins might have higher limits
354 |         for i in range(100):
    |             ^
355 |             admin_client.get('/api/documents')
    |
help: Rename unused `i` to `_i`

B007 Loop control variable `i` not used within loop body
   --> tests_e2e/test_security_workflows.py:359:13
    |
357 |         # Regular users have standard limits
358 |         regular_limited = False
359 |         for i in range(100):
    |             ^
360 |             response = regular_client.get('/api/documents')
361 |             if response.status_code == 429:
    |
help: Rename unused `i` to `_i`

F841 Local variable `regular_limited` is assigned to but never used
   --> tests_e2e/test_security_workflows.py:362:17
    |
360 |             response = regular_client.get('/api/documents')
361 |             if response.status_code == 429:
362 |                 regular_limited = True
    |                 ^^^^^^^^^^^^^^^
363 |                 break
    |
help: Remove assignment to unused variable `regular_limited`

B007 Loop control variable `i` not used within loop body
   --> tests_e2e/test_security_workflows.py:367:13
    |
365 |         # Guests have strictest limits
366 |         guest_limited = False
367 |         for i in range(50):
    |             ^
368 |             response = guest_client.get('/api/documents')
369 |             if response.status_code == 429:
    |
help: Rename unused `i` to `_i`

F841 Local variable `guest_limited` is assigned to but never used
   --> tests_e2e/test_security_workflows.py:370:17
    |
368 |             response = guest_client.get('/api/documents')
369 |             if response.status_code == 429:
370 |                 guest_limited = True
    |                 ^^^^^^^^^^^^^
371 |                 break
    |
help: Remove assignment to unused variable `guest_limited`

PERF401 Use a list comprehension to create a transformed list
   --> tests_e2e/test_security_workflows.py:586:25
    |
584 |                 for response in responses:
585 |                     if not isinstance(response, Exception):
586 |                         status_codes.append(response.status)
    |                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
587 |
588 |                 return status_codes
    |
help: Replace for loop with list comprehension

F841 Local variable `chat_messages` is assigned to but never used
   --> tests_e2e/test_web_ui_basics.py:140:9
    |
139 |         # Check if message appears in chat (depending on implementation)
140 |         chat_messages = page.locator(".chat-message, .message, #chat-messages")
    |         ^^^^^^^^^^^^^
141 |
142 |         print("✅ Chat input functionality working")
    |
help: Remove assignment to unused variable `chat_messages`

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
  --> tests_e2e/utils/test_helpers.py:39:13
   |
37 |           # Delete documents
38 |           for doc_id in self.created_resources['documents']:
39 | /             try:
40 | |                 api_client.delete(f'/api/documents/{doc_id}')
41 | |             except:
42 | |                 pass
   | |____________________^
43 |
44 |           # Delete users
   |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
  --> tests_e2e/utils/test_helpers.py:41:13
   |
39 |             try:
40 |                 api_client.delete(f'/api/documents/{doc_id}')
41 |             except:
   |             ^^^^^^
42 |                 pass
   |

S110 `try`-`except`-`pass` detected, consider logging the exception
  --> tests_e2e/utils/test_helpers.py:41:13
   |
39 |               try:
40 |                   api_client.delete(f'/api/documents/{doc_id}')
41 | /             except:
42 | |                 pass
   | |____________________^
43 |
44 |           # Delete users
   |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> tests_e2e/utils/test_helpers.py:41:13
   |
39 |               try:
40 |                   api_client.delete(f'/api/documents/{doc_id}')
41 | /             except:
42 | |                 pass
   | |____________________^
43 |
44 |           # Delete users
   |

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
  --> tests_e2e/utils/test_helpers.py:46:13
   |
44 |           # Delete users
45 |           for user_id in self.created_resources['users']:
46 | /             try:
47 | |                 api_client.delete(f'/api/users/{user_id}')
48 | |             except:
49 | |                 pass
   | |____________________^
50 |
51 |           # Delete files
   |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
  --> tests_e2e/utils/test_helpers.py:48:13
   |
46 |             try:
47 |                 api_client.delete(f'/api/users/{user_id}')
48 |             except:
   |             ^^^^^^
49 |                 pass
   |

S110 `try`-`except`-`pass` detected, consider logging the exception
  --> tests_e2e/utils/test_helpers.py:48:13
   |
46 |               try:
47 |                   api_client.delete(f'/api/users/{user_id}')
48 | /             except:
49 | |                 pass
   | |____________________^
50 |
51 |           # Delete files
   |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> tests_e2e/utils/test_helpers.py:48:13
   |
46 |               try:
47 |                   api_client.delete(f'/api/users/{user_id}')
48 | /             except:
49 | |                 pass
   | |____________________^
50 |
51 |           # Delete files
   |

SIM105 Use `contextlib.suppress(BaseException)` instead of `try`-`except`-`pass`
  --> tests_e2e/utils/test_helpers.py:53:13
   |
51 |           # Delete files
52 |           for file_path in self.created_resources['files']:
53 | /             try:
54 | |                 Path(file_path).unlink()
55 | |             except:
56 | |                 pass
   | |____________________^
57 |
58 |           # Clear tracking
   |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(BaseException): ...`

E722 Do not use bare `except`
  --> tests_e2e/utils/test_helpers.py:55:13
   |
53 |             try:
54 |                 Path(file_path).unlink()
55 |             except:
   |             ^^^^^^
56 |                 pass
   |

S110 `try`-`except`-`pass` detected, consider logging the exception
  --> tests_e2e/utils/test_helpers.py:55:13
   |
53 |               try:
54 |                   Path(file_path).unlink()
55 | /             except:
56 | |                 pass
   | |____________________^
57 |
58 |           # Clear tracking
   |

PERF203 `try`-`except` within a loop incurs performance overhead
  --> tests_e2e/utils/test_helpers.py:55:13
   |
53 |               try:
54 |                   Path(file_path).unlink()
55 | /             except:
56 | |                 pass
   | |____________________^
57 |
58 |           # Clear tracking
   |

C401 Unnecessary generator (rewrite as a set comprehension)
   --> tests_e2e/utils/test_helpers.py:146:37
    |
144 |             'api_calls': len(self.get_api_calls()),
145 |             'slow_requests': len(self.get_slow_requests()),
146 |             'unique_endpoints': len(set(req['url'] for req in self.requests))
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
147 |         }
    |
help: Rewrite as a set comprehension

F841 Local variable `redis_success` is assigned to but never used
   --> verify_actual_dependencies.py:195:5
    |
194 |     # Test optional Redis (doesn't fail if not available)
195 |     redis_success = test_optional_redis()
    |     ^^^^^^^^^^^^^
196 |
197 |     # Overall success if database is working (Redis is optional)
    |
help: Remove assignment to unused variable `redis_success`

C901 `verify_fixes` is too complex (18 > 10)
  --> verify_fixes.py:14:5
   |
14 | def verify_fixes():
   |     ^^^^^^^^^^^^
15 |     """Verify all fixes have been applied."""
16 |     print("=" * 60)
   |

F841 Local variable `repo` is assigned to but never used
  --> verify_fixes.py:51:9
   |
50 |         db = DatabaseConnection(":memory:")
51 |         repo = MultiDocumentIndexRepository(db)
   |         ^^^^
52 |
53 |         # Check if table was created
   |
help: Remove assignment to unused variable `repo`

SIM105 Use `contextlib.suppress(psutil.NoSuchProcess)` instead of `try`-`except`-`pass`
  --> verify_server_startup.py:32:13
   |
30 |           # Kill children first
31 |           for child in children:
32 | /             try:
33 | |                 child.terminate()
34 | |             except psutil.NoSuchProcess:
35 | |                 pass
   | |____________________^
36 |
37 |           # Kill parent
   |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(psutil.NoSuchProcess): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
  --> verify_server_startup.py:34:13
   |
32 |               try:
33 |                   child.terminate()
34 | /             except psutil.NoSuchProcess:
35 | |                 pass
   | |____________________^
36 |
37 |           # Kill parent
   |

SIM105 Use `contextlib.suppress(psutil.NoSuchProcess)` instead of `try`-`except`-`pass`
  --> verify_server_startup.py:38:9
   |
37 |           # Kill parent
38 | /         try:
39 | |             parent.terminate()
40 | |         except psutil.NoSuchProcess:
41 | |             pass
   | |________________^
42 |
43 |           # Give them time to terminate gracefully
   |
help: Replace `try`-`except`-`pass` with `with contextlib.suppress(psutil.NoSuchProcess): ...`

PERF203 `try`-`except` within a loop incurs performance overhead
  --> verify_server_startup.py:51:13
   |
49 |                   if child.is_running():
50 |                       child.kill()
51 | /             except psutil.NoSuchProcess:
52 | |                 pass
   | |____________________^
53 |
54 |           try:
   |

C901 `verify_server_startup` is too complex (15 > 10)
  --> verify_server_startup.py:64:5
   |
64 | def verify_server_startup():
   |     ^^^^^^^^^^^^^^^^^^^^^
65 |     """
66 |     Verify that the API server starts up correctly.
   |

W293 Blank line contains whitespace
  --> verify_server_startup.py:67:1
   |
65 |     """
66 |     Verify that the API server starts up correctly.
67 |
   | ^^^^
68 |     Returns:
69 |         bool: True if server started successfully, False otherwise
   |
help: Remove whitespace from blank line

S603 `subprocess` call: check for execution of untrusted input
  --> verify_server_startup.py:94:26
   |
92 |         # Start the server process
93 |         # Use DEVNULL instead of PIPE to avoid buffering issues
94 |         server_process = subprocess.Popen(
   |                          ^^^^^^^^^^^^^^^^
95 |             [sys.executable, str(server_script)],
96 |             stdout=subprocess.DEVNULL,
   |

Found 1075 errors (2 fixed, 1073 remaining).
No fixes available (268 hidden fixes can be enabled with the `--unsafe-fixes` option).
